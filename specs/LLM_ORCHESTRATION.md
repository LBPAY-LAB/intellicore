# LLM Self-Hosted & Agent Orchestration
## Stack Completa para IA e Automa√ß√£o

---

## ü§ñ LLM SELF-HOSTED

### **Desenvolvimento**
```
Ollama
```

**Por qu√™:**
- ‚úÖ **Open-source** (MIT)
- ‚úÖ **Extremamente f√°cil**: `ollama run llama3.3`
- ‚úÖ **CPU/GPU**: Funciona em ambos
- ‚úÖ **Modelos**: Llama, Mistral, Gemma, etc.
- ‚úÖ **API**: OpenAI-compatible
- ‚úÖ **Quantiza√ß√£o**: Autom√°tica (4-bit, 8-bit)
- ‚úÖ **Mem√≥ria**: Gerenciamento autom√°tico

**Modelos recomendados para dev:**
```bash
# Pequeno e r√°pido (7B)
ollama run llama3.3:7b

# M√©dio (13B)
ollama run llama3.3:13b

# Grande (70B) - Requer GPU
ollama run llama3.3:70b
```

**Vantagens para dev:**
- ‚úÖ Setup em segundos
- ‚úÖ Troca de modelos f√°cil
- ‚úÖ Sem configura√ß√£o complexa
- ‚úÖ Funciona offline

---

### **Produ√ß√£o**
```
vLLM
```

**Por qu√™:**
- ‚úÖ **Open-source** (Apache 2.0)
- ‚úÖ **Performance**: 24x mais r√°pido que HuggingFace
- ‚úÖ **Throughput**: PagedAttention (otimiza√ß√£o de mem√≥ria)
- ‚úÖ **Batching**: Continuous batching autom√°tico
- ‚úÖ **Quantiza√ß√£o**: AWQ, GPTQ, SqueezeLLM
- ‚úÖ **API**: OpenAI-compatible
- ‚úÖ **Multi-GPU**: Tensor parallelism nativo
- ‚úÖ **Production-ready**: Usado por Anthropic, Databricks

**Compara√ß√£o:**

| Feature | vLLM | Ollama | Text Generation Inference (TGI) |
|---------|------|--------|--------------------------------|
| Performance | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Throughput | 24x HF | 5x HF | 10x HF |
| Batching | Continuous | Basic | Continuous |
| Multi-GPU | ‚úÖ Nativo | ‚ùå | ‚úÖ Nativo |
| Quantiza√ß√£o | AWQ, GPTQ | Auto | AWQ, GPTQ |
| Facilidade | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê |
| Produ√ß√£o | ‚úÖ | ‚ö†Ô∏è | ‚úÖ |

**Decis√£o:** 
- **Dev**: Ollama (facilidade)
- **Prod**: vLLM (performance)

---

### **Modelos Recomendados**

#### **Para Portugu√™s (pt-BR)**
```
1. Llama 3.3 70B (Meta)
   - Melhor modelo open-source geral
   - Excelente em portugu√™s
   - Requer GPU (A100 40GB ou 2x A10G)

2. Mistral Large 2 (Mistral AI)
   - Alternativa ao Llama
   - Bom em portugu√™s
   - Menor que Llama 70B

3. Qwen 2.5 72B (Alibaba)
   - Excelente em multilingual
   - Forte em portugu√™s
   - Bom para tarefas t√©cnicas
```

#### **Para Embeddings (Vector Search)**
```
1. multilingual-e5-large
   - Melhor para portugu√™s
   - 560M par√¢metros
   - 1024 dimens√µes

2. BGE-M3 (BAAI)
   - Multilingual
   - 567M par√¢metros
   - Suporta 100+ idiomas
```

**Decis√£o:**
- **LLM Principal**: Llama 3.3 70B
- **Embeddings**: multilingual-e5-large

---

### **Infraestrutura LLM**

**Desenvolvimento:**
```
1x VM com GPU
- GPU: NVIDIA RTX 4090 (24GB VRAM)
- RAM: 64GB
- Storage: 500GB NVMe
- Custo: ~$1.50/hora (cloud) ou ~$2.000 (hardware pr√≥prio)
```

**Produ√ß√£o:**
```
2x VMs com GPU (HA)
- GPU: NVIDIA A100 40GB (cada)
- RAM: 128GB (cada)
- Storage: 1TB NVMe (cada)
- Custo: ~$6/hora (cloud) ou ~$20.000 (hardware pr√≥prio)
```

**Alternativa econ√¥mica (Produ√ß√£o):**
```
4x VMs com GPU menor
- GPU: NVIDIA A10G 24GB (cada)
- RAM: 96GB (cada)
- Tensor Parallelism: 4-way split
- Custo: ~$4/hora (cloud)
```

---

## üé≠ ORQUESTRA√á√ÉO DE AGENTES

### **Frameworks Analisados**

#### **1. LangGraph (LangChain)**
```
Tipo: State machine para agentes
License: MIT
```

**Pr√≥s:**
- ‚úÖ **Controle total**: Define grafo de estados explicitamente
- ‚úÖ **Debugging**: Visualiza√ß√£o do grafo
- ‚úÖ **Persist√™ncia**: Checkpoints autom√°ticos
- ‚úÖ **Streaming**: Respostas em tempo real
- ‚úÖ **Human-in-the-loop**: Aprova√ß√µes manuais
- ‚úÖ **Integra√ß√£o**: LangChain ecosystem

**Contras:**
- ‚ö†Ô∏è Curva de aprendizado m√©dia
- ‚ö†Ô∏è Requer definir estados manualmente

**Casos de uso:**
- ‚úÖ Workflows complexos com m√∫ltiplos estados
- ‚úÖ Aprova√ß√µes humanas necess√°rias
- ‚úÖ Debugging detalhado importante

---

#### **2. CrewAI**
```
Tipo: Multi-agent collaboration
License: MIT
```

**Pr√≥s:**
- ‚úÖ **Simplicidade**: API declarativa
- ‚úÖ **Roles**: Agentes com pap√©is espec√≠ficos
- ‚úÖ **Tasks**: Delega√ß√£o autom√°tica
- ‚úÖ **Collaboration**: Agentes trabalham juntos
- ‚úÖ **Memory**: Compartilhamento de contexto

**Contras:**
- ‚ö†Ô∏è Menos controle que LangGraph
- ‚ö†Ô∏è Abstra√ß√£o pode esconder complexidade

**Casos de uso:**
- ‚úÖ M√∫ltiplos agentes especializados
- ‚úÖ Colabora√ß√£o entre agentes
- ‚úÖ Delega√ß√£o de tarefas

---

#### **3. AutoGen (Microsoft)**
```
Tipo: Conversational agents
License: MIT
```

**Pr√≥s:**
- ‚úÖ **Conversa√ß√£o**: Agentes conversam entre si
- ‚úÖ **Code execution**: Executa c√≥digo automaticamente
- ‚úÖ **Human-in-the-loop**: Aprova√ß√µes
- ‚úÖ **Groupchat**: M√∫ltiplos agentes em grupo
- ‚úÖ **Microsoft**: Suporte enterprise

**Contras:**
- ‚ö†Ô∏è Focado em conversa√ß√£o (pode ser overkill)
- ‚ö†Ô∏è Menos estruturado que LangGraph

**Casos de uso:**
- ‚úÖ Agentes que precisam conversar
- ‚úÖ Code generation/execution
- ‚úÖ Brainstorming entre agentes

---

#### **4. LlamaIndex Workflows**
```
Tipo: Event-driven workflows
License: MIT
```

**Pr√≥s:**
- ‚úÖ **Event-driven**: Baseado em eventos
- ‚úÖ **RAG nativo**: Integra√ß√£o com retrieval
- ‚úÖ **Streaming**: Respostas incrementais
- ‚úÖ **Type-safe**: TypeScript/Python

**Contras:**
- ‚ö†Ô∏è Mais novo (menos maduro)
- ‚ö†Ô∏è Focado em RAG (menos gen√©rico)

**Casos de uso:**
- ‚úÖ RAG complexo
- ‚úÖ Event-driven workflows
- ‚úÖ Streaming importante

---

#### **5. Haystack**
```
Tipo: NLP pipelines
License: Apache 2.0
```

**Pr√≥s:**
- ‚úÖ **Pipelines**: Composi√ß√£o de componentes
- ‚úÖ **RAG**: Excelente para retrieval
- ‚úÖ **Production**: Battle-tested
- ‚úÖ **Deepset**: Empresa por tr√°s

**Contras:**
- ‚ö†Ô∏è Focado em NLP/RAG (menos gen√©rico)
- ‚ö†Ô∏è Menos flex√≠vel para agentes complexos

**Casos de uso:**
- ‚úÖ RAG pipelines
- ‚úÖ Document processing
- ‚úÖ Q&A systems

---

### **Compara√ß√£o Resumida**

| Framework | Complexidade | Controle | RAG | Multi-Agent | Produ√ß√£o |
|-----------|--------------|----------|-----|-------------|----------|
| LangGraph | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| CrewAI | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| AutoGen | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| LlamaIndex | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Haystack | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

### **Decis√£o: Arquitetura H√≠brida**

**Para nosso caso (LBPay), recomendo combinar:**

```
LangGraph (workflows complexos)
+
CrewAI (agentes especializados)
+
LlamaIndex (RAG para documentos)
```

**Por qu√™:**

1. **LangGraph** para workflows de valida√ß√£o:
   - Estado: rascunho ‚Üí em_an√°lise ‚Üí aprovado
   - Checkpoints em cada etapa
   - Human-in-the-loop para aprova√ß√µes

2. **CrewAI** para agentes especializados:
   - Agente PF (especialista em pessoa f√≠sica)
   - Agente PJ (especialista em pessoa jur√≠dica)
   - Agente Compliance (valida normas BACEN)
   - Agente Fraud (detec√ß√£o de fraude)

3. **LlamaIndex** para RAG:
   - Indexar documentos BACEN
   - Indexar pol√≠ticas internas
   - Retrieval contextual

---

## üîÑ ORQUESTRA√á√ÉO DE WORKFLOWS/DADOS

### **Frameworks Analisados**

#### **1. Temporal**
```
Tipo: Durable execution engine
License: MIT
```

**Pr√≥s:**
- ‚úÖ **Durabilidade**: Workflows sobrevivem a crashes
- ‚úÖ **Long-running**: Workflows de dias/meses
- ‚úÖ **Retry**: Autom√°tico com backoff
- ‚úÖ **Versioning**: Workflows versionados
- ‚úÖ **Observability**: UI completa
- ‚úÖ **Multi-language**: Go, Python, TypeScript, Java

**Contras:**
- ‚ö†Ô∏è Complexidade de setup
- ‚ö†Ô∏è Requer infraestrutura dedicada

**Casos de uso:**
- ‚úÖ Processos de neg√≥cio longos (KYC, aprova√ß√µes)
- ‚úÖ Sagas/compensa√ß√µes
- ‚úÖ Workflows cr√≠ticos

---

#### **2. Dagster**
```
Tipo: Data orchestration
License: Apache 2.0
```

**Pr√≥s:**
- ‚úÖ **Data-aware**: Entende depend√™ncias de dados
- ‚úÖ **Testing**: Testes de pipelines nativos
- ‚úÖ **Lineage**: Rastreamento de dados
- ‚úÖ **Partitioning**: Dados particionados
- ‚úÖ **UI**: Dagit (interface gr√°fica)
- ‚úÖ **Type-safe**: Python com tipos

**Contras:**
- ‚ö†Ô∏è Focado em dados (menos gen√©rico)
- ‚ö†Ô∏è N√£o √© durable execution

**Casos de uso:**
- ‚úÖ ETL/ELT pipelines
- ‚úÖ Data warehousing
- ‚úÖ ML training pipelines
- ‚úÖ Batch processing

---

#### **3. Prefect**
```
Tipo: Workflow orchestration
License: Apache 2.0
```

**Pr√≥s:**
- ‚úÖ **Simplicidade**: API Python limpa
- ‚úÖ **Dynamic**: Workflows din√¢micos
- ‚úÖ **Observability**: UI moderna
- ‚úÖ **Retry**: Pol√≠ticas flex√≠veis
- ‚úÖ **Caching**: Cache de resultados

**Contras:**
- ‚ö†Ô∏è Menos dur√°vel que Temporal
- ‚ö†Ô∏è Menos features enterprise

**Casos de uso:**
- ‚úÖ Workflows Python
- ‚úÖ Data pipelines
- ‚úÖ Automa√ß√£o geral

---

#### **4. Apache Airflow**
```
Tipo: Workflow orchestration
License: Apache 2.0
```

**Pr√≥s:**
- ‚úÖ **Maturidade**: Padr√£o da ind√∫stria
- ‚úÖ **Comunidade**: Gigantesca
- ‚úÖ **Integra√ß√µes**: 1000+ operators
- ‚úÖ **UI**: Completa
- ‚úÖ **Scheduling**: Cron-like

**Contras:**
- ‚ö†Ô∏è Complexidade alta
- ‚ö†Ô∏è DAGs est√°ticos (menos flex√≠vel)
- ‚ö†Ô∏è Setup pesado

**Casos de uso:**
- ‚úÖ Batch processing
- ‚úÖ ETL tradicional
- ‚úÖ Scheduled jobs

---

### **Compara√ß√£o Resumida**

| Framework | Durabilidade | Simplicidade | Data-Aware | Long-Running | Produ√ß√£o |
|-----------|--------------|--------------|------------|--------------|----------|
| Temporal | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |
| Dagster | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Prefect | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê |
| Airflow | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê |

---

### **Decis√£o: Arquitetura H√≠brida**

**Para nosso caso (LBPay), recomendo:**

```
Temporal (processos de neg√≥cio)
+
Dagster (pipelines de dados)
```

**Por qu√™:**

1. **Temporal** para processos cr√≠ticos:
   - KYC workflow (pode levar dias)
   - Aprova√ß√µes em m√∫ltiplas etapas
   - Transa√ß√µes PIX (compensa√ß√µes)
   - Workflows com SLA

2. **Dagster** para dados:
   - ETL de documentos ‚Üí PostgreSQL
   - Sincroniza√ß√£o SQL ‚Üí Graph ‚Üí Vector
   - Gera√ß√£o de embeddings em batch
   - Relat√≥rios agendados

---

## üèóÔ∏è Arquitetura Completa de Orquestra√ß√£o

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                  FRONTEND (Next.js)                     ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ           API GATEWAY (Node.js + tRPC)                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                          ‚Üì
        ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
        ‚Üì                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê              ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ  AGENT LAYER     ‚îÇ              ‚îÇ  WORKFLOW LAYER  ‚îÇ
‚îÇ  (Python)        ‚îÇ              ‚îÇ  (Go/Python)     ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ              ‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  ‚Ä¢ LangGraph     ‚îÇ              ‚îÇ  ‚Ä¢ Temporal      ‚îÇ
‚îÇ  ‚Ä¢ CrewAI        ‚îÇ              ‚îÇ  ‚Ä¢ Dagster       ‚îÇ
‚îÇ  ‚Ä¢ LlamaIndex    ‚îÇ              ‚îÇ                  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò              ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì                                   ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    LLM LAYER                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  Dev: Ollama (Llama 3.3 70B)                            ‚îÇ
‚îÇ  Prod: vLLM (Llama 3.3 70B)                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
        ‚Üì
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                   DATA LAYER                            ‚îÇ
‚îÇ  ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ  ‚îÇ
‚îÇ  PostgreSQL | NebulaGraph | Qdrant | Valkey            ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## üìã Exemplo de Uso Combinado

### **Caso: Cria√ß√£o de Cliente PF**

**1. Frontend ‚Üí API Gateway**
```typescript
// Next.js
const result = await trpc.entity.create.mutate({
  type: 'cliente_pf',
  rawInput: 'nome: Jo√£o Silva, cpf: 123.456.789-00, ...'
});
```

**2. API Gateway ‚Üí CrewAI (Agentes)**
```python
# Python (FastAPI)
from crewai import Agent, Task, Crew

# Agente especializado em PF
pf_agent = Agent(
  role='Especialista em Pessoa F√≠sica',
  goal='Extrair e validar dados de PF',
  backstory='Conhece todas as regras BACEN para PF',
  llm=llm  # vLLM/Ollama
)

# Agente de compliance
compliance_agent = Agent(
  role='Compliance Officer',
  goal='Validar conformidade com normas',
  backstory='Especialista em regulamenta√ß√£o BACEN',
  llm=llm
)

# Task de extra√ß√£o
extract_task = Task(
  description=f'Extrair dados estruturados de: {raw_input}',
  agent=pf_agent
)

# Task de valida√ß√£o
validate_task = Task(
  description='Validar dados extra√≠dos contra pol√≠ticas',
  agent=compliance_agent,
  context=[extract_task]  # Depende da extra√ß√£o
)

# Executar crew
crew = Crew(agents=[pf_agent, compliance_agent], tasks=[extract_task, validate_task])
result = crew.kickoff()
```

**3. LangGraph (Workflow de Estados)**
```python
# Python
from langgraph.graph import StateGraph

# Definir estados
class EntityState(TypedDict):
    raw_input: str
    extracted_data: dict
    validation_result: dict
    current_state: str

# Criar grafo
workflow = StateGraph(EntityState)

# Adicionar n√≥s
workflow.add_node("extract", extract_node)
workflow.add_node("validate", validate_node)
workflow.add_node("save", save_node)

# Adicionar edges
workflow.add_edge("extract", "validate")
workflow.add_conditional_edges(
    "validate",
    lambda state: "save" if state["validation_result"]["valid"] else "extract"
)

# Executar
result = workflow.invoke({"raw_input": input_text})
```

**4. Temporal (Processo de Aprova√ß√£o)**
```python
# Python
from temporalio import workflow

@workflow.defn
class KYCWorkflow:
    @workflow.run
    async def run(self, entity_id: int) -> str:
        # Etapa 1: Valida√ß√£o autom√°tica
        validation = await workflow.execute_activity(
            validate_entity,
            entity_id,
            start_to_close_timeout=timedelta(minutes=5)
        )
        
        if not validation.auto_approved:
            # Etapa 2: Aprova√ß√£o humana (pode levar dias)
            approval = await workflow.wait_condition(
                lambda: self.approval_received,
                timeout=timedelta(days=7)
            )
            
            if not approval:
                return "REJECTED_TIMEOUT"
        
        # Etapa 3: Ativa√ß√£o
        await workflow.execute_activity(
            activate_entity,
            entity_id,
            start_to_close_timeout=timedelta(minutes=1)
        )
        
        return "APPROVED"
```

**5. Dagster (Sincroniza√ß√£o de Dados)**
```python
# Python
from dagster import asset, AssetExecutionContext

@asset
def entities_in_postgres(context: AssetExecutionContext):
    """Entidades no PostgreSQL"""
    return fetch_entities_from_postgres()

@asset(deps=[entities_in_postgres])
def entities_in_graph(context: AssetExecutionContext, entities_in_postgres):
    """Sincronizar entidades para NebulaGraph"""
    sync_to_nebula_graph(entities_in_postgres)
    return entities_in_postgres

@asset(deps=[entities_in_postgres])
def entity_embeddings(context: AssetExecutionContext, entities_in_postgres):
    """Gerar embeddings para busca sem√¢ntica"""
    embeddings = generate_embeddings(entities_in_postgres)
    upload_to_qdrant(embeddings)
    return embeddings
```

---

## üí∞ An√°lise de Custo

### **LLM Self-Hosted**

**Desenvolvimento:**
- 1x GPU VM (RTX 4090 24GB)
- Ollama + Llama 3.3 70B (quantizado 4-bit)
- **Custo: $1.50/hora ou $1.080/m√™s (24/7)**

**Produ√ß√£o:**
- 2x GPU VMs (A100 40GB cada)
- vLLM + Llama 3.3 70B
- Load balancing
- **Custo: $6/hora ou $4.320/m√™s (24/7)**

**Compara√ß√£o com SaaS:**
- OpenAI GPT-4: $30-150/1M tokens
- Anthropic Claude: $15-75/1M tokens
- **Estimativa: $5.000-20.000/m√™s** (dependendo do volume)

**Economia: 60-80% com self-hosted**

---

### **Orquestra√ß√£o**

**Temporal:**
- 3x VMs (8GB RAM, 4 vCPU cada)
- PostgreSQL para state
- **Custo: $150/m√™s**

**Dagster:**
- 2x VMs (16GB RAM, 8 vCPU cada)
- PostgreSQL para metadata
- **Custo: $200/m√™s**

**Total Orquestra√ß√£o: $350/m√™s**

---

## ‚úÖ Stack Final Recomendada

### **LLM**
- **Dev**: Ollama + Llama 3.3 70B
- **Prod**: vLLM + Llama 3.3 70B
- **Embeddings**: multilingual-e5-large

### **Agent Orchestration**
- **LangGraph**: Workflows de valida√ß√£o
- **CrewAI**: Agentes especializados (PF, PJ, Compliance)
- **LlamaIndex**: RAG para documentos

### **Workflow Orchestration**
- **Temporal**: Processos de neg√≥cio (KYC, aprova√ß√µes)
- **Dagster**: Pipelines de dados (ETL, sync, embeddings)

### **Todas as tecnologias:**
- ‚úÖ 100% Open-Source
- ‚úÖ Zero custo de licen√ßa
- ‚úÖ Self-hosted
- ‚úÖ Production-ready

---

## ‚ùì Aprova√ß√£o

Esta stack completa atende:
- ‚úÖ Ollama (dev) + vLLM (prod)
- ‚úÖ LLM self-hosted (Llama 3.3 70B)
- ‚úÖ Orquestra√ß√£o de agentes (LangGraph + CrewAI + LlamaIndex)
- ‚úÖ Orquestra√ß√£o de workflows (Temporal + Dagster)
- ‚úÖ 100% Open-Source e free

**Aprovado para implementa√ß√£o?**
