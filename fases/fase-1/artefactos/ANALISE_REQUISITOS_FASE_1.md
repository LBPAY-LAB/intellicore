# üìã An√°lise de Requisitos - Fase 1: Funda√ß√£o

**Projeto**: SuperCore v2.0
**Fase**: Fase 1 - Funda√ß√£o (Q1 2025)
**Data**: 2025-12-28
**Vers√£o**: 1.0.0

---

## üéØ Objetivo da Fase 1

Construir a **funda√ß√£o t√©cnica** do SuperCore v2.0, estabelecendo:
- ‚úÖ Modelo de dados (PostgreSQL + pgvector)
- ‚úÖ CRUD completo de Or√°culos
- ‚úÖ Gest√£o de Object Definitions
- ‚úÖ Upload e processamento de documentos
- ‚úÖ Pipeline RAG Trimodal (SQL + Vector + Graph)
- ‚úÖ Chat IA Assistant com streaming (SSE)
- ‚úÖ Interface administrativa (Back-office)

**Outcome esperado**: Plataforma funcional onde administradores podem criar Or√°culos, definir objetos, fazer upload de documentos e interagir via chat IA.

---

## üìö Requisitos Funcionais Mapeados

### RF001: Gest√£o de Or√°culos (Domains)
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo
**Complexidade**: Alta
**Story Points**: 34 SP

#### Descri√ß√£o Detalhada
Permitir que administradores criem e gerenciem **Or√°culos** (dom√≠nios de conhecimento isolados). Cada Or√°culo representa uma √°rea de neg√≥cio espec√≠fica (ex: Compliance, Pagamentos, Risco de Cr√©dito) com sua pr√≥pria base de conhecimento, configura√ß√µes e assistente IA.

**Rela√ß√£o com RF001-F (Gest√£o de Solu√ß√µes)**:
- Cada Or√°culo **pertence a 1 Solu√ß√£o** (campo `solution_id` obrigat√≥rio)
- Solu√ß√µes agrupam m√∫ltiplos or√°culos relacionados (ex: "LBPAY Core Banking" cont√©m or√°culos de Pagamentos, Compliance, Risco)
- Nome e slug do Or√°culo devem ser √∫nicos **dentro da mesma solu√ß√£o** (podem repetir entre solu√ß√µes diferentes)
- Quando uma solu√ß√£o √© deletada, todos seus or√°culos s√£o deletados em cascata (ON DELETE CASCADE)

#### User Stories
1. **Como administrador, quero listar todos os Or√°culos** para ter uma vis√£o geral dos dom√≠nios ativos
2. **Como administrador, quero criar um novo Or√°culo** para adicionar um novo dom√≠nio de conhecimento
3. **Como administrador, quero visualizar detalhes de um Or√°culo** para entender suas configura√ß√µes e estat√≠sticas
4. **Como administrador, quero editar um Or√°culo existente** para atualizar suas configura√ß√µes
5. **Como administrador, quero ativar/desativar um Or√°culo** para controlar sua disponibilidade
6. **Como administrador, quero deletar um Or√°culo** quando ele n√£o for mais necess√°rio

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] CRUD completo: Create, Read, Update, Delete
- [x] **Obrigat√≥rio**: Or√°culo pertence a 1 Solu√ß√£o (solution_id)
- [x] Valida√ß√£o de nome √∫nico **por solu√ß√£o** (pode haver "Compliance Bot" em 2 solu√ß√µes diferentes)
- [x] Valida√ß√£o de slug √∫nico **por solu√ß√£o** (URL-friendly, lowercase, hyphens)
- [x] Filtro por solu√ß√£o na listagem (opcional)
- [x] Status: Active/Inactive
- [x] Timestamps: created_at, updated_at
- [x] Soft delete: deleted_at (n√£o deletar fisicamente)

**Performance**:
- [x] Listagem com pagina√ß√£o (20 itens/p√°gina)
- [x] Busca em tempo real (<300ms)
- [x] Filtros: Status (Active/Inactive), Data de cria√ß√£o

**Seguran√ßa**:
- [x] Autentica√ß√£o obrigat√≥ria (JWT)
- [x] Apenas administradores podem criar/editar/deletar
- [x] Auditoria: Registrar todas as opera√ß√µes (quem, quando, o qu√™)

**UX/UI**:
- [x] Listagem em tabela com ordena√ß√£o e busca
- [x] Formul√°rio de cria√ß√£o com preview
- [x] Formul√°rio de edi√ß√£o com change tracking
- [x] Confirma√ß√£o antes de deletar
- [x] Feedback visual (toasts, spinners)
- [x] WCAG 2.1 AA compliant

#### Implementa√ß√£o T√©cnica

**Backend (Go)**:
```go
// models/oracle.go
type Oracle struct {
    ID          uuid.UUID  `json:"id" db:"id"`
    SolutionID  uuid.UUID  `json:"solution_id" db:"solution_id" binding:"required"` // Nova: pertence a 1 solu√ß√£o
    Name        string     `json:"name" db:"name" binding:"required,min=3,max=100"`
    Slug        string     `json:"slug" db:"slug" binding:"required,slug"`
    Description string     `json:"description" db:"description" binding:"max=500"`
    Status      string     `json:"status" db:"status" binding:"oneof=active inactive"`
    ModelName   string     `json:"model_name" db:"model_name" binding:"required"`
    Temperature float64    `json:"temperature" db:"temperature" binding:"min=0,max=2"`
    MaxTokens   int        `json:"max_tokens" db:"max_tokens" binding:"min=100,max=4000"`
    CreatedAt   time.Time  `json:"created_at" db:"created_at"`
    UpdatedAt   time.Time  `json:"updated_at" db:"updated_at"`
    DeletedAt   *time.Time `json:"deleted_at,omitempty" db:"deleted_at"`
}

// handlers/oracles.go
func ListOracles(c *gin.Context) {
    page := c.DefaultQuery("page", "1")
    limit := c.DefaultQuery("limit", "20")
    search := c.Query("search")
    status := c.Query("status")
    solutionID := c.Query("solution_id") // Nova: filtrar por solu√ß√£o

    oracles, total, err := oracleRepo.List(page, limit, search, status, solutionID)
    if err != nil {
        c.JSON(500, gin.H{"error": err.Error()})
        return
    }

    c.JSON(200, gin.H{
        "data": oracles,
        "total": total,
        "page": page,
        "limit": limit,
    })
}

func CreateOracle(c *gin.Context) {
    var oracle Oracle
    if err := c.ShouldBindJSON(&oracle); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }

    // Nova: validar que solu√ß√£o existe e est√° ativa
    solution, err := solutionRepo.GetByID(oracle.SolutionID)
    if err != nil {
        c.JSON(404, gin.H{"error": "Solution not found"})
        return
    }
    if solution.Status != "active" && solution.Status != "testing" {
        c.JSON(400, gin.H{"error": "Solution must be active or testing"})
        return
    }

    // Check uniqueness (nome √∫nico dentro da solu√ß√£o)
    exists, _ := oracleRepo.ExistsByNameInSolution(oracle.Name, oracle.SolutionID)
    if exists {
        c.JSON(409, gin.H{"error": "Oracle with this name already exists in this solution"})
        return
    }

    // Generate slug
    oracle.Slug = slug.Make(oracle.Name)

    if err := oracleRepo.Create(&oracle); err != nil {
        c.JSON(500, gin.H{"error": err.Error()})
        return
    }

    // Audit log
    auditLog.Log(c, "oracle_created", oracle.ID, oracle)

    c.JSON(201, oracle)
}
```

**Frontend (Next.js)**:
- P√°gina: `/admin/oracles`
- Componentes: OracleTable, OracleForm, OracleCard
- Estado: React Query (cache, refetch, optimistic updates)
- Formul√°rio: React Hook Form + Zod validation

**Database (PostgreSQL)**:
```sql
CREATE TABLE oracles (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    solution_id UUID NOT NULL REFERENCES solutions(id) ON DELETE CASCADE, -- Nova: pertence a 1 solu√ß√£o
    name VARCHAR(100) NOT NULL,
    slug VARCHAR(100) NOT NULL,
    description TEXT,
    status VARCHAR(20) NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'inactive')),
    model_name VARCHAR(50) NOT NULL DEFAULT 'gpt-4-turbo',
    temperature DECIMAL(3,2) DEFAULT 0.7 CHECK (temperature >= 0 AND temperature <= 2),
    max_tokens INTEGER DEFAULT 2000 CHECK (max_tokens >= 100 AND max_tokens <= 4000),
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    deleted_at TIMESTAMP,
    UNIQUE(solution_id, name), -- Nova: nome √∫nico por solu√ß√£o
    UNIQUE(solution_id, slug)  -- Nova: slug √∫nico por solu√ß√£o
);

CREATE INDEX idx_oracles_solution_id ON oracles(solution_id) WHERE deleted_at IS NULL;
CREATE INDEX idx_oracles_status ON oracles(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_oracles_created_at ON oracles(created_at DESC);
```

#### Depend√™ncias
- **Requisitos**: RF001-F (Gest√£o de Solu√ß√µes) deve estar implementado primeiro
- **Tecnologias**: Go 1.21, Gin, PostgreSQL 16, UUID v4
- **Bibliotecas**: go-playground/validator, gosimple/slug, google/uuid
- **Fase 0 completa**: Database setup, migrations, auth

#### Testes Obrigat√≥rios

**Unit Tests (Go)**:
- [x] `TestOracleValidation` - Validar campos obrigat√≥rios
- [x] `TestOracleUniqueName` - Garantir nomes √∫nicos
- [x] `TestOracleSlugGeneration` - Gerar slugs corretos
- [x] `TestOracleCRUD` - Criar, ler, atualizar, deletar

**Integration Tests**:
- [x] `TestOracleAPI_List` - GET /api/v1/oracles (200)
- [x] `TestOracleAPI_Create` - POST /api/v1/oracles (201)
- [x] `TestOracleAPI_CreateDuplicate` - POST /api/v1/oracles (409)
- [x] `TestOracleAPI_Get` - GET /api/v1/oracles/:id (200)
- [x] `TestOracleAPI_Update` - PUT /api/v1/oracles/:id (200)
- [x] `TestOracleAPI_Delete` - DELETE /api/v1/oracles/:id (204)

**E2E Tests (Playwright)**:
- [x] `oracle-crud.spec.ts` - Fluxo completo de cria√ß√£o, edi√ß√£o e dele√ß√£o
- [x] `oracle-search.spec.ts` - Busca e filtros
- [x] `oracle-validation.spec.ts` - Valida√ß√µes de formul√°rio

**Cobertura M√≠nima**: ‚â•85%

#### M√©tricas de Sucesso
- **Performance**: Listagem <200ms (p95), Cria√ß√£o <500ms (p95)
- **Disponibilidade**: 99.5% uptime
- **Usabilidade**: SUS Score ‚â•80
- **Qualidade**: 0 bugs cr√≠ticos em produ√ß√£o

---

### RF001-B: Sistema de Tags para Or√°culos
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo
**Complexidade**: M√©dia
**Story Points**: 8 SP
**Depend√™ncia**: RF001 (base)

#### Descri√ß√£o Detalhada
Implementar sistema de **tags multi-palavra** para classifica√ß√£o √°gil de Or√°culos. Tags substituem o campo "Dom√≠nio" anterior, permitindo classifica√ß√£o flex√≠vel com m√∫ltiplas etiquetas por Or√°culo.

#### Exemplos de Tags
- `#Core Banking` (com espa√ßo)
- `#PIX Rules`
- `#Dict Rules`
- `#Compliance`
- `#AML` (Anti-Money Laundering)
- `#KYC` (Know Your Customer)

#### User Stories
1. **Como administrador, quero adicionar m√∫ltiplas tags a um Or√°culo** para classific√°-lo em diferentes categorias
2. **Como administrador, quero filtrar Or√°culos por tags** para encontrar rapidamente os de um dom√≠nio espec√≠fico
3. **Como administrador, quero buscar Or√°culos por tags** na barra de pesquisa global
4. **Como administrador, quero ver todas as tags usadas no sistema** para manter consist√™ncia na nomenclatura

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] Tags permitem espa√ßos (ex: `#Core Banking`)
- [x] Rela√ß√£o many-to-many (um Or√°culo pode ter N tags, uma tag pode estar em N Or√°culos)
- [x] Auto-complete de tags existentes ao digitar
- [x] Cria√ß√£o de novas tags on-the-fly
- [x] Remo√ß√£o de tags de um Or√°culo
- [x] Filtro por m√∫ltiplas tags (AND/OR logic)
- [x] Busca full-text em tags

**Valida√ß√µes**:
- [x] Tag deve come√ßar com `#`
- [x] Tag deve ter entre 2-50 caracteres
- [x] Sem caracteres especiais (exceto espa√ßos e h√≠fens)
- [x] Case-insensitive (`#PIX Rules` === `#pix rules`)
- [x] No m√°ximo 10 tags por Or√°culo

**Performance**:
- [x] Filtro por tags <200ms
- [x] Auto-complete <100ms
- [x] Indexa√ß√£o full-text (PostgreSQL GIN index)

#### Implementa√ß√£o T√©cnica

**Backend (Go)**:
```go
// models/oracle_tag.go
type OracleTag struct {
    ID        uuid.UUID  `json:"id" db:"id"`
    Name      string     `json:"name" db:"name" binding:"required,min=2,max=50"`
    Slug      string     `json:"slug" db:"slug"` // lowercase, no #
    UsageCount int       `json:"usage_count" db:"usage_count"` // quantos Or√°culos usam
    CreatedAt time.Time  `json:"created_at" db:"created_at"`
}

type OracleTagAssociation struct {
    OracleID uuid.UUID `db:"oracle_id"`
    TagID    uuid.UUID `db:"tag_id"`
}
```

**Database Migration**:
```sql
-- 003_create_oracle_tags.up.sql
CREATE TABLE oracle_tags (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(50) UNIQUE NOT NULL,
    slug VARCHAR(50) UNIQUE NOT NULL,
    usage_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE TABLE oracle_tag_associations (
    oracle_id UUID NOT NULL REFERENCES oracles(id) ON DELETE CASCADE,
    tag_id UUID NOT NULL REFERENCES oracle_tags(id) ON DELETE CASCADE,
    PRIMARY KEY (oracle_id, tag_id),
    created_at TIMESTAMP DEFAULT NOW()
);

CREATE INDEX idx_oracle_tags_slug ON oracle_tags USING GIN (to_tsvector('portuguese', slug));
CREATE INDEX idx_oracle_tag_associations_oracle ON oracle_tag_associations(oracle_id);
CREATE INDEX idx_oracle_tag_associations_tag ON oracle_tag_associations(tag_id);
```

**API Endpoints**:
- `GET /api/tags` - Listar todas as tags (com usage_count)
- `GET /api/tags/autocomplete?q=core` - Auto-complete de tags
- `POST /api/oracles/:id/tags` - Adicionar tags a Or√°culo
- `DELETE /api/oracles/:id/tags/:tagId` - Remover tag de Or√°culo
- `GET /api/oracles?tags=core-banking,pix-rules` - Filtrar por tags

---

### RF001-C: Configura√ß√£o de Tipos de Or√°culo
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo
**Complexidade**: M√©dia
**Story Points**: 5 SP
**Depend√™ncia**: RF001 (base)

#### Descri√ß√£o Detalhada
Permitir que administradores **gerenciem tipos de Or√°culos** via interface administrativa. Tipos definem como o Or√°culo ser√° consumido/integrado (Middleware, Portal Web, MCP Server, etc.).

#### Tipos Padr√£o (Iniciais)
1. **Middleware** - Integra√ß√£o entre sistemas
2. **Portal Web** - Interface web din√¢mica
3. **MCP Server** - Servidor de contexto MCP

#### User Stories
1. **Como administrador, quero criar novos tipos de Or√°culo** para suportar novos contextos de integra√ß√£o
2. **Como administrador, quero editar tipos existentes** para atualizar suas descri√ß√µes
3. **Como administrador, quero desativar tipos** quando n√£o forem mais usados
4. **Como administrador, quero ver quantos Or√°culos usam cada tipo** para entender distribui√ß√£o

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] CRUD de tipos (Create, Read, Update, Delete)
- [x] Nome √∫nico por tipo
- [x] Descri√ß√£o detalhada (at√© 500 caracteres)
- [x] √çcone emoji opcional
- [x] Status: Active/Inactive
- [x] Counter: quantos Or√°culos usam o tipo
- [x] Prote√ß√£o contra dele√ß√£o: tipos em uso n√£o podem ser deletados (apenas desativados)

**Valida√ß√µes**:
- [x] Nome √∫nico (case-insensitive)
- [x] Descri√ß√£o m√≠nima de 20 caracteres
- [x] Slug auto-gerado (lowercase, hyphens)

**Regras de Neg√≥cio**:
- [x] Se tipo tem `oraclesCount > 0` ‚Üí n√£o pode deletar (apenas editar/desativar)
- [x] Se tipo `inactive` ‚Üí n√£o aparece em dropdowns de cria√ß√£o/edi√ß√£o de Or√°culos
- [x] Sistema sempre mant√©m 3 tipos padr√£o (Middleware, Portal Web, MCP Server) ativos

#### Implementa√ß√£o T√©cnica

**Backend (Go)**:
```go
// models/oracle_type.go
type OracleType struct {
    ID           uuid.UUID  `json:"id" db:"id"`
    Name         string     `json:"name" db:"name" binding:"required,min=3,max=50"`
    Slug         string     `json:"slug" db:"slug"`
    Description  string     `json:"description" db:"description" binding:"required,min=20,max=500"`
    Icon         string     `json:"icon,omitempty" db:"icon"` // emoji opcional
    Status       string     `json:"status" db:"status" binding:"oneof=active inactive"`
    OraclesCount int        `json:"oracles_count" db:"oracles_count"`
    CreatedAt    time.Time  `json:"created_at" db:"created_at"`
    UpdatedAt    time.Time  `json:"updated_at" db:"updated_at"`
}
```

**Database Migration**:
```sql
-- 004_create_oracle_types.up.sql
CREATE TABLE oracle_types (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(50) UNIQUE NOT NULL,
    slug VARCHAR(50) UNIQUE NOT NULL,
    description TEXT NOT NULL,
    icon VARCHAR(10),
    status VARCHAR(20) DEFAULT 'active' CHECK (status IN ('active', 'inactive')),
    oracles_count INTEGER DEFAULT 0,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW()
);

-- Inserir tipos padr√£o
INSERT INTO oracle_types (name, slug, description, icon, status) VALUES
('Middleware', 'middleware', 'Integra√ß√£o entre sistemas, permitindo comunica√ß√£o e troca de dados', '‚öôÔ∏è', 'active'),
('Portal Web', 'portal-web', 'Interface web din√¢mica gerada pelo Or√°culo para usu√°rios finais', 'üåê', 'active'),
('MCP Server', 'mcp-server', 'Servidor de contexto seguindo protocolo MCP (Model Context Protocol)', 'üîå', 'active');

-- Adicionar FK em oracles
ALTER TABLE oracles ADD COLUMN type_id UUID REFERENCES oracle_types(id);
UPDATE oracles SET type_id = (SELECT id FROM oracle_types WHERE slug = 'middleware' LIMIT 1);
ALTER TABLE oracles ALTER COLUMN type_id SET NOT NULL;

CREATE INDEX idx_oracles_type_id ON oracles(type_id);
```

**API Endpoints**:
- `GET /api/oracle-types` - Listar todos os tipos
- `GET /api/oracle-types?status=active` - Apenas ativos (para dropdowns)
- `POST /api/oracle-types` - Criar novo tipo
- `PUT /api/oracle-types/:id` - Editar tipo
- `DELETE /api/oracle-types/:id` - Deletar tipo (apenas se `oraclesCount === 0`)

---

### RF001-D: Gest√£o de Provedores LLM
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo
**Complexidade**: Alta
**Story Points**: 13 SP
**Depend√™ncia**: RF001 (base)

#### Descri√ß√£o Detalhada
Permitir configura√ß√£o centralizada de **provedores de LLM** (online e self-hosted) via interface administrativa. Or√°culos selecionam provedores pr√©-configurados ao inv√©s de hardcoded models.

#### Tipos de Provedores

**Online (API-based)**:
- OpenAI (GPT-4 Turbo, GPT-4, GPT-3.5 Turbo)
- Anthropic (Claude 3 Opus, Claude 3 Sonnet)
- Google (Gemini 1.5 Pro, Gemini 1.0 Pro)
- Cohere, Mistral

**Self-Hosted**:
- Ollama (Llama 2, Mistral, etc.)
- LocalAI
- Text Generation WebUI
- LM Studio

#### User Stories
1. **Como administrador, quero configurar provedores online** com API keys para uso em Or√°culos
2. **Como administrador, quero configurar provedores self-hosted** com endpoints locais
3. **Como administrador, quero testar conectividade** antes de salvar um provedor
4. **Como administrador, quero ativar/desativar provedores** para controlar disponibilidade
5. **Como administrador, quero ver quais Or√°culos usam cada provedor** para impacto de mudan√ßas

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade - Provedores Online**:
- [x] CRUD de provedores (Create, Read, Update, Delete)
- [x] Campos: Provider (OpenAI, Anthropic, Google), Model, API Key, Display Name
- [x] API Key armazenada com criptografia AES-256
- [x] API Key exibida mascarada (ex: `sk-***7A2E`)
- [x] Teste de conectividade opcional (request simples)
- [x] Status: Active/Testing/Inactive

**Funcionalidade - Provedores Self-Hosted**:
- [x] Campos: Provider (Ollama, LocalAI), Model, Endpoint URL, Auth Token (opcional)
- [x] Health check autom√°tico a cada 5 minutos
- [x] Status atualizado automaticamente se endpoint offline
- [x] Lat√™ncia m√©dia nos √∫ltimos 100 requests

**Valida√ß√µes**:
- [x] API Key formato v√°lido (provider-specific regex)
  - OpenAI: `^sk-(proj-)?[A-Za-z0-9]{40,}$`
  - Anthropic: `^sk-ant-[A-Za-z0-9-]+$`
  - Google: `^AIza[A-Za-z0-9_-]{35}$`
- [x] Endpoint URL v√°lida (http/https)
- [x] Modelo existe no provedor (via API discovery se dispon√≠vel)

**Regras de Neg√≥cio**:
- [x] Se provedor tem Or√°culos ativos ‚Üí n√£o pode deletar (apenas desativar)
- [x] Provedores inativos n√£o aparecem em dropdowns de cria√ß√£o/edi√ß√£o de Or√°culos
- [x] Health check falha ‚Üí status `inactive` autom√°tico

#### Implementa√ß√£o T√©cnica

**Backend (Go + Python)**:
```go
// models/llm_provider.go
type LLMProvider struct {
    ID            uuid.UUID  `json:"id" db:"id"`
    ProviderType  string     `json:"provider_type" db:"provider_type"` // online | self-hosted
    Provider      string     `json:"provider" db:"provider"` // openai, anthropic, ollama, etc.
    Model         string     `json:"model" db:"model"`
    APIKey        string     `json:"-" db:"api_key"` // encrypted, n√£o retornar em JSON
    APIKeyMasked  string     `json:"api_key_masked" db:"-"` // sk-***7A2E
    Endpoint      string     `json:"endpoint,omitempty" db:"endpoint"` // para self-hosted
    DisplayName   string     `json:"display_name,omitempty" db:"display_name"`
    Status        string     `json:"status" db:"status"` // active, testing, inactive
    AvgLatency    float64    `json:"avg_latency_ms,omitempty" db:"avg_latency_ms"`
    OraclesCount  int        `json:"oracles_count" db:"oracles_count"`
    LastTested    *time.Time `json:"last_tested,omitempty" db:"last_tested"`
    CreatedAt     time.Time  `json:"created_at" db:"created_at"`
    UpdatedAt     time.Time  `json:"updated_at" db:"updated_at"`
}
```

**Database Migration**:
```sql
-- 005_create_llm_providers.up.sql
CREATE TABLE llm_providers (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    provider_type VARCHAR(20) NOT NULL CHECK (provider_type IN ('online', 'self-hosted')),
    provider VARCHAR(50) NOT NULL,
    model VARCHAR(100) NOT NULL,
    api_key TEXT, -- encrypted
    endpoint TEXT,
    display_name VARCHAR(100),
    status VARCHAR(20) DEFAULT 'testing' CHECK (status IN ('active', 'testing', 'inactive')),
    avg_latency_ms FLOAT,
    oracles_count INTEGER DEFAULT 0,
    last_tested TIMESTAMP,
    created_at TIMESTAMP DEFAULT NOW(),
    updated_at TIMESTAMP DEFAULT NOW(),
    UNIQUE(provider, model)
);

-- Inserir provedores padr√£o
INSERT INTO llm_providers (provider_type, provider, model, display_name, status) VALUES
('online', 'openai', 'gpt-4-turbo', 'OpenAI - GPT-4 Turbo', 'inactive'),
('online', 'anthropic', 'claude-3-opus', 'Anthropic - Claude 3 Opus', 'inactive');

-- Adicionar FK em oracles
ALTER TABLE oracles ADD COLUMN llm_provider_id UUID REFERENCES llm_providers(id);
UPDATE oracles SET llm_provider_id = (SELECT id FROM llm_providers WHERE provider = 'openai' LIMIT 1);
ALTER TABLE oracles ALTER COLUMN llm_provider_id SET NOT NULL;
-- Remover campos antigos
ALTER TABLE oracles DROP COLUMN model_name;

CREATE INDEX idx_oracles_llm_provider_id ON oracles(llm_provider_id);
```

**API Endpoints**:
- `GET /api/llm-providers` - Listar todos
- `GET /api/llm-providers?status=active` - Apenas ativos (para dropdowns)
- `POST /api/llm-providers` - Criar novo
- `PUT /api/llm-providers/:id` - Editar
- `DELETE /api/llm-providers/:id` - Deletar (apenas se `oraclesCount === 0`)
- `POST /api/llm-providers/:id/test` - Testar conectividade
- `GET /api/llm-providers/:id/health` - Health check (self-hosted)

**Encryption (API Keys)**:
```go
// utils/encryption.go
import "crypto/aes"
import "crypto/cipher"

func EncryptAPIKey(plaintext string) (string, error) {
    key := []byte(os.Getenv("ENCRYPTION_KEY")) // 32 bytes
    block, _ := aes.NewCipher(key)
    gcm, _ := cipher.NewGCM(block)
    nonce := make([]byte, gcm.NonceSize())
    ciphertext := gcm.Seal(nonce, nonce, []byte(plaintext), nil)
    return base64.StdEncoding.EncodeToString(ciphertext), nil
}

func DecryptAPIKey(ciphertext string) (string, error) {
    key := []byte(os.Getenv("ENCRYPTION_KEY"))
    data, _ := base64.StdEncoding.DecodeString(ciphertext)
    block, _ := aes.NewCipher(key)
    gcm, _ := cipher.NewGCM(block)
    nonceSize := gcm.NonceSize()
    nonce, ciphertext := data[:nonceSize], data[nonceSize:]
    plaintext, _ := gcm.Open(nil, nonce, ciphertext, nil)
    return string(plaintext), nil
}
```

---

### RF001-E: RAG Global (Shared Knowledge Base)
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo
**Complexidade**: M√©dia
**Story Points**: 4 SP
**Depend√™ncia**: RF001 (base), RF004 (RAG Trimodal)

#### Descri√ß√£o Detalhada
Criar um **Or√°culo Global especial** que cont√©m conhecimento compartilhado entre todos os Or√°culos **da mesma solu√ß√£o** (regula√ß√µes BACEN, pol√≠ticas LGPD, normas AML/KYC, etc.). Este Or√°culo funciona como **fallback** quando Or√°culos espec√≠ficos n√£o encontram respostas suficientes.

**Rela√ß√£o com RF001-F (Gest√£o de Solu√ß√µes)**:
- Cada **Solu√ß√£o tem exatamente 1 RAG Global** (auto-criado ao criar a solu√ß√£o)
- RAG Global √© isolado por solu√ß√£o (multi-tenancy completo)
- Or√°culos s√≥ consultam o RAG Global **da sua pr√≥pria solu√ß√£o**
- Exemplo: "LBPAY Core Banking" tem seu pr√≥prio RAG Global, separado de "SuperCommerce"

#### Casos de Uso
1. **Regula√ß√µes Financeiras**: BACEN, CVM, SUSEP (compartilhadas por todos os Or√°culos)
2. **Compliance Global**: LGPD, PCI-DSS, ISO 27001
3. **Pol√≠ticas Corporativas**: C√≥digos de conduta, pol√≠ticas de seguran√ßa
4. **Gloss√°rio Financeiro**: Termos t√©cnicos, acr√¥nimos, conceitos

#### Exemplos Pr√°ticos

**Cen√°rio 1**: Or√°culo "PIX Compliance"
```
User: "Qual o limite de transa√ß√£o PIX para PF?"
Sistema:
1. Busca RAG do Or√°culo PIX (espec√≠fico) ‚Üí Encontra: "Limite R$ 1.000 (noturno)"
2. Busca RAG Global (fallback) ‚Üí Encontra: "Resolu√ß√£o BCB 1/2020, Art. 3¬∫"
3. Combina: "R$ 1.000 no hor√°rio noturno (20h-6h), conforme Resolu√ß√£o BCB 1/2020"
```

**Cen√°rio 2**: Or√°culo "KYC Onboarding"
```
User: "Preciso validar CPF do cliente?"
Sistema:
1. Busca RAG KYC (espec√≠fico) ‚Üí Encontra: "Valida√ß√£o CPF obrigat√≥ria"
2. Busca RAG Global (fallback) ‚Üí Encontra: "LGPD Art. 7¬∫ - base legal"
3. Combina: "Sim, obrigat√≥rio. Base legal: LGPD Art. 7¬∫ (execu√ß√£o de contrato)"
```

#### User Stories
1. **Como sistema, quero criar automaticamente 1 RAG Global** ao criar uma nova solu√ß√£o (RF001-F)
2. **Como administrador, quero fazer upload de documentos globais** no RAG Global da minha solu√ß√£o (PDFs de regula√ß√µes, pol√≠ticas)
3. **Como usu√°rio, quero que o chat IA consulte automaticamente o RAG Global da solu√ß√£o** quando necess√°rio (fallback)
4. **Como administrador, quero ver quais Or√°culos da solu√ß√£o est√£o usando o RAG Global** (metrics)

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] Campo `is_global` em tabela `oracles` (boolean, default: false)
- [x] **Apenas 1 Or√°culo pode ser `is_global=true` por solu√ß√£o** (n√£o sistema inteiro)
- [x] **RAG Global √© auto-criado** ao criar nova solu√ß√£o (RF001-F)
- [x] RAG Global √© consultado automaticamente via `HybridRAGRetriever`
- [x] Fallback logic: Per-Oracle RAG primeiro, Global RAG **da mesma solu√ß√£o** segundo
- [x] Respostas indicam fonte (Global vs Per-Oracle)

**Valida√ß√µes**:
- [x] Apenas admin pode editar Or√°culo Global (cria√ß√£o √© autom√°tica)
- [x] Or√°culo Global n√£o pode ser deletado manualmente (deletado com a solu√ß√£o via CASCADE)
- [x] Se `is_global=true` ‚Üí tipo deve ser "RAG Global" (novo tipo)
- [x] Or√°culos s√≥ consultam RAG Global **da sua pr√≥pria solu√ß√£o** (`solution_id` match)

**Performance**:
- [x] Fallback adiciona <100ms ao tempo total (queries paralelas)
- [x] Cache compartilhado (Redis) para queries globais frequentes

**UX/UI**:
- [x] Badge visual "üåç Global" em listagem de Or√°culos
- [x] Chat IA mostra fonte das respostas:
  - "üìÑ Fonte: Or√°culo PIX (espec√≠fico)"
  - "üåç Fonte: RAG Global (regula√ß√£o BACEN)"

#### Implementa√ß√£o T√©cnica

**Database Migration**:
```sql
-- 006_add_global_oracle_flag.up.sql
ALTER TABLE oracles ADD COLUMN is_global BOOLEAN DEFAULT FALSE;

-- Constraint: apenas 1 Or√°culo global POR SOLU√á√ÉO (n√£o sistema inteiro)
CREATE UNIQUE INDEX idx_oracles_global_per_solution
ON oracles(solution_id, is_global) WHERE is_global = TRUE AND deleted_at IS NULL;

-- Criar tipo "RAG Global"
INSERT INTO oracle_types (name, slug, description, icon, status) VALUES
('RAG Global', 'rag-global', 'Base de conhecimento compartilhada entre or√°culos da mesma solu√ß√£o', 'üåç', 'active');

-- NOTA: RAG Global N√ÉO √© criado aqui manualmente
-- Ser√° auto-criado ao executar RF001-F (CreateSolution handler)
-- Cada solu√ß√£o ter√° seu pr√≥prio RAG Global isolado
```

**Backend (Python - RAG)**:
```python
# services/hybrid_rag_retriever.py
class HybridRAGRetriever:
    def __init__(self, oracle_id: str, solution_id: str = None):
        self.oracle_id = oracle_id
        self.solution_id = solution_id or self._get_oracle_solution_id(oracle_id)
        self.global_oracle_id = self._get_global_oracle_id_for_solution(self.solution_id)

    async def retrieve(self, query: str, top_k: int = 10) -> List[Document]:
        # 1Ô∏è‚É£ Per-Oracle RAG (espec√≠fico)
        oracle_results = await self.vector_db.search(
            oracle_id=self.oracle_id,
            query_embedding=self.embed(query),
            limit=top_k
        )

        # 2Ô∏è‚É£ Global RAG (fallback) - executado em paralelo
        # IMPORTANTE: Apenas consulta RAG Global DA MESMA SOLU√á√ÉO
        global_results = []
        if self.global_oracle_id and len(oracle_results) < top_k:
            global_results = await self.vector_db.search(
                oracle_id=self.global_oracle_id,
                query_embedding=self.embed(query),
                limit=top_k - len(oracle_results)
            )

        # 3Ô∏è‚É£ Merge e tag source
        merged = []
        for doc in oracle_results:
            doc.metadata["source_type"] = "per-oracle"
            doc.metadata["source_icon"] = "üìÑ"
            merged.append(doc)

        for doc in global_results:
            doc.metadata["source_type"] = "global"
            doc.metadata["source_icon"] = "üåç"
            merged.append(doc)

        # 4Ô∏è‚É£ Rerank (LLM-based)
        return self.rerank(merged, query)[:top_k]

    def _get_oracle_solution_id(self, oracle_id: str) -> str:
        result = db.query("SELECT solution_id FROM oracles WHERE id = $1", oracle_id)
        return result[0]["solution_id"] if result else None

    def _get_global_oracle_id_for_solution(self, solution_id: str) -> str:
        # Query database for is_global=true NA MESMA SOLU√á√ÉO
        result = db.query(
            "SELECT id FROM oracles WHERE solution_id = $1 AND is_global = TRUE LIMIT 1",
            solution_id
        )
        return result[0]["id"] if result else None
```

**Frontend (Chat IA - Source Badges)**:
```tsx
// components/ChatMessage.tsx
function ChatMessage({ message }: { message: Message }) {
  return (
    <div className="message">
      <ReactMarkdown>{message.content}</ReactMarkdown>

      {/* Source badges */}
      {message.sources && (
        <div className="sources mt-2 flex gap-2">
          {message.sources.map((source, i) => (
            <Badge key={i} variant={source.type === 'global' ? 'secondary' : 'default'}>
              {source.icon} {source.name}
            </Badge>
          ))}
        </div>
      )}
    </div>
  );
}
```

#### Depend√™ncias
- **Requisitos**: RF001-F (Gest√£o de Solu√ß√µes) - RAG Global √© auto-criado ao criar solu√ß√£o
- **Tecnologias**: PostgreSQL (unique constraints), Python (async queries)

#### M√©tricas de Sucesso
- **Recall**: +15% (com RAG Global vs sem)
- **Global hit rate**: 30-40% das queries consultam Global **da mesma solu√ß√£o**
- **Lat√™ncia**: <100ms adicionais para fallback
- **Governan√ßa**: 1 fonte √∫nica de regula√ß√µes **por solu√ß√£o** (consist√™ncia + isolamento)

#### Roadmap de Expans√£o (Fase 3)
- **Cross-Oracle Search**: Buscar em m√∫ltiplos Or√°culos **da mesma solu√ß√£o** simultaneamente
- **Smart Routing**: LLM decide automaticamente quais Or√°culos consultar (sempre dentro da solu√ß√£o)
- **Global + Multi-Oracle**: Combinar RAG Global + 2-3 Or√°culos relacionados (multi-tenancy mantido)

---

### RF001-F: Gest√£o de Solu√ß√µes (Aggregators)
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 0.5 - Solu√ß√£o (novo n√≠vel organizacional acima de Or√°culos)
**Complexidade**: M√©dia
**Story Points**: 8 SP
**Depend√™ncia**: RF001 (base)

#### Descri√ß√£o Detalhada
Criar camada **Solu√ß√£o** como agregador organizacional de Or√°culos. Cada solu√ß√£o representa um produto/cliente/dom√≠nio de neg√≥cio (ex: "LBPAY Core Banking") e cont√©m:
- **1 RAG Global** (obrigat√≥rio, auto-criado)
- **N Or√°culos** espec√≠ficos (Compliance, PIX, KYC, etc.)

**Hierarquia**:
```
Sistema SuperCore
‚îî‚îÄ‚îÄ Solu√ß√£o (ex: "LBPAY Core Banking")
    ‚îú‚îÄ‚îÄ RAG Global (obrigat√≥rio, 1 por solu√ß√£o)
    ‚îú‚îÄ‚îÄ Or√°culo 1 (Payment Gateway)
    ‚îú‚îÄ‚îÄ Or√°culo 2 (Compliance Bot)
    ‚îî‚îÄ‚îÄ Or√°culo N
```

**Isolamento**: Cada solu√ß√£o tem dados 100% isolados (multi-tenancy).

#### User Stories
1. **Como administrador, quero listar todas as Solu√ß√µes** para ter vis√£o dos produtos/clientes ativos
2. **Como administrador, quero criar uma nova Solu√ß√£o** com gera√ß√£o autom√°tica de RAG Global
3. **Como administrador, quero visualizar dashboard de uma Solu√ß√£o** com m√©tricas de or√°culos
4. **Como administrador, quero editar informa√ß√µes de uma Solu√ß√£o** (nome, descri√ß√£o, icon)
5. **Como administrador, quero ativar/desativar uma Solu√ß√£o** para controlar disponibilidade
6. **Como administrador, quero deletar uma Solu√ß√£o** quando n√£o for mais necess√°ria

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] CRUD completo: Create, Read, Update, Delete
- [x] Auto-cria√ß√£o de RAG Global ao criar Solu√ß√£o (transacional)
- [x] Valida√ß√£o de nome √∫nico
- [x] Valida√ß√£o de slug (URL-friendly)
- [x] Status: Active/Testing/Inactive
- [x] Emoji icon como identificador visual
- [x] Timestamps: created_at, updated_at
- [x] Soft delete: deleted_at
- [x] Prote√ß√£o contra dele√ß√£o: bloqueado se tem or√°culos ativos

**Performance**:
- [x] Listagem com pagina√ß√£o (12 cards/p√°gina)
- [x] Card grid responsivo (3/2/1 colunas)
- [x] M√©tricas agregadas: count(or√°culos), count(objetos), count(agentes)

**Seguran√ßa**:
- [x] Apenas administradores podem criar/editar/deletar
- [x] Auditoria completa de opera√ß√µes

**UX/UI**:
- [x] Home page = listagem de solu√ß√µes (n√£o or√°culos)
- [x] Card grid com icon + nome + status + m√©tricas
- [x] Wizard de 3 etapas para criar solu√ß√£o
- [x] Dashboard por solu√ß√£o (m√©tricas + lista de or√°culos)
- [x] Breadcrumb navega√ß√£o: Solu√ß√µes > {Solu√ß√£o} > Or√°culos

#### Implementa√ß√£o T√©cnica

**Database (PostgreSQL)**:
```sql
-- Migration: 007_create_solutions_table.up.sql
CREATE TABLE solutions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    name VARCHAR(255) NOT NULL UNIQUE,
    slug VARCHAR(255) NOT NULL UNIQUE,
    icon VARCHAR(10) NOT NULL, -- emoji
    description TEXT,
    global_rag_oracle_id UUID REFERENCES oracles(id), -- RAG Global para esta solu√ß√£o
    status VARCHAR(50) NOT NULL DEFAULT 'active' CHECK (status IN ('active', 'testing', 'inactive')),
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    deleted_at TIMESTAMP
);

-- Foreign key: oracles pertencem a 1 solu√ß√£o
ALTER TABLE oracles ADD COLUMN solution_id UUID REFERENCES solutions(id) ON DELETE CASCADE;
CREATE INDEX idx_oracles_solution_id ON oracles(solution_id) WHERE deleted_at IS NULL;

-- Unique constraint: apenas 1 RAG Global por solu√ß√£o
CREATE UNIQUE INDEX idx_solutions_global_rag
ON solutions(global_rag_oracle_id) WHERE global_rag_oracle_id IS NOT NULL;

-- Indexes
CREATE INDEX idx_solutions_status ON solutions(status) WHERE deleted_at IS NULL;
CREATE INDEX idx_solutions_created_at ON solutions(created_at DESC);
```

**Backend (Go)**:
```go
// models/solution.go
type Solution struct {
    ID                  uuid.UUID  `json:"id" db:"id"`
    Name                string     `json:"name" db:"name" binding:"required,min=3,max=100"`
    Slug                string     `json:"slug" db:"slug" binding:"required,slug"`
    Icon                string     `json:"icon" db:"icon" binding:"required,emoji"`
    Description         string     `json:"description" db:"description" binding:"max=500"`
    GlobalRAGOracleID   *uuid.UUID `json:"global_rag_oracle_id,omitempty" db:"global_rag_oracle_id"`
    Status              string     `json:"status" db:"status" binding:"oneof=active testing inactive"`
    CreatedAt           time.Time  `json:"created_at" db:"created_at"`
    UpdatedAt           time.Time  `json:"updated_at" db:"updated_at"`
    DeletedAt           *time.Time `json:"deleted_at,omitempty" db:"deleted_at"`

    // Agrega√ß√µes (n√£o persistidas)
    Metrics SolutionMetrics `json:"metrics,omitempty" db:"-"`
    GlobalRagOracle *Oracle `json:"global_rag_oracle,omitempty" db:"-"`
}

type SolutionMetrics struct {
    OraclesCount     int `json:"oracles_count"`
    ObjectsCount     int `json:"objects_count"`
    AgentsCount      int `json:"agents_count"`
    MCPServersCount  int `json:"mcp_servers_count,omitempty"`
}

// handlers/solutions.go
func CreateSolution(c *gin.Context) {
    var request CreateSolutionRequest
    if err := c.ShouldBindJSON(&request); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }

    // Start Temporal Workflow (SAGA pattern with automatic compensation)
    workflowOptions := client.StartWorkflowOptions{
        ID:        fmt.Sprintf("create-solution-%s", uuid.New().String()),
        TaskQueue: "global-crud", // Go workers handle CRUD operations
        WorkflowExecutionTimeout: 2 * time.Hour,
    }

    we, err := temporalClient.ExecuteWorkflow(
        context.Background(),
        workflowOptions,
        workflows.CreateSolutionWorkflow,
        request, // { Name, Icon, Description, Documents }
    )
    if err != nil {
        c.JSON(500, gin.H{"error": "Failed to start workflow", "details": err.Error()})
        return
    }

    // Get workflow result (blocks until workflow completes)
    var solution Solution
    if err := we.Get(context.Background(), &solution); err != nil {
        c.JSON(500, gin.H{"error": "Workflow failed", "details": err.Error()})
        return
    }

    // Audit log
    auditLog.Log(c, "solution_created", solution.ID, solution)

    c.JSON(201, gin.H{
        "solution": solution,
        "workflow_id": we.GetID(),
        "run_id": we.GetRunID(),
    })
}

// Temporal Workflow Implementation (Go SDK)
// File: workflows/create_solution_workflow.go
package workflows

import (
    "fmt"
    "time"

    "go.temporal.io/sdk/workflow"
)

type CreateSolutionRequest struct {
    Name        string     `json:"name"`
    Icon        string     `json:"icon"`
    Description string     `json:"description"`
    Documents   []Document `json:"documents,omitempty"`
}

// CreateSolutionWorkflow - SAGA pattern with automatic compensation
func CreateSolutionWorkflow(ctx workflow.Context, req CreateSolutionRequest) (*Solution, error) {
    logger := workflow.GetLogger(ctx)
    logger.Info("Starting CreateSolution workflow", "name", req.Name)

    // Activity options with retry policy
    activityOptions := workflow.ActivityOptions{
        StartToCloseTimeout: 30 * time.Second,
        RetryPolicy: &temporal.RetryPolicy{
            MaximumAttempts: 3,
            InitialInterval: time.Second,
            MaximumInterval: 10 * time.Second,
        },
    }
    ctx = workflow.WithActivityOptions(ctx, activityOptions)

    // Activity 1: Create Solution (DB transaction)
    var solution Solution
    err := workflow.ExecuteActivity(ctx, activities.CreateSolutionDB, req).Get(ctx, &solution)
    if err != nil {
        logger.Error("Failed to create solution", "error", err)
        return nil, fmt.Errorf("create solution failed: %w", err)
    }
    logger.Info("Solution created", "solution_id", solution.ID)

    // Activity 2: Create RAG Global oracle (DB transaction)
    var ragGlobal Oracle
    err = workflow.ExecuteActivity(ctx, activities.CreateRAGGlobalOracle, solution.ID).Get(ctx, &ragGlobal)
    if err != nil {
        // Compensation: Delete solution
        logger.Warn("RAG Global creation failed, compensating...", "error", err)
        _ = workflow.ExecuteActivity(ctx, activities.DeleteSolution, solution.ID).Get(ctx, nil)
        return nil, fmt.Errorf("create RAG Global failed: %w", err)
    }
    logger.Info("RAG Global created", "oracle_id", ragGlobal.ID)

    // Activity 3: Link RAG Global to Solution
    err = workflow.ExecuteActivity(ctx, activities.LinkRAGGlobal, solution.ID, ragGlobal.ID).Get(ctx, nil)
    if err != nil {
        // Compensation: Delete both
        logger.Warn("Failed to link RAG Global, compensating...", "error", err)
        _ = workflow.ExecuteActivity(ctx, activities.DeleteRAGGlobal, ragGlobal.ID).Get(ctx, nil)
        _ = workflow.ExecuteActivity(ctx, activities.DeleteSolution, solution.ID).Get(ctx, nil)
        return nil, fmt.Errorf("link RAG Global failed: %w", err)
    }

    // Activity 4: Process initial documents (long-running, optional)
    if len(req.Documents) > 0 {
        // Change activity timeout for long-running document processing
        docActivityOptions := workflow.ActivityOptions{
            StartToCloseTimeout: 30 * time.Minute,
            HeartbeatTimeout:    5 * time.Minute,
            RetryPolicy: &temporal.RetryPolicy{
                MaximumAttempts: 2, // Only 2 attempts for expensive operations
            },
        }
        docCtx := workflow.WithActivityOptions(ctx, docActivityOptions)

        // Process documents in parallel
        futures := make([]workflow.Future, len(req.Documents))
        for i, doc := range req.Documents {
            futures[i] = workflow.ExecuteActivity(docCtx, activities.ProcessDocument,
                ProcessDocRequest{
                    OracleID: ragGlobal.ID,
                    Document: doc,
                })
        }

        // Wait for all documents (partial failure is OK)
        for i, future := range futures {
            var result ProcessDocResult
            if err := future.Get(ctx, &result); err != nil {
                logger.Warn("Document processing failed", "index", i, "error", err)
                // Continue with other docs (non-critical)
            } else {
                logger.Info("Document processed", "index", i, "chunks", result.ChunksProcessed)
            }
        }
    }

    // Activity 5: Finalize solution status
    err = workflow.ExecuteActivity(ctx, activities.FinalizeSolution, solution.ID).Get(ctx, nil)
    if err != nil {
        logger.Warn("Failed to finalize solution", "error", err)
        // Non-critical, don't fail workflow
    }

    logger.Info("CreateSolution workflow completed", "solution_id", solution.ID)
    return &solution, nil
}

// Activities Implementation (Go)
// File: activities/solution_activities.go
package activities

import (
    "context"
    "fmt"

    "github.com/google/uuid"
    "gorm.io/gorm"
)

type SolutionActivities struct {
    db *gorm.DB
}

func (a *SolutionActivities) CreateSolutionDB(ctx context.Context, req CreateSolutionRequest) (*Solution, error) {
    solution := &Solution{
        ID:          uuid.New(),
        Name:        req.Name,
        Slug:        slug.Make(req.Name),
        Icon:        req.Icon,
        Description: req.Description,
        Status:      "active",
    }

    if err := a.db.Create(solution).Error; err != nil {
        return nil, fmt.Errorf("failed to create solution: %w", err)
    }

    return solution, nil
}

func (a *SolutionActivities) CreateRAGGlobalOracle(ctx context.Context, solutionID uuid.UUID) (*Oracle, error) {
    ragGlobal := &Oracle{
        SolutionID:    &solutionID,
        Name:          fmt.Sprintf("RAG Global - %s", solutionID),
        TypeID:        getOracleTypeID("rag-global"),
        IsGlobal:      true,
        LLMProviderID: getDefaultLLMProvider(),
        Status:        "active",
    }

    if err := a.db.Create(ragGlobal).Error; err != nil {
        return nil, fmt.Errorf("failed to create RAG Global: %w", err)
    }

    return ragGlobal, nil
}

func (a *SolutionActivities) LinkRAGGlobal(ctx context.Context, solutionID, ragGlobalID uuid.UUID) error {
    if err := a.db.Model(&Solution{}).Where("id = ?", solutionID).
        Update("global_rag_oracle_id", ragGlobalID).Error; err != nil {
        return fmt.Errorf("failed to link RAG Global: %w", err)
    }
    return nil
}

func (a *SolutionActivities) DeleteSolution(ctx context.Context, solutionID uuid.UUID) error {
    return a.db.Delete(&Solution{}, "id = ?", solutionID).Error
}

func (a *SolutionActivities) DeleteRAGGlobal(ctx context.Context, oracleID uuid.UUID) error {
    return a.db.Delete(&Oracle{}, "id = ?", oracleID).Error
}

func (a *SolutionActivities) FinalizeSolution(ctx context.Context, solutionID uuid.UUID) error {
    return a.db.Model(&Solution{}).Where("id = ?", solutionID).
        Update("status", "active").Error
}

func DeleteSolution(c *gin.Context) {
    solutionID := c.Param("id")

    // Verificar se tem or√°culos ativos
    activeOraclesCount, _ := oracleRepo.CountActive(solutionID)
    if activeOraclesCount > 0 {
        c.JSON(409, gin.H{
            "error": "Cannot delete solution with active oracles",
            "active_oracles_count": activeOraclesCount,
        })
        return
    }

    // Soft delete
    if err := solutionRepo.SoftDelete(solutionID); err != nil {
        c.JSON(500, gin.H{"error": err.Error()})
        return
    }

    auditLog.Log(c, "solution_deleted", solutionID, nil)
    c.JSON(204, nil)
}
```

**Frontend (Next.js)**:
- P√°gina: `/solucoes` (home page principal)
- P√°gina: `/solucoes/{slug}` (dashboard de solu√ß√£o)
- P√°gina: `/solucoes/new` (wizard de cria√ß√£o)
- P√°gina: `/solucoes/{slug}/oracles` (lista de or√°culos da solu√ß√£o)
- Componentes: SolutionCard, SolutionForm (wizard 3 etapas), SolutionDashboard

**Rotas de API**:
```
GET    /api/v1/solutions              # Listar solu√ß√µes (com m√©tricas)
POST   /api/v1/solutions              # Criar solu√ß√£o + RAG Global
GET    /api/v1/solutions/:id          # Detalhes de solu√ß√£o
GET    /api/v1/solutions/:slug        # Detalhes por slug
PUT    /api/v1/solutions/:id          # Atualizar solu√ß√£o
DELETE /api/v1/solutions/:id          # Deletar solu√ß√£o (soft)
GET    /api/v1/solutions/:id/metrics  # M√©tricas agregadas
```

#### Impacto em Requisitos Existentes

**RF001 (Gest√£o de Or√°culos)**:
- Adicionar campo `solution_id` obrigat√≥rio
- Listar or√°culos agora filtra por solu√ß√£o
- Criar or√°culo requer `solution_id` no payload

**RF001-E (RAG Global)**:
- RAG Global agora √© **per-solution** (n√£o global ao sistema)
- 1 RAG Global por solu√ß√£o (n√£o 1 para todo o sistema)
- Isolamento de conhecimento entre solu√ß√µes

**RF002-RF017 (todos)**:
- Todos recursos (Objects, Agents, MCPs, etc.) herdam `solution_id` de seu or√°culo pai

#### Testes Obrigat√≥rios

**Unit Tests (Go)**:
- [x] `TestSolutionValidation` - Nome, slug, icon obrigat√≥rios
- [x] `TestSolutionUniqueName` - Nomes √∫nicos
- [x] `TestSolutionTransactionalCreate` - Rollback se RAG Global falha
- [x] `TestSolutionDeleteProtection` - Bloqueia se tem or√°culos ativos

**Integration Tests**:
- [x] `TestSolutionAPI_Create` - POST /api/v1/solutions (201, cria RAG Global)
- [x] `TestSolutionAPI_Delete` - DELETE blocked se or√°culos ativos (409)
- [x] `TestSolutionAPI_Metrics` - GET /api/v1/solutions/:id/metrics (200)

**E2E Tests (Playwright)**:
- [x] `solution-crud.spec.ts` - Criar solu√ß√£o ‚Üí ver dashboard ‚Üí deletar
- [x] `solution-wizard.spec.ts` - Wizard 3 etapas completo
- [x] `solution-isolation.spec.ts` - Or√°culos de solu√ß√£o A n√£o aparecem em solu√ß√£o B

#### M√©tricas de Sucesso
- **Performance**: Cria√ß√£o transacional <1s (solu√ß√£o + RAG Global)
- **Usabilidade**: Wizard completion rate ‚â•90%
- **Isolamento**: 0 vazamentos de dados entre solu√ß√µes
- **Governan√ßa**: 1 RAG Global por solu√ß√£o (sempre)

---

### RF002: Object Definitions (Schema Din√¢mico)
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 2 - Objetos
**Complexidade**: Muito Alta
**Story Points**: 42 SP

#### Descri√ß√£o Detalhada
Permitir que cada Or√°culo defina seus pr√≥prios **Object Definitions** (schemas de objetos) de forma din√¢mica. Um Object Definition √© um template que define a estrutura de dados de um tipo de objeto (ex: Cliente, Produto, Transa√ß√£o).

**Exemplo**:
- Or√°culo "Compliance" ‚Üí Object Definition "Transa√ß√£o Suspeita" com campos: valor, data, cliente_id, motivo
- Or√°culo "Pagamentos" ‚Üí Object Definition "Pagamento" com campos: valor, m√©todo, status, merchant_id

#### User Stories
1. **Como administrador, quero criar um Object Definition para um Or√°culo** para definir a estrutura de dados
2. **Como administrador, quero adicionar campos (fields) a um Object Definition** para especificar atributos
3. **Como administrador, quero definir tipos de campos** (string, number, date, boolean, array, object)
4. **Como administrador, quero definir valida√ß√µes** (required, min, max, regex, enum)
5. **Como administrador, quero versionar Object Definitions** para manter compatibilidade com dados antigos
6. **Como administrador, quero visualizar o JSON Schema gerado** para validar estrutura

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] CRUD de Object Definitions
- [x] Suporte a 8 tipos de campos: string, number, integer, boolean, date, array, object, enum
- [x] Valida√ß√µes: required, min, max, minLength, maxLength, pattern (regex), enum
- [x] Nested objects (objetos dentro de objetos)
- [x] Arrays de objetos
- [x] JSON Schema v√°lido (Draft 2020-12)
- [x] Versionamento (v1, v2, v3...) com migra√ß√£o autom√°tica

**Performance**:
- [x] Listagem <300ms (p95)
- [x] Cria√ß√£o <500ms (p95)
- [x] Valida√ß√£o de JSON Schema <100ms (p95)

**Seguran√ßa**:
- [x] Isolamento por Or√°culo (Object Definitions n√£o compartilhados)
- [x] Valida√ß√£o de schema antes de salvar
- [x] Auditoria de mudan√ßas

**UX/UI**:
- [x] Form Builder visual (drag-and-drop de campos)
- [x] Preview do JSON Schema gerado
- [x] Valida√ß√£o em tempo real
- [x] Versionamento visual (hist√≥rico de mudan√ßas)

#### Implementa√ß√£o T√©cnica

**Backend (Go)**:
```go
// models/object_definition.go
type ObjectDefinition struct {
    ID          uuid.UUID       `json:"id" db:"id"`
    OracleID    uuid.UUID       `json:"oracle_id" db:"oracle_id"`
    Name        string          `json:"name" db:"name"`
    Slug        string          `json:"slug" db:"slug"`
    Description string          `json:"description" db:"description"`
    Version     int             `json:"version" db:"version"`
    JSONSchema  json.RawMessage `json:"json_schema" db:"json_schema"`
    IsActive    bool            `json:"is_active" db:"is_active"`
    CreatedAt   time.Time       `json:"created_at" db:"created_at"`
    UpdatedAt   time.Time       `json:"updated_at" db:"updated_at"`
}

type Field struct {
    Name        string                 `json:"name"`
    Type        string                 `json:"type"` // string, number, boolean, date, array, object
    Description string                 `json:"description"`
    Required    bool                   `json:"required"`
    Validation  map[string]interface{} `json:"validation"` // min, max, pattern, enum, etc
    Fields      []Field                `json:"fields,omitempty"` // for nested objects
}

// handlers/object_definitions.go
func CreateObjectDefinition(c *gin.Context) {
    var req struct {
        OracleID    uuid.UUID `json:"oracle_id" binding:"required"`
        Name        string    `json:"name" binding:"required,min=3,max=100"`
        Description string    `json:"description"`
        Fields      []Field   `json:"fields" binding:"required,min=1"`
    }

    if err := c.ShouldBindJSON(&req); err != nil {
        c.JSON(400, gin.H{"error": err.Error()})
        return
    }

    // Generate JSON Schema from fields
    schema := generateJSONSchema(req.Fields)

    // Validate JSON Schema
    if err := validateJSONSchema(schema); err != nil {
        c.JSON(400, gin.H{"error": "Invalid JSON Schema: " + err.Error()})
        return
    }

    objDef := ObjectDefinition{
        OracleID:    req.OracleID,
        Name:        req.Name,
        Slug:        slug.Make(req.Name),
        Description: req.Description,
        Version:     1,
        JSONSchema:  schema,
        IsActive:    true,
    }

    if err := objDefRepo.Create(&objDef); err != nil {
        c.JSON(500, gin.H{"error": err.Error()})
        return
    }

    c.JSON(201, objDef)
}

// utils/json_schema.go
func generateJSONSchema(fields []Field) json.RawMessage {
    schema := map[string]interface{}{
        "$schema": "https://json-schema.org/draft/2020-12/schema",
        "type":    "object",
        "properties": fieldsToProperties(fields),
        "required": getRequiredFields(fields),
    }

    bytes, _ := json.Marshal(schema)
    return bytes
}

func fieldsToProperties(fields []Field) map[string]interface{} {
    props := make(map[string]interface{})

    for _, field := range fields {
        prop := map[string]interface{}{
            "type":        field.Type,
            "description": field.Description,
        }

        // Add validation rules
        if field.Validation != nil {
            for k, v := range field.Validation {
                prop[k] = v
            }
        }

        // Handle nested objects
        if field.Type == "object" && len(field.Fields) > 0 {
            prop["properties"] = fieldsToProperties(field.Fields)
            prop["required"] = getRequiredFields(field.Fields)
        }

        // Handle arrays
        if field.Type == "array" && len(field.Fields) > 0 {
            prop["items"] = map[string]interface{}{
                "type":       "object",
                "properties": fieldsToProperties(field.Fields),
                "required":   getRequiredFields(field.Fields),
            }
        }

        props[field.Name] = prop
    }

    return props
}
```

**Database (PostgreSQL)**:
```sql
CREATE TABLE object_definitions (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    oracle_id UUID NOT NULL REFERENCES oracles(id) ON DELETE CASCADE,
    name VARCHAR(100) NOT NULL,
    slug VARCHAR(100) NOT NULL,
    description TEXT,
    version INTEGER NOT NULL DEFAULT 1,
    json_schema JSONB NOT NULL,
    is_active BOOLEAN NOT NULL DEFAULT true,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    UNIQUE (oracle_id, slug, version)
);

CREATE INDEX idx_object_definitions_oracle ON object_definitions(oracle_id);
CREATE INDEX idx_object_definitions_active ON object_definitions(is_active) WHERE is_active = true;
```

#### Depend√™ncias
- **RF001 completo**: Or√°culos devem existir
- **Bibliotecas**: xeipuuv/gojsonschema (valida√ß√£o de JSON Schema)

#### Testes Obrigat√≥rios
- [x] `TestObjectDefinitionCRUD` - CRUD completo
- [x] `TestJSONSchemaGeneration` - Gerar JSON Schema v√°lido
- [x] `TestJSONSchemaValidation` - Validar schemas inv√°lidos
- [x] `TestNestedObjects` - Suporte a objetos aninhados
- [x] `TestArrayFields` - Suporte a arrays
- [x] `TestVersioning` - Versionamento de schemas

**Cobertura M√≠nima**: ‚â•85%

---

### RF003: Upload e Processamento de Documentos
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 1 - Or√°culo (Knowledge Base)
**Complexidade**: Muito Alta
**Story Points**: 38 SP

#### Descri√ß√£o Detalhada
Permitir que administradores fa√ßam upload de documentos para a base de conhecimento de cada Or√°culo. O sistema deve processar automaticamente os documentos atrav√©s de um pipeline RAG:
1. Upload (local disk ou S3)
2. Text extraction (PDF, DOCX, TXT, etc)
3. Chunking (semantic, fixed-size, recursive)
4. Embedding generation (OpenAI ada-002, 1536 dimensions)
5. Vector indexing (pgvector)
6. Graph extraction (NebulaGraph - entidades e rela√ß√µes)

#### User Stories
1. **Como administrador, quero fazer upload de documentos** para alimentar a base de conhecimento
2. **Como administrador, quero visualizar progresso do processamento** em tempo real
3. **Como administrador, quero listar documentos de um Or√°culo** para gerenciar a base
4. **Como administrador, quero reprocessar um documento** quando o pipeline for atualizado
5. **Como administrador, quero deletar um documento** e seus chunks/embeddings

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] Suporte a 30+ formatos: PDF, DOCX, XLSX, PPTX, TXT, MD, HTML, CSV, JSON, XML, MP3, MP4, etc
- [x] Drag-and-drop upload (multi-file)
- [x] Upload via URL (import from web)
- [x] Max file size: 100MB por arquivo
- [x] Batch upload (at√© 50 arquivos simult√¢neos)
- [x] Pipeline ass√≠ncrono (Celery ou Go channels)
- [x] Progress tracking (WebSocket real-time updates)

**Pipeline RAG**:
- [x] **Stage 1 - Upload**: Salvar arquivo em storage (0-20% progress)
- [x] **Stage 2 - Text Extraction**: Extrair texto do documento (20-40%)
  - PDF: PyPDF2 + pdfminer.six
  - DOCX: python-docx
  - Audio: Whisper API
  - Video: Whisper API (extract audio first)
- [x] **Stage 3 - Chunking**: Dividir texto em chunks (40-60%)
  - Strategy: Semantic chunking (LangChain RecursiveCharacterTextSplitter)
  - Chunk size: 1000 chars, overlap: 200 chars
- [x] **Stage 4 - Embedding**: Gerar embeddings (60-90%)
  - Model: OpenAI text-embedding-ada-002 (1536 dimensions)
  - Batch size: 100 chunks/request
- [x] **Stage 5 - Indexing**: Salvar no pgvector (90-100%)
  - Store: chunks + embeddings + metadata
  - Index: IVFFlat (faster than exact search, 99% recall)

**Performance**:
- [x] Upload <5s (10MB file)
- [x] Processing: 1 page/second (PDF)
- [x] Embedding: 100 chunks/second (OpenAI API)
- [x] Total pipeline: <2 min (100-page PDF)

**Seguran√ßa**:
- [x] Virus scan (ClamAV)
- [x] Content-Type validation (magic bytes, n√£o apenas extens√£o)
- [x] Isolamento por Or√°culo (documentos n√£o compartilhados)

**UX/UI**:
- [x] Drag-and-drop zone (react-dropzone)
- [x] Upload queue com progress bars
- [x] Real-time status updates (WebSocket)
- [x] Document list table (sortable, searchable)
- [x] Preview de documentos (PDF viewer)

#### Implementa√ß√£o T√©cnica

**Backend (Python + FastAPI)**:
```python
# api/documents.py
from fastapi import UploadFile, Depends
from temporalio.client import Client as TemporalClient
import aiofiles
import uuid

@router.post("/oracles/{oracle_id}/documents/upload")
async def upload_document(
    oracle_id: UUID,
    file: UploadFile,
    db: Session = Depends(get_db),
    temporal_client: TemporalClient = Depends(get_temporal_client)
):
    # Validate file
    if file.size > 100 * 1024 * 1024:  # 100MB
        raise HTTPException(400, "File too large")

    # Save to storage
    file_path = f"/storage/{oracle_id}/{file.filename}"
    async with aiofiles.open(file_path, 'wb') as f:
        content = await file.read()
        await f.write(content)

    # Create document record
    document = Document(
        oracle_id=oracle_id,
        filename=file.filename,
        file_path=file_path,
        file_size=file.size,
        mime_type=file.content_type,
        status="uploaded"
    )
    db.add(document)
    db.commit()

    # Start Temporal Workflow (long-running, durable document processing)
    workflow_id = f"process-document-{document.id}"

    await temporal_client.start_workflow(
        "ProcessDocumentWorkflow",
        ProcessDocumentRequest(
            document_id=document.id,
            oracle_id=oracle_id,
            file_path=file_path,
            mime_type=file.content_type
        ),
        id=workflow_id,
        task_queue="global-ai",  # Python workers (RAG processing)
        execution_timeout=timedelta(minutes=30),  # Long-running (large docs)
    )

    return {
        "id": document.id,
        "status": "processing",
        "workflow_id": workflow_id
    }

# Temporal Workflow Implementation (Python SDK)
# File: workflows/process_document_workflow.py
from temporalio import workflow
from temporalio.common import RetryPolicy
from datetime import timedelta
from dataclasses import dataclass

@dataclass
class ProcessDocumentRequest:
    document_id: str
    oracle_id: str
    file_path: str
    mime_type: str

@dataclass
class ProcessDocumentResult:
    chunk_count: int
    status: str
    error_message: str = None

@workflow.defn
class ProcessDocumentWorkflow:
    """
    Long-running workflow for document processing (RAG pipeline).
    Survives worker crashes, supports progress tracking via queries.
    """

    def __init__(self):
        self._progress = 0
        self._status = "initializing"
        self._chunk_count = 0

    @workflow.run
    async def run(self, req: ProcessDocumentRequest) -> ProcessDocumentResult:
        logger = workflow.logger
        logger.info(f"Starting ProcessDocument workflow for doc {req.document_id}")

        # Activity options with retry policy
        activity_options = workflow.ActivityOptions(
            start_to_close_timeout=timedelta(minutes=5),
            retry_policy=RetryPolicy(
                maximum_attempts=3,
                initial_interval=timedelta(seconds=1),
                maximum_interval=timedelta(seconds=10),
            ),
        )
        ctx = workflow.with_activity_options(activity_options)

        try:
            # Activity 1: Extract text from document (PDF, DOCX, etc)
            self._update_progress(20, "extracting")
            text = await workflow.execute_activity(
                "extract_text",
                args=[req.file_path, req.mime_type],
                activity_options=ctx,
            )
            logger.info(f"Text extracted: {len(text)} chars")

            # Activity 2: Chunk text (semantic chunking)
            self._update_progress(40, "chunking")
            chunks = await workflow.execute_activity(
                "chunk_text",
                args=[text],
                activity_options=ctx,
            )
            self._chunk_count = len(chunks)
            logger.info(f"Text chunked: {len(chunks)} chunks")

            # Activity 3: Generate embeddings (batch processing)
            self._update_progress(60, "embedding")

            # Long-running activity for embedding generation (30 min timeout)
            embedding_options = workflow.ActivityOptions(
                start_to_close_timeout=timedelta(minutes=30),
                heartbeat_timeout=timedelta(minutes=5),  # Progress heartbeats
                retry_policy=RetryPolicy(maximum_attempts=2),
            )

            await workflow.execute_activity(
                "generate_embeddings",
                args=[req.document_id, chunks],
                activity_options=embedding_options,
            )
            logger.info(f"Embeddings generated for {len(chunks)} chunks")

            # Activity 4: Create vector index (pgvector IVFFlat)
            self._update_progress(90, "indexing")
            await workflow.execute_activity(
                "create_vector_index",
                args=[req.document_id],
                activity_options=ctx,
            )

            # Activity 5: Finalize document status
            self._update_progress(100, "completed")
            await workflow.execute_activity(
                "finalize_document",
                args=[req.document_id, len(chunks)],
                activity_options=ctx,
            )

            logger.info(f"Document processing completed: {req.document_id}")
            return ProcessDocumentResult(
                chunk_count=len(chunks),
                status="completed"
            )

        except Exception as e:
            logger.error(f"Document processing failed: {e}")
            self._update_progress(0, "failed")

            # Compensation: Update document status to failed
            await workflow.execute_activity(
                "mark_document_failed",
                args=[req.document_id, str(e)],
                activity_options=ctx,
            )

            return ProcessDocumentResult(
                chunk_count=0,
                status="failed",
                error_message=str(e)
            )

    def _update_progress(self, progress: int, status: str):
        """Internal method to update workflow state (queryable via Temporal)"""
        self._progress = progress
        self._status = status

    @workflow.query
    def get_progress(self) -> dict:
        """Query to check current progress (non-blocking)"""
        return {
            "progress": self._progress,
            "status": self._status,
            "chunk_count": self._chunk_count
        }

# Activities Implementation (Python)
# File: activities/document_activities.py
from temporalio import activity
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings import OpenAIEmbeddings
from typing import List
import PyPDF2
from docx import Document as DocxDocument

@activity.defn
async def extract_text(file_path: str, mime_type: str) -> str:
    """Extract text from PDF, DOCX, TXT, MD, etc"""

    if mime_type == "application/pdf":
        # Extract from PDF
        with open(file_path, 'rb') as f:
            reader = PyPDF2.PdfReader(f)
            text = ""
            for page in reader.pages:
                text += page.extract_text()
        return text

    elif mime_type == "application/vnd.openxmlformats-officedocument.wordprocessingml.document":
        # Extract from DOCX
        doc = DocxDocument(file_path)
        text = "\n".join([p.text for p in doc.paragraphs])
        return text

    elif mime_type in ["text/plain", "text/markdown"]:
        # Extract from TXT/MD
        with open(file_path, 'r') as f:
            return f.read()

    else:
        raise ValueError(f"Unsupported mime type: {mime_type}")

@activity.defn
async def chunk_text(text: str) -> List[str]:
    """Chunk text using LangChain RecursiveCharacterTextSplitter"""

    splitter = RecursiveCharacterTextSplitter(
        chunk_size=1000,
        chunk_overlap=200,
        separators=["\n\n", "\n", ".", " ", ""]
    )

    chunks = splitter.split_text(text)
    return chunks

@activity.defn
async def generate_embeddings(document_id: str, chunks: List[str]):
    """Generate embeddings for all chunks (batch processing, long-running)"""

    embeddings_model = OpenAIEmbeddings(model="text-embedding-ada-002")

    # Process in batches of 100 (OpenAI API limit)
    batch_size = 100
    for i in range(0, len(chunks), batch_size):
        batch = chunks[i:i+batch_size]

        # Generate embeddings for batch
        embeddings = embeddings_model.embed_documents(batch)

        # Save to database
        for j, (chunk, embedding) in enumerate(zip(batch, embeddings)):
            chunk_index = i + j

            db.execute("""
                INSERT INTO document_chunks (document_id, chunk_index, content, embedding)
                VALUES (:doc_id, :idx, :content, :embedding)
            """, {
                "doc_id": document_id,
                "idx": chunk_index,
                "content": chunk,
                "embedding": embedding
            })

        # Report heartbeat to Temporal (prevent timeout)
        activity.heartbeat(f"Processed {i+len(batch)}/{len(chunks)} chunks")

@activity.defn
async def create_vector_index(document_id: str):
    """Create pgvector IVFFlat index for fast similarity search"""

    db.execute("""
        CREATE INDEX IF NOT EXISTS idx_chunks_embedding
        ON document_chunks
        USING ivfflat (embedding vector_cosine_ops)
        WITH (lists = 100)
    """)

@activity.defn
async def finalize_document(document_id: str, chunk_count: int):
    """Update document status to completed"""

    db.execute("""
        UPDATE documents
        SET status = 'completed', chunk_count = :chunk_count
        WHERE id = :doc_id
    """, {"doc_id": document_id, "chunk_count": chunk_count})

@activity.defn
async def mark_document_failed(document_id: str, error_message: str):
    """Update document status to failed (compensation)"""

    db.execute("""
        UPDATE documents
        SET status = 'failed', error_message = :error
        WHERE id = :doc_id
    """, {"doc_id": document_id, "error": error_message})

# Frontend can query progress via Temporal Client
# Example: client.get_workflow_handle(workflow_id).query("get_progress")
```

**Database (PostgreSQL + pgvector)**:
```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

CREATE TABLE documents (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    oracle_id UUID NOT NULL REFERENCES oracles(id) ON DELETE CASCADE,
    filename VARCHAR(255) NOT NULL,
    file_path TEXT NOT NULL,
    file_size BIGINT NOT NULL,
    mime_type VARCHAR(100),
    status VARCHAR(20) NOT NULL DEFAULT 'uploaded'
        CHECK (status IN ('uploaded', 'processing', 'completed', 'failed')),
    chunk_count INTEGER DEFAULT 0,
    error_message TEXT,
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW()
);

CREATE TABLE document_chunks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    document_id UUID NOT NULL REFERENCES documents(id) ON DELETE CASCADE,
    chunk_index INTEGER NOT NULL,
    content TEXT NOT NULL,
    embedding vector(1536), -- OpenAI ada-002 dimensions
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    UNIQUE (document_id, chunk_index)
);

-- IVFFlat index for fast similarity search (99% recall, 10√ó faster than exact)
CREATE INDEX idx_chunks_embedding
ON document_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

#### Depend√™ncias
- **RF001 completo**: Or√°culos devem existir
- **Bibliotecas Python**: PyPDF2, python-docx, openai, langchain, pgvector
- **Servi√ßos**: OpenAI API (embeddings), ClamAV (virus scan)

#### Testes Obrigat√≥rios
- [x] `TestDocumentUpload` - Upload de arquivo
- [x] `TestDocumentProcessing` - Pipeline completo
- [x] `TestTextExtraction` - Extra√ß√£o de texto (PDF, DOCX)
- [x] `TestChunking` - Chunking sem√¢ntico
- [x] `TestEmbeddingGeneration` - Embeddings OpenAI
- [x] `TestVectorIndexing` - pgvector IVFFlat
- [x] `TestProgressTracking` - WebSocket updates

**Cobertura M√≠nima**: ‚â•80%

---

### RF004: Chat IA Assistant (RAG Trimodal)
**Prioridade**: P0 (Cr√≠tico)
**Camada**: Camada 3 - Agentes (IA Assistant)
**Complexidade**: Muito Alta
**Story Points**: 46 SP

#### Descri√ß√£o Detalhada
Implementar um **Chat IA Assistant** para cada Or√°culo, capaz de responder perguntas usando **RAG Trimodal** (SQL + Vector + Graph). O assistente deve:
1. Receber pergunta do usu√°rio
2. Gerar query SQL (consultar dados estruturados em PostgreSQL)
3. Gerar embedding da pergunta (buscar chunks similares em pgvector)
4. Gerar query Cypher (consultar grafo de conhecimento em NebulaGraph)
5. Combinar resultados das 3 fontes
6. Gerar resposta usando LLM (GPT-4 Turbo) com contexto enriquecido
7. Streamer resposta token-by-token via SSE

#### User Stories
1. **Como usu√°rio, quero fazer perguntas ao Or√°culo** para obter insights
2. **Como usu√°rio, quero ver a resposta em tempo real** (streaming)
3. **Como usu√°rio, quero ver as fontes usadas** (cita√ß√µes de documentos)
4. **Como usu√°rio, quero refinar minha pergunta** (follow-up questions)
5. **Como usu√°rio, quero exportar conversas** (JSON, PDF)

#### Crit√©rios de Aceita√ß√£o

**Funcionalidade**:
- [x] RAG Trimodal (SQL + Vector + Graph)
- [x] Streaming de resposta (SSE, token-by-token)
- [x] Cita√ß√µes de fontes (links para documentos)
- [x] Hist√≥rico de conversas (persistido)
- [x] Suporte a follow-up questions (contexto mantido)
- [x] Detec√ß√£o de inten√ß√£o (classificar tipo de pergunta)

**RAG Pipeline**:
- [x] **Step 1 - Intent Detection**: Classificar pergunta (factual, analytical, exploratory)
- [x] **Step 2 - SQL Query Generation**: Gerar SQL se pergunta envolve dados estruturados
- [x] **Step 3 - Vector Search**: Buscar top-5 chunks mais similares (cosine similarity)
- [x] **Step 4 - Graph Query**: Gerar Cypher se pergunta envolve rela√ß√µes/entidades
- [x] **Step 5 - Context Assembly**: Combinar resultados em um contexto √∫nico
- [x] **Step 6 - LLM Generation**: Gerar resposta usando GPT-4 Turbo
- [x] **Step 7 - Stream Response**: Enviar tokens via SSE

**Performance**:
- [x] Lat√™ncia total (p95): <3s (sem streaming)
- [x] Time to First Token (TTFT): <500ms
- [x] Streaming: 30-50 tokens/segundo
- [x] Vector search: <100ms
- [x] SQL query: <200ms
- [x] Graph query: <300ms

**Seguran√ßa**:
- [x] Isolamento por Or√°culo (usu√°rio s√≥ acessa seu Or√°culo)
- [x] Rate limiting (10 perguntas/minuto por usu√°rio)
- [x] Input sanitization (evitar SQL injection, prompt injection)

**UX/UI**:
- [x] Chat interface (mensagens do usu√°rio + IA)
- [x] Typing indicator (IA est√° pensando)
- [x] Streaming visual (tokens aparecem progressivamente)
- [x] Cita√ß√µes clic√°veis (abrem documento fonte)
- [x] Feedback (üëç üëé para melhorar respostas)

#### Implementa√ß√£o T√©cnica

**Backend (Python + FastAPI)**:
```python
# api/chat.py
from fastapi import APIRouter
from sse_starlette.sse import EventSourceResponse

router = APIRouter()

@router.post("/oracles/{oracle_id}/chat/stream")
async def chat_stream(oracle_id: UUID, message: str, conversation_id: UUID = None):
    """Stream chat response using Server-Sent Events"""

    async def event_generator():
        try:
            # Step 1: Intent detection
            intent = await detect_intent(message)
            yield {"event": "intent", "data": intent}

            # Step 2: SQL query (if needed)
            sql_results = None
            if intent in ["factual", "analytical"]:
                sql_query = await generate_sql_query(oracle_id, message)
                sql_results = await execute_sql_query(sql_query)
                yield {"event": "sql", "data": {"query": sql_query, "results": sql_results}}

            # Step 3: Vector search
            embedding = await generate_embedding(message)
            chunks = await vector_search(oracle_id, embedding, top_k=5)
            yield {"event": "chunks", "data": chunks}

            # Step 4: Graph query (if needed)
            graph_results = None
            if intent == "exploratory":
                cypher_query = await generate_cypher_query(oracle_id, message)
                graph_results = await execute_cypher_query(cypher_query)
                yield {"event": "graph", "data": {"query": cypher_query, "results": graph_results}}

            # Step 5: Assemble context
            context = assemble_context(sql_results, chunks, graph_results)

            # Step 6: Stream LLM response
            async for token in stream_llm_response(message, context):
                yield {"event": "token", "data": token}

            yield {"event": "done", "data": ""}

        except Exception as e:
            yield {"event": "error", "data": str(e)}

    return EventSourceResponse(event_generator())

# services/rag_pipeline.py
import openai
from pgvector.psycopg2 import register_vector

async def vector_search(oracle_id: UUID, embedding: list[float], top_k: int = 5):
    """Search for similar chunks using pgvector cosine similarity"""

    query = """
        SELECT
            dc.id,
            dc.content,
            d.filename,
            1 - (dc.embedding <=> :embedding::vector) AS similarity
        FROM document_chunks dc
        JOIN documents d ON d.id = dc.document_id
        WHERE d.oracle_id = :oracle_id
        ORDER BY dc.embedding <=> :embedding::vector
        LIMIT :top_k
    """

    results = await db.execute(query, {
        "oracle_id": oracle_id,
        "embedding": embedding,
        "top_k": top_k
    })

    return [
        {
            "id": row.id,
            "content": row.content,
            "source": row.filename,
            "similarity": row.similarity
        }
        for row in results
    ]

async def stream_llm_response(message: str, context: str):
    """Stream GPT-4 Turbo response token-by-token"""

    system_prompt = f"""Voc√™ √© um assistente IA especializado.
    Use o contexto abaixo para responder a pergunta do usu√°rio.
    Se n√£o souber a resposta, diga que n√£o sabe.

    Contexto:
    {context}
    """

    response = await openai.ChatCompletion.acreate(
        model="gpt-4-turbo",
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": message}
        ],
        temperature=0.7,
        max_tokens=2000,
        stream=True
    )

    async for chunk in response:
        if chunk.choices[0].delta.content:
            yield chunk.choices[0].delta.content
```

**Frontend (Next.js + SSE)**:
```typescript
// hooks/useChat.ts
import { useEffect, useState } from 'react'

export function useChat(oracleId: string) {
  const [messages, setMessages] = useState<Message[]>([])
  const [isStreaming, setIsStreaming] = useState(false)

  const sendMessage = async (content: string) => {
    // Add user message
    const userMessage = { role: 'user', content, timestamp: new Date() }
    setMessages(prev => [...prev, userMessage])

    // Start streaming
    setIsStreaming(true)
    const aiMessage: Message = { role: 'assistant', content: '', timestamp: new Date() }
    setMessages(prev => [...prev, aiMessage])

    const eventSource = new EventSource(
      `/api/v1/oracles/${oracleId}/chat/stream?message=${encodeURIComponent(content)}`
    )

    eventSource.addEventListener('token', (e) => {
      const token = JSON.parse(e.data)
      setMessages(prev => {
        const updated = [...prev]
        updated[updated.length - 1].content += token
        return updated
      })
    })

    eventSource.addEventListener('done', () => {
      setIsStreaming(false)
      eventSource.close()
    })

    eventSource.addEventListener('error', (e) => {
      console.error('SSE error:', e)
      setIsStreaming(false)
      eventSource.close()
    })
  }

  return { messages, sendMessage, isStreaming }
}
```

#### Depend√™ncias
- **RF001, RF002, RF003 completos**: Or√°culos, Object Definitions, Documentos
- **Bibliotecas Python**: openai, langchain, pgvector, nebula3-python
- **Servi√ßos**: OpenAI API (GPT-4 Turbo, embeddings), NebulaGraph

#### Testes Obrigat√≥rios
- [x] `TestIntentDetection` - Classificar tipo de pergunta
- [x] `TestVectorSearch` - Buscar chunks similares
- [x] `TestSQLGeneration` - Gerar SQL v√°lido
- [x] `TestCypherGeneration` - Gerar Cypher v√°lido
- [x] `TestContextAssembly` - Combinar resultados
- [x] `TestStreamingResponse` - SSE streaming
- [x] `TestCitations` - Rastrear fontes usadas

**Cobertura M√≠nima**: ‚â•80%

---

## üìä Matriz de Rastreabilidade

| Requisito | User Stories | Mockups | Sprints | Epics | Prioridade |
|-----------|-------------|---------|---------|-------|------------|
| RF001 | 6 stories | 01, 02, 03, 04 | 2, 3 | 1.1, 1.3 | P0 |
| RF002 | 6 stories | (future) | 4 | 1.4 | P0 |
| RF003 | 5 stories | 05 | 3 | 1.5 | P0 |
| RF004 | 5 stories | 07 | 4 | 1.6 | P0 |

---

## üéØ Fora de Escopo (Fase 1)

‚ùå **N√£o implementar na Fase 1**:
- Agentes aut√¥nomos (CrewAI, LangChain Agents) ‚Üí Fase 2
- Workflows automatizados ‚Üí Fase 2
- MCP servers ‚Üí Fase 2
- NebulaGraph (Graph DB) ‚Üí Fase 3 (apenas vector search na Fase 1)
- Escalabilidade horizontal ‚Üí Fase 4
- Multi-tenancy ‚Üí Fase 4
- Observability avan√ßada ‚Üí Fase 4

---

## üìÖ Cronograma

| Sprint | Dura√ß√£o | Requisitos | Story Points |
|--------|---------|------------|--------------|
| Sprint 1 | 1 semana | Setup & Foundation | 24 SP |
| Sprint 2 | 2 semanas | RF001 (Or√°culos) | 34 SP |
| Sprint 3 | 2 semanas | RF003 (Documentos) | 38 SP |
| Sprint 4 | 2 semanas | RF002 + RF004 | 42 + 46 = 88 SP |
| Sprint 5 | 1 semana | Frontend Implementation | 46 SP |
| Sprint 6 | 1 semana | Testing & Deployment | 30 SP |

**Total**: 10 semanas (2.5 meses)

---

## ‚úÖ Crit√©rios de Aceita√ß√£o da Fase 1

**Para considerar a Fase 1 COMPLETA**, todos os seguintes crit√©rios devem ser atendidos:

### Funcionalidades
- [x] CRUD completo de Or√°culos (RF001)
- [x] CRUD completo de Object Definitions (RF002)
- [x] Upload e processamento de documentos (RF003)
- [x] Chat IA Assistant com RAG (RF004)
- [x] 7 p√°ginas de UI funcionais (mockups 01-07)

### Qualidade
- [x] Cobertura de testes ‚â•80%
- [x] 0 vulnerabilidades HIGH/CRITICAL
- [x] Performance: API p95 <500ms, Chat TTFT <500ms
- [x] Disponibilidade: 99% uptime

### Documenta√ß√£o
- [x] README completo
- [x] API documentation (OpenAPI/Swagger)
- [x] Deployment guide
- [x] User manual (b√°sico)

### Deploy
- [x] Ambiente QA funcional
- [x] Ambiente Staging funcional
- [x] CI/CD pipeline funcionando

---

## üìö Refer√™ncias

- [requisitos_funcionais_v2.0.md](../../../documentation-base/requisitos_funcionais_v2.0.md)
- [arquitetura_supercore_v2.0.md](../../../documentation-base/arquitetura_supercore_v2.0.md)
- [stack_supercore_v2.0.md](../../../documentation-base/stack_supercore_v2.0.md)
- [BACKLOG_FASE_1.md](../BACKLOG_FASE_1.md)
- [SPRINTS_FASE_1.md](../SPRINTS_FASE_1.md)

---

**Vers√£o**: 1.0.0
**Data**: 2025-12-28
**Autor**: Squad Produto (Product Owner + Business Analyst)
**Aprovado por**: Tech Lead (pendente)
