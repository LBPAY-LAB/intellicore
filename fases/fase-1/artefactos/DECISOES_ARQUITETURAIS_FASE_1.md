# ğŸ—ï¸ DecisÃµes Arquiteturais - Fase 1: FundaÃ§Ã£o

**Projeto**: SuperCore v2.0
**Fase**: Fase 1 - FundaÃ§Ã£o (Q1 2025)
**Data**: 2025-12-28
**VersÃ£o**: 1.0.0

---

## ğŸ“‹ Ãndice de ADRs

1. [ADR-001: Escolha de PostgreSQL com pgvector para Vector Search](#adr-001-escolha-de-postgresql-com-pgvector-para-vector-search)
2. [ADR-002: Go para CRUD e Python para IA/RAG](#adr-002-go-para-crud-e-python-para-iarag)
3. [ADR-003: SSE (Server-Sent Events) para Chat Streaming](#adr-003-sse-server-sent-events-para-chat-streaming)
4. [ADR-004: JSON Schema para Object Definitions](#adr-004-json-schema-para-object-definitions)
5. [ADR-005: IVFFlat Index Strategy para pgvector](#adr-005-ivfflat-index-strategy-para-pgvector)
6. [ADR-006: Soft Delete para OrÃ¡culos e Documentos](#adr-006-soft-delete-para-orÃ¡culos-e-documentos)
7. [ADR-007: WebSocket para Document Processing Updates](#adr-007-websocket-para-document-processing-updates)

---

## ADR-001: Escolha de PostgreSQL com pgvector para Vector Search

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Tech Lead, Architecture Owner

### Contexto
A Fase 1 requer capacidade de **vector search** para o pipeline RAG (buscar documentos similares usando embeddings). As opÃ§Ãµes consideradas foram:
- **OpÃ§Ã£o A**: Database dedicado de vetores (Qdrant, Weaviate, Pinecone)
- **OpÃ§Ã£o B**: PostgreSQL com extensÃ£o pgvector
- **OpÃ§Ã£o C**: Elasticsearch com dense_vector

### DecisÃ£o
**Escolhemos PostgreSQL com pgvector (OpÃ§Ã£o B)**

### Justificativa

#### Vantagens da OpÃ§Ã£o B (pgvector):
1. **Simplicidade Operacional** (ğŸ”¥ Mais importante):
   - 1 database em vez de 2 (PostgreSQL jÃ¡ usado para dados estruturados)
   - Menos complexidade de deployment
   - Menos custos de infraestrutura (1 instÃ¢ncia em vez de 2)

2. **TransaÃ§Ãµes ACID**:
   - Vetores e metadados na mesma transaÃ§Ã£o
   - ConsistÃªncia garantida entre chunks e embeddings
   - Rollback atÃ´mico em caso de erro

3. **Queries HÃ­bridas**:
   - Combinar vector search + SQL filters em 1 query
   - Exemplo: "Buscar documentos similares AND criados nos Ãºltimos 30 dias"
   - Performance melhor que JOIN entre 2 databases

4. **Custo**:
   - Sem licenÃ§as adicionais (pgvector Ã© open source)
   - AWS RDS PostgreSQL jÃ¡ suporta pgvector nativamente

5. **Maturidade**:
   - PostgreSQL: 25+ anos de maturidade
   - pgvector: 50k+ stars no GitHub, 1M+ downloads/mÃªs
   - Usado por OpenAI, Supabase, Notion

#### Desvantagens Conhecidas:
- Performance inferior a databases dedicados (Qdrant, Weaviate) em escala >10M vetores
- Falta de features avanÃ§adas (filtered vector search, multi-vector queries)

**MitigaÃ§Ã£o**:
- Fase 1 terÃ¡ <100k vetores (escala pequena, performance nÃ£o crÃ­tica)
- Se precisar escalar na Fase 3/4, migrar para Qdrant (dados jÃ¡ estruturados em PostgreSQL)

#### Alternativas Rejeitadas:

**OpÃ§Ã£o A (Qdrant)**: Melhor performance, mas:
- Adiciona complexidade operacional (2 databases)
- Falta de transaÃ§Ãµes ACID entre PostgreSQL e Qdrant
- Custo adicional de infraestrutura
- Overkill para Fase 1 (<100k vetores)

**OpÃ§Ã£o C (Elasticsearch)**: Boa opÃ§Ã£o, mas:
- Complexidade de deployment (JVM, heap tuning)
- Custo elevado (memÃ³ria intensiva)
- Menos maduro para vector search (feature recente)

### ConsequÃªncias

#### Positivas:
- âœ… Setup mais simples (1 comando: `CREATE EXTENSION vector`)
- âœ… Queries hÃ­bridas SQL + Vector em 1 linha
- âœ… Backup unificado (PostgreSQL + vetores)
- âœ… Menos custos de infra

#### Negativas:
- âŒ Performance limitada em >10M vetores (p95 search latency >500ms)
- âŒ Falta de features avanÃ§adas (filtered vector search)

#### Neutras:
- âš ï¸ PossÃ­vel migraÃ§Ã£o futura para Qdrant (Fase 3/4)

### ImplementaÃ§Ã£o

```sql
-- Enable pgvector extension
CREATE EXTENSION IF NOT EXISTS vector;

-- Create table with vector column
CREATE TABLE document_chunks (
    id UUID PRIMARY KEY,
    document_id UUID REFERENCES documents(id),
    content TEXT,
    embedding vector(1536), -- OpenAI ada-002 dimensions
    created_at TIMESTAMP DEFAULT NOW()
);

-- Create IVFFlat index (see ADR-005)
CREATE INDEX idx_chunks_embedding
ON document_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- Vector similarity search query
SELECT
    id,
    content,
    1 - (embedding <=> :query_embedding::vector) AS similarity
FROM document_chunks
WHERE 1 - (embedding <=> :query_embedding::vector) > 0.7 -- threshold
ORDER BY embedding <=> :query_embedding::vector
LIMIT 5;
```

### ReferÃªncias
- [pgvector GitHub](https://github.com/pgvector/pgvector)
- [stack_supercore_v2.0.md - SeÃ§Ã£o PostgreSQL](../../../documentation-base/stack_supercore_v2.0.md#postgresql-16)
- [RAG_PIPELINE_ARCHITECTURE.md](../../../documentation-base/RAG_PIPELINE_ARCHITECTURE.md)

---

## ADR-002: Go para CRUD e Python para IA/RAG

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Tech Lead, Backend Lead

### Contexto
O SuperCore v2.0 requer 2 tipos de workloads:
1. **CRUD operations**: APIs para OrÃ¡culos, Object Definitions, Documentos (estruturadas, sÃ­ncronas)
2. **IA/RAG processing**: Embeddings, LLM calls, chunking, vector search (computaÃ§Ã£o intensiva, assÃ­ncrona)

OpÃ§Ãµes consideradas:
- **OpÃ§Ã£o A**: Tudo em Go (monolÃ­tico)
- **OpÃ§Ã£o B**: Tudo em Python (monolÃ­tico)
- **OpÃ§Ã£o C**: Go para CRUD + Python para IA/RAG (hÃ­brido)

### DecisÃ£o
**Escolhemos Go para CRUD + Python para IA/RAG (OpÃ§Ã£o C)**

### Justificativa

#### Vantagens de Go (para CRUD):
1. **Performance**:
   - 10-20Ã— mais rÃ¡pido que Python em APIs sÃ­ncronas
   - Baixa latÃªncia (<50ms p95 para CRUD)
   - Baixo consumo de memÃ³ria (10-50 MB por serviÃ§o)

2. **ConcorrÃªncia**:
   - Goroutines nativas (lightweight threads)
   - Excelente para APIs com muitas conexÃµes simultÃ¢neas

3. **Deployment**:
   - Binary Ãºnico (sem dependÃªncias externas)
   - Startup rÃ¡pido (<1s)
   - FÃ¡cil de containerizar (Docker image <20MB)

4. **Type Safety**:
   - Compilado, detecta erros em build time
   - Refactoring mais seguro

#### Vantagens de Python (para IA/RAG):
1. **Ecossistema IA/ML** (ğŸ”¥ Mais importante):
   - LangChain, OpenAI SDK, Hugging Face
   - 90% das bibliotecas de ML sÃ£o Python-first
   - Exemplos e documentaÃ§Ã£o abundantes

2. **Prototipagem RÃ¡pida**:
   - IteraÃ§Ã£o rÃ¡pida em pipelines RAG
   - Notebooks (Jupyter) para experimentaÃ§Ã£o

3. **AssÃ­ncrono**:
   - AsyncIO para I/O-bound tasks (API calls, embeddings)
   - Celery para background jobs

#### Por que NÃƒO monolÃ­tico (OpÃ§Ãµes A e B)?

**OpÃ§Ã£o A (Tudo em Go)**: Ruim porque:
- Falta de bibliotecas de IA/ML (Go ML ecosystem Ã© imaturo)
- DifÃ­cil integrar OpenAI, LangChain, Hugging Face
- Menos exemplos e documentaÃ§Ã£o

**OpÃ§Ã£o B (Tudo em Python)**: Ruim porque:
- Performance inferior em CRUD (10-20Ã— mais lento que Go)
- Alto consumo de memÃ³ria (100-300 MB por worker)
- Startup lento (>5s)
- Deployment mais complexo (dependÃªncias, virtualenv)

### Arquitetura de IntegraÃ§Ã£o

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ API Gateway (Nginx / Traefik)                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                       â”‚
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Go Service     â”‚    â”‚ Python Service   â”‚
         â”‚  (Port 8080)    â”‚    â”‚ (Port 8000)      â”‚
         â”‚                 â”‚    â”‚                  â”‚
         â”‚ - CRUD OrÃ¡culos â”‚    â”‚ - Document       â”‚
         â”‚ - CRUD Obj Defs â”‚    â”‚   Processing     â”‚
         â”‚ - User Auth     â”‚    â”‚ - Embeddings     â”‚
         â”‚ - Metrics       â”‚    â”‚ - Vector Search  â”‚
         â”‚                 â”‚    â”‚ - LLM Calls      â”‚
         â”‚ Framework: Gin  â”‚    â”‚ Framework:       â”‚
         â”‚                 â”‚    â”‚   FastAPI        â”‚
         â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”‚                      â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â”‚
                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                  â”‚ PostgreSQL 16       â”‚
                  â”‚ + pgvector 0.5.1    â”‚
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ComunicaÃ§Ã£o entre serviÃ§os**:
- Go â†’ Python: HTTP REST (sÃ­ncronas) ou Redis Pub/Sub (assÃ­ncronas)
- Python â†’ Go: NÃ£o necessÃ¡rio (Python nÃ£o chama Go)

### ConsequÃªncias

#### Positivas:
- âœ… Melhor performance para CRUD (Go)
- âœ… Melhor DX para IA/RAG (Python)
- âœ… Cada serviÃ§o otimizado para seu workload
- âœ… Escalabilidade independente (Go e Python podem escalar separadamente)

#### Negativas:
- âŒ 2 linguagens para manter (Go + Python)
- âŒ 2 stacks para gerenciar (Gin + FastAPI)
- âŒ Complexidade de deployment (2 serviÃ§os)

#### Neutras:
- âš ï¸ NecessÃ¡rio padronizar APIs (OpenAPI spec compartilhada)
- âš ï¸ NecessÃ¡rio monitoramento unificado (mÃ©tricas de ambos serviÃ§os)

### ImplementaÃ§Ã£o

**Go Service** (CRUD):
```go
// main.go
package main

import (
    "github.com/gin-gonic/gin"
)

func main() {
    r := gin.Default()

    // Oracles CRUD
    r.GET("/api/v1/oracles", ListOracles)
    r.POST("/api/v1/oracles", CreateOracle)
    r.GET("/api/v1/oracles/:id", GetOracle)
    r.PUT("/api/v1/oracles/:id", UpdateOracle)
    r.DELETE("/api/v1/oracles/:id", DeleteOracle)

    r.Run(":8080")
}
```

**Python Service** (IA/RAG):
```python
# main.py
from fastapi import FastAPI
from services.document_processor import process_document
from services.rag_pipeline import chat_stream

app = FastAPI()

@app.post("/api/v1/documents/process")
async def process_document_endpoint(document_id: str):
    await process_document(document_id)
    return {"status": "processing"}

@app.post("/api/v1/chat/stream")
async def chat_endpoint(oracle_id: str, message: str):
    return EventSourceResponse(chat_stream(oracle_id, message))
```

### ReferÃªncias
- [stack_supercore_v2.0.md - SeÃ§Ã£o Backend](../../../documentation-base/stack_supercore_v2.0.md#backend)
- [arquitetura_supercore_v2.0.md - ADR-002](../../../documentation-base/arquitetura_supercore_v2.0.md#adr-002)

---

## ADR-003: SSE (Server-Sent Events) para Chat Streaming

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Frontend Lead, Backend Lead

### Contexto
O Chat IA Assistant (RF004) deve streamer respostas token-by-token para melhor UX (usuÃ¡rio vÃª resposta progressivamente, nÃ£o espera 10-30s para resposta completa).

OpÃ§Ãµes consideradas:
- **OpÃ§Ã£o A**: SSE (Server-Sent Events)
- **OpÃ§Ã£o B**: WebSocket
- **OpÃ§Ã£o C**: Long Polling

### DecisÃ£o
**Escolhemos SSE (OpÃ§Ã£o A)**

### Justificativa

#### Vantagens de SSE:
1. **Simplicidade** (ğŸ”¥ Mais importante):
   - HTTP/1.1 puro (nÃ£o requer upgrade de protocolo)
   - Built-in no browser (EventSource API)
   - Menos cÃ³digo do que WebSocket

2. **Unidirecional** (Server â†’ Client):
   - Chat streaming Ã© unidirecional (servidor envia tokens, cliente sÃ³ escuta)
   - NÃ£o precisa de comunicaÃ§Ã£o bidirecional

3. **ReconexÃ£o AutomÃ¡tica**:
   - EventSource API reconecta automaticamente se conexÃ£o cair
   - WebSocket requer implementaÃ§Ã£o manual

4. **Compatibilidade**:
   - Funciona em todos browsers modernos (>95% coverage)
   - Fallback para long polling em IE (polyfill disponÃ­vel)

5. **Debugging**:
   - VisÃ­vel no DevTools Network tab (como HTTP requests)
   - WebSocket requer ferramentas especializadas

#### Desvantagens de WebSocket (OpÃ§Ã£o B):
- Bidirecional (overkill para chat streaming unidirecional)
- Requer upgrade de protocolo (HTTP â†’ WS)
- ReconexÃ£o manual
- Debugging mais difÃ­cil

#### Desvantagens de Long Polling (OpÃ§Ã£o C):
- LatÃªncia alta (mÃºltiplos round-trips)
- Overhead de HTTP headers em cada request
- Ineficiente para streaming contÃ­nuo

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend        â”‚
â”‚ (Next.js)       â”‚
â”‚                 â”‚
â”‚ EventSource API â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ HTTP/1.1 (SSE)
         â”‚ GET /api/v1/chat/stream?message=...
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend          â”‚
â”‚ (FastAPI)        â”‚
â”‚                  â”‚
â”‚ async def        â”‚
â”‚ event_generator()â”‚
â”‚   yield token    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ OpenAI API       â”‚
â”‚ (stream=True)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplementaÃ§Ã£o

**Backend (Python + FastAPI)**:
```python
from fastapi import APIRouter
from sse_starlette.sse import EventSourceResponse
import openai

@router.get("/chat/stream")
async def chat_stream(oracle_id: str, message: str):
    async def event_generator():
        try:
            # Call OpenAI with streaming
            response = await openai.ChatCompletion.acreate(
                model="gpt-4-turbo",
                messages=[{"role": "user", "content": message}],
                stream=True
            )

            # Stream tokens
            async for chunk in response:
                if chunk.choices[0].delta.content:
                    token = chunk.choices[0].delta.content
                    yield {
                        "event": "token",
                        "data": token
                    }

            # Send done event
            yield {"event": "done", "data": ""}

        except Exception as e:
            yield {"event": "error", "data": str(e)}

    return EventSourceResponse(event_generator())
```

**Frontend (Next.js + TypeScript)**:
```typescript
// hooks/useChat.ts
import { useEffect, useState } from 'react'

export function useChat(oracleId: string) {
  const [messages, setMessages] = useState<Message[]>([])
  const [isStreaming, setIsStreaming] = useState(false)

  const sendMessage = async (content: string) => {
    // Add user message
    setMessages(prev => [...prev, { role: 'user', content }])

    // Start SSE streaming
    setIsStreaming(true)
    const aiMessage = { role: 'assistant', content: '' }
    setMessages(prev => [...prev, aiMessage])

    const eventSource = new EventSource(
      `/api/v1/chat/stream?oracle_id=${oracleId}&message=${encodeURIComponent(content)}`
    )

    eventSource.addEventListener('token', (e) => {
      const token = e.data
      setMessages(prev => {
        const updated = [...prev]
        updated[updated.length - 1].content += token
        return updated
      })
    })

    eventSource.addEventListener('done', () => {
      setIsStreaming(false)
      eventSource.close()
    })

    eventSource.addEventListener('error', (e) => {
      console.error('SSE error:', e)
      setIsStreaming(false)
      eventSource.close()
    })
  }

  return { messages, sendMessage, isStreaming }
}
```

### ConsequÃªncias

#### Positivas:
- âœ… ImplementaÃ§Ã£o simples (menos cÃ³digo)
- âœ… ReconexÃ£o automÃ¡tica
- âœ… Debugging fÃ¡cil (DevTools Network tab)
- âœ… Performance boa (latency <100ms por token)

#### Negativas:
- âŒ Apenas unidirecional (Server â†’ Client)
- âŒ HTTP/1.1 limite de 6 conexÃµes simultÃ¢neas por domÃ­nio (mitigado por HTTP/2)

#### Neutras:
- âš ï¸ Se precisar bidirecional no futuro (ex: typing indicator), migrar para WebSocket

### MÃ©tricas de Sucesso
- **Time to First Token (TTFT)**: <500ms
- **Streaming Rate**: 30-50 tokens/segundo
- **Error Rate**: <1% (reconexÃ£o automÃ¡tica reduz falhas)

### ReferÃªncias
- [MDN - Server-Sent Events](https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events)
- [sse-starlette](https://github.com/sysid/sse-starlette)
- [mockup 07_oracles_chat_ia_assistant.md](../ux-ui/mockups/07_oracles_chat_ia_assistant.md)

---

## ADR-004: JSON Schema para Object Definitions

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Tech Lead, Data Modeling Specialist

### Contexto
O SuperCore v2.0 permite que cada OrÃ¡culo defina seus prÃ³prios **Object Definitions** (schemas dinÃ¢micos). Precisamos de um formato padrÃ£o para:
1. Definir estrutura de objetos (campos, tipos, validaÃ§Ãµes)
2. Validar dados em runtime
3. Gerar formulÃ¡rios dinÃ¢micos no frontend

OpÃ§Ãµes consideradas:
- **OpÃ§Ã£o A**: JSON Schema (Draft 2020-12)
- **OpÃ§Ã£o B**: Formato customizado (prÃ³prio)
- **OpÃ§Ã£o C**: Protocol Buffers (protobuf)

### DecisÃ£o
**Escolhemos JSON Schema (OpÃ§Ã£o A)**

### Justificativa

#### Vantagens de JSON Schema:
1. **PadrÃ£o da IndÃºstria** (ğŸ”¥ Mais importante):
   - EspecificaÃ§Ã£o aberta (IETF)
   - Usado por OpenAPI, AWS, Google Cloud
   - 50+ bibliotecas de validaÃ§Ã£o (todas linguagens)

2. **ValidaÃ§Ã£o Built-in**:
   - Tipos: string, number, integer, boolean, array, object
   - ValidaÃ§Ãµes: required, min, max, pattern (regex), enum
   - Nested objects e arrays

3. **Tooling**:
   - Geradores de formulÃ¡rios (react-jsonschema-form)
   - Geradores de TypeScript types (json-schema-to-typescript)
   - Editores visuais (JSON Schema Editor)

4. **Versionamento**:
   - JSON Schema suporta `$schema` e `$id` (versionamento nativo)

5. **Human-Readable**:
   - JSON puro (fÃ¡cil de ler e editar)
   - DocumentaÃ§Ã£o auto-descritiva (description, examples)

#### Desvantagens de OpÃ§Ãµes B e C:

**OpÃ§Ã£o B (Formato customizado)**: Ruim porque:
- Reinventar a roda (JSON Schema jÃ¡ resolve)
- Falta de tooling (precisarÃ­amos construir tudo)
- Falta de validadores prontos

**OpÃ§Ã£o C (Protocol Buffers)**: Ruim porque:
- BinÃ¡rio (nÃ£o human-readable)
- Curva de aprendizado (sintaxe complexa)
- Overkill (protobuf Ã© para serializaÃ§Ã£o de alta performance, nÃ£o para schemas dinÃ¢micos)

### Exemplo de JSON Schema

**Input** (Form Builder no frontend):
```json
{
  "name": "TransaÃ§Ã£o Suspeita",
  "fields": [
    {
      "name": "valor",
      "type": "number",
      "description": "Valor da transaÃ§Ã£o em reais",
      "required": true,
      "validation": {
        "minimum": 0,
        "maximum": 1000000
      }
    },
    {
      "name": "data",
      "type": "string",
      "format": "date-time",
      "description": "Data e hora da transaÃ§Ã£o",
      "required": true
    },
    {
      "name": "motivo",
      "type": "string",
      "description": "Motivo da suspeita",
      "enum": ["valor_alto", "multiplas_transacoes", "destino_suspeito"]
    }
  ]
}
```

**Output** (JSON Schema gerado automaticamente):
```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "$id": "https://supercore.com/schemas/transacao-suspeita/v1",
  "type": "object",
  "title": "TransaÃ§Ã£o Suspeita",
  "description": "Schema para transaÃ§Ãµes suspeitas no OrÃ¡culo de Compliance",
  "properties": {
    "valor": {
      "type": "number",
      "description": "Valor da transaÃ§Ã£o em reais",
      "minimum": 0,
      "maximum": 1000000
    },
    "data": {
      "type": "string",
      "format": "date-time",
      "description": "Data e hora da transaÃ§Ã£o"
    },
    "motivo": {
      "type": "string",
      "description": "Motivo da suspeita",
      "enum": ["valor_alto", "multiplas_transacoes", "destino_suspeito"]
    }
  },
  "required": ["valor", "data"],
  "additionalProperties": false
}
```

### ImplementaÃ§Ã£o

**Backend (Go) - ValidaÃ§Ã£o**:
```go
import "github.com/xeipuuv/gojsonschema"

func ValidateObject(schemaJSON string, dataJSON string) (bool, []string) {
    schemaLoader := gojsonschema.NewStringLoader(schemaJSON)
    dataLoader := gojsonschema.NewStringLoader(dataJSON)

    result, err := gojsonschema.Validate(schemaLoader, dataLoader)
    if err != nil {
        return false, []string{err.Error()}
    }

    if result.Valid() {
        return true, nil
    }

    errors := []string{}
    for _, err := range result.Errors() {
        errors = append(errors, err.String())
    }

    return false, errors
}
```

**Frontend (React) - Form Generation**:
```typescript
import Form from '@rjsf/core'
import validator from '@rjsf/validator-ajv8'

function DynamicForm({ schema, onSubmit }) {
  return (
    <Form
      schema={schema}
      validator={validator}
      onSubmit={(data) => onSubmit(data.formData)}
    />
  )
}
```

### ConsequÃªncias

#### Positivas:
- âœ… PadrÃ£o da indÃºstria (interoperabilidade)
- âœ… Tooling rico (validadores, geradores)
- âœ… ValidaÃ§Ã£o automÃ¡tica (backend + frontend)
- âœ… Versionamento nativo

#### Negativas:
- âŒ Curva de aprendizado (JSON Schema tem 100+ keywords)
- âŒ ValidaÃ§Ãµes complexas requerem custom keywords

#### Neutras:
- âš ï¸ Se precisar validaÃ§Ãµes muito complexas, criar custom validators

### ReferÃªncias
- [JSON Schema Specification](https://json-schema.org/draft/2020-12/json-schema-core.html)
- [xeipuuv/gojsonschema](https://github.com/xeipuuv/gojsonschema)
- [react-jsonschema-form](https://github.com/rjsf-team/react-jsonschema-form)

---

## ADR-005: IVFFlat Index Strategy para pgvector

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Backend Lead, Database Architect

### Contexto
O pgvector suporta 2 tipos de Ã­ndices para vector similarity search:
1. **IVFFlat** (Inverted File with Flat storage): Approximate Nearest Neighbor (ANN)
2. **HNSW** (Hierarchical Navigable Small World): Mais preciso, mas mais lento

Precisamos escolher qual Ã­ndice usar para a Fase 1.

### DecisÃ£o
**Escolhemos IVFFlat**

### Justificativa

#### Vantagens de IVFFlat:
1. **Build Time RÃ¡pido**:
   - IVFFlat: ~10s para 100k vetores
   - HNSW: ~5 min para 100k vetores
   - Fase 1 terÃ¡ <100k vetores (build rÃ¡pido importante para iteraÃ§Ãµes)

2. **Menor Consumo de MemÃ³ria**:
   - IVFFlat: ~200 MB para 100k vetores (1536 dims)
   - HNSW: ~500 MB para 100k vetores

3. **Recall Suficiente**:
   - IVFFlat: 99% recall (com `lists = 100`)
   - HNSW: 99.9% recall
   - DiferenÃ§a de 0.9% nÃ£o Ã© crÃ­tica para Fase 1

4. **Simplicidade**:
   - IVFFlat tem 1 parÃ¢metro: `lists` (nÃºmero de clusters)
   - HNSW tem 2 parÃ¢metros: `m` e `ef_construction` (mais complexo)

#### Quando usar HNSW (Fase 3/4)?
- Datasets grandes (>1M vetores)
- Recall crÃ­tico (>99.5%)
- LatÃªncia de search <10ms (HNSW Ã© 2-3Ã— mais rÃ¡pido)

### ConfiguraÃ§Ã£o

**CriaÃ§Ã£o do Ã­ndice**:
```sql
-- IVFFlat index
CREATE INDEX idx_chunks_embedding
ON document_chunks
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- lists = sqrt(total_rows) Ã© uma boa regra geral
-- Para 10k vetores: lists = 100
-- Para 100k vetores: lists = 316
-- Para 1M vetores: lists = 1000
```

**Query otimizada**:
```sql
-- Set probes (quantos clusters buscar)
SET ivfflat.probes = 10; -- default = 1, aumentar para melhor recall

-- Similarity search
SELECT
    id,
    content,
    1 - (embedding <=> :query_embedding::vector) AS similarity
FROM document_chunks
ORDER BY embedding <=> :query_embedding::vector
LIMIT 5;
```

**Trade-off probes vs latency**:
| Probes | Recall | Latency (p95) |
|--------|--------|---------------|
| 1      | 85%    | 50ms          |
| 5      | 95%    | 80ms          |
| 10     | 99%    | 120ms         |
| 20     | 99.9%  | 200ms         |

**Para Fase 1**: `probes = 10` (99% recall, 120ms latency)

### ConsequÃªncias

#### Positivas:
- âœ… Build rÃ¡pido (<10s para 100k vetores)
- âœ… Menor consumo de memÃ³ria (200 MB vs 500 MB)
- âœ… Recall suficiente (99%)
- âœ… ConfiguraÃ§Ã£o simples (1 parÃ¢metro)

#### Negativas:
- âŒ Recall inferior a HNSW (99% vs 99.9%)
- âŒ Latency superior a HNSW (120ms vs 50ms)

#### Neutras:
- âš ï¸ Se escalar >1M vetores na Fase 3/4, migrar para HNSW

### MÃ©tricas de Sucesso
- **Recall**: â‰¥99%
- **Latency (p95)**: <200ms
- **Build Time**: <30s (100k vetores)

### ReferÃªncias
- [pgvector README - Indexing](https://github.com/pgvector/pgvector#indexing)
- [stack_supercore_v2.0.md - pgvector](../../../documentation-base/stack_supercore_v2.0.md#pgvector)

---

## ADR-006: Soft Delete para OrÃ¡culos e Documentos

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Tech Lead, Product Owner

### Contexto
Quando administradores deletam OrÃ¡culos ou Documentos, precisamos decidir:
- **Hard delete**: Deletar fisicamente do banco (DELETE FROM)
- **Soft delete**: Marcar como deletado (UPDATE SET deleted_at = NOW())

### DecisÃ£o
**Escolhemos Soft Delete**

### Justificativa

#### Vantagens de Soft Delete:
1. **Auditoria e Compliance** (ğŸ”¥ Mais importante):
   - HistÃ³rico completo mantido (quem deletou, quando)
   - Rastreabilidade para auditorias (SOC2, LGPD)
   - PossÃ­vel restaurar dados deletados acidentalmente

2. **Integridade Referencial**:
   - Objetos relacionados nÃ£o quebram (ex: Document chunks ainda referenciam documento)
   - Evita CASCADE deletes acidentais

3. **Analytics**:
   - PossÃ­vel analisar dados deletados (ex: "quantos OrÃ¡culos foram deletados no Ãºltimo mÃªs?")

4. **Undo/Restore**:
   - Restaurar OrÃ¡culos/Documentos deletados acidentalmente
   - Importante para UX (usuÃ¡rios cometem erros)

#### Desvantagens de Hard Delete:
- Dados perdidos permanentemente (sem undo)
- Falta de auditoria (quem deletou? quando?)
- CASCADE deletes podem quebrar integridade

### ImplementaÃ§Ã£o

**Schema (PostgreSQL)**:
```sql
CREATE TABLE oracles (
    id UUID PRIMARY KEY,
    name VARCHAR(100) NOT NULL,
    -- ... outros campos ...
    created_at TIMESTAMP NOT NULL DEFAULT NOW(),
    updated_at TIMESTAMP NOT NULL DEFAULT NOW(),
    deleted_at TIMESTAMP -- NULL = ativo, NOT NULL = deletado
);

-- Index para queries que excluem deletados
CREATE INDEX idx_oracles_not_deleted
ON oracles(id)
WHERE deleted_at IS NULL;

-- Constraint para evitar duplicatas (mesmo para deletados)
CREATE UNIQUE INDEX idx_oracles_name_unique
ON oracles(name)
WHERE deleted_at IS NULL;
```

**Backend (Go)**:
```go
// Soft delete
func DeleteOracle(id uuid.UUID) error {
    query := `
        UPDATE oracles
        SET deleted_at = NOW()
        WHERE id = $1 AND deleted_at IS NULL
    `
    result, err := db.Exec(query, id)
    if err != nil {
        return err
    }

    if result.RowsAffected() == 0 {
        return ErrNotFound
    }

    return nil
}

// List (excluir deletados por padrÃ£o)
func ListOracles() ([]Oracle, error) {
    query := `
        SELECT * FROM oracles
        WHERE deleted_at IS NULL
        ORDER BY created_at DESC
    `
    // ...
}

// Restore
func RestoreOracle(id uuid.UUID) error {
    query := `
        UPDATE oracles
        SET deleted_at = NULL
        WHERE id = $1 AND deleted_at IS NOT NULL
    `
    // ...
}
```

**Auditoria**:
```go
// Registrar quem deletou
type AuditLog struct {
    ID        uuid.UUID `json:"id"`
    Action    string    `json:"action"` // "oracle_deleted"
    EntityID  uuid.UUID `json:"entity_id"`
    UserID    uuid.UUID `json:"user_id"`
    Timestamp time.Time `json:"timestamp"`
    Details   string    `json:"details"`
}

func DeleteOracle(id uuid.UUID, userID uuid.UUID) error {
    // Soft delete
    // ...

    // Audit log
    auditLog := AuditLog{
        Action:    "oracle_deleted",
        EntityID:  id,
        UserID:    userID,
        Timestamp: time.Now(),
        Details:   fmt.Sprintf("Oracle %s deleted by user %s", id, userID),
    }
    db.Create(&auditLog)

    return nil
}
```

### ConsequÃªncias

#### Positivas:
- âœ… Auditoria completa (quem, quando, o quÃª)
- âœ… RestauraÃ§Ã£o possÃ­vel (undo)
- âœ… Compliance (SOC2, LGPD)
- âœ… Analytics de deletions

#### Negativas:
- âŒ Queries precisam filtrar `deleted_at IS NULL` (complexidade adicional)
- âŒ Crescimento de database (dados deletados ocupam espaÃ§o)
- âŒ Constraints precisam considerar deleted_at (ex: unique constraints)

#### MitigaÃ§Ãµes:
- **Queries**: Usar views que filtram automaticamente `deleted_at IS NULL`
- **Storage**: Purge periÃ³dico de dados deletados >365 dias (GDPR compliance)
- **Constraints**: Usar partial indexes (`WHERE deleted_at IS NULL`)

### PolÃ­tica de Purge

**GDPR Compliance**: Deletar fisicamente dados apÃ³s 365 dias de soft delete

```sql
-- Job mensal (cron)
DELETE FROM oracles
WHERE deleted_at IS NOT NULL
  AND deleted_at < NOW() - INTERVAL '365 days';
```

### ReferÃªncias
- [GDPR Right to Erasure](https://gdpr-info.eu/art-17-gdpr/)
- [SOC2 Audit Logging](https://www.vanta.com/resources/soc-2-audit-logging)

---

## ADR-007: WebSocket para Document Processing Updates

**Status**: âœ… Aceito
**Data**: 2025-12-28
**Decisores**: Frontend Lead, Backend Lead

### Contexto
O pipeline de processamento de documentos (RF003) tem 5 estÃ¡gios que podem levar 1-5 minutos. Precisamos notificar o usuÃ¡rio do progresso em tempo real.

OpÃ§Ãµes consideradas:
- **OpÃ§Ã£o A**: WebSocket (bidirecional, tempo real)
- **OpÃ§Ã£o B**: SSE (unidirecional, tempo real)
- **OpÃ§Ã£o C**: Polling (requisiÃ§Ãµes periÃ³dicas a cada 2s)

### DecisÃ£o
**Escolhemos WebSocket (OpÃ§Ã£o A)**

### Justificativa

#### Por que WebSocket?

**Caso de Uso: Batch Upload**
- UsuÃ¡rio faz upload de 10-50 arquivos simultÃ¢neos
- Backend processa todos em paralelo
- Frontend precisa mostrar progresso de CADA arquivo
- Updates frequentes (100+ updates/minuto em batch upload)

**Vantagens do WebSocket para este caso**:
1. **Bidirecional**:
   - Server â†’ Client: Progress updates
   - Client â†’ Server: Cancelar processamento, pausar, retry
   - SSE nÃ£o suporta Client â†’ Server

2. **Baixa LatÃªncia**:
   - WebSocket: <50ms por update
   - Polling: 2000ms (intervalo de polling)

3. **EficiÃªncia**:
   - WebSocket: 1 conexÃ£o persistente
   - Polling: 100 requests/minuto (overhead de HTTP headers)

4. **Broadcast**:
   - FÃ¡cil enviar updates para mÃºltiplos clientes (ex: admin vendo uploads de outros users)

#### Por que NÃƒO SSE ou Polling?

**SSE (OpÃ§Ã£o B)**: Ruim porque:
- Unidirecional (nÃ£o pode cancelar processamento)
- MÃºltiplas conexÃµes SSE (1 por arquivo) = overhead

**Polling (OpÃ§Ã£o C)**: Ruim porque:
- LatÃªncia alta (2s de delay)
- Overhead (100+ requests/minuto)
- Ineficiente para batch upload

### Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Frontend         â”‚
â”‚ (React)          â”‚
â”‚                  â”‚
â”‚ WebSocket Client â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚ ws://localhost:3000/ws/documents/:oracle_id
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Backend          â”‚
â”‚ (FastAPI)        â”‚
â”‚                  â”‚
â”‚ WebSocket Server â”‚
â”‚ ConnectionManagerâ”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Document         â”‚
â”‚ Processor        â”‚
â”‚ (Async Pipeline) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ImplementaÃ§Ã£o

**Backend (Python + FastAPI)**:
```python
from fastapi import WebSocket, WebSocketDisconnect
from typing import Dict, Set

# Connection Manager
class ConnectionManager:
    def __init__(self):
        self.active_connections: Dict[str, Set[WebSocket]] = {}

    async def connect(self, oracle_id: str, websocket: WebSocket):
        await websocket.accept()
        if oracle_id not in self.active_connections:
            self.active_connections[oracle_id] = set()
        self.active_connections[oracle_id].add(websocket)

    def disconnect(self, oracle_id: str, websocket: WebSocket):
        self.active_connections[oracle_id].remove(websocket)

    async def broadcast(self, oracle_id: str, message: dict):
        """Send message to all clients connected to this oracle"""
        if oracle_id in self.active_connections:
            dead_connections = set()
            for connection in self.active_connections[oracle_id]:
                try:
                    await connection.send_json(message)
                except:
                    dead_connections.add(connection)

            # Remove dead connections
            for conn in dead_connections:
                self.disconnect(oracle_id, conn)

manager = ConnectionManager()

# WebSocket endpoint
@app.websocket("/ws/documents/{oracle_id}")
async def websocket_endpoint(websocket: WebSocket, oracle_id: str):
    await manager.connect(oracle_id, websocket)

    try:
        while True:
            # Receive messages from client (ex: cancel, pause, retry)
            data = await websocket.receive_json()

            if data["action"] == "cancel":
                document_id = data["document_id"]
                await cancel_processing(document_id)
                await websocket.send_json({
                    "document_id": document_id,
                    "status": "cancelled"
                })

    except WebSocketDisconnect:
        manager.disconnect(oracle_id, websocket)

# Document processor sends updates
async def process_document(document_id: str, oracle_id: str):
    # Stage 1: Upload
    await manager.broadcast(oracle_id, {
        "document_id": document_id,
        "progress": 20,
        "status": "uploaded",
        "current_step": "Upload",
        "total_steps": 5
    })

    # Stage 2: Extract
    text = await extract_text(document)
    await manager.broadcast(oracle_id, {
        "document_id": document_id,
        "progress": 40,
        "status": "extracted",
        "current_step": "Text Extraction",
        "total_steps": 5
    })

    # ... stages 3-5 ...
```

**Frontend (React + TypeScript)**:
```typescript
import { useEffect, useState } from 'react'

export function useDocumentProcessing(oracleId: string) {
  const [uploadQueue, setUploadQueue] = useState<UploadItem[]>([])
  const ws = useRef<WebSocket | null>(null)

  useEffect(() => {
    // Connect WebSocket
    ws.current = new WebSocket(`ws://localhost:3000/ws/documents/${oracleId}`)

    ws.current.onmessage = (event) => {
      const data = JSON.parse(event.data)

      // Update upload queue with progress
      setUploadQueue(prev =>
        prev.map(item =>
          item.id === data.document_id
            ? {
                ...item,
                progress: data.progress,
                status: data.status,
                currentStep: data.current_step,
              }
            : item
        )
      )
    }

    ws.current.onerror = (error) => {
      console.error('WebSocket error:', error)
    }

    ws.current.onclose = () => {
      console.log('WebSocket closed')
    }

    // Cleanup on unmount
    return () => {
      ws.current?.close()
    }
  }, [oracleId])

  const cancelProcessing = (documentId: string) => {
    ws.current?.send(JSON.stringify({
      action: 'cancel',
      document_id: documentId
    }))
  }

  return { uploadQueue, cancelProcessing }
}
```

### ConsequÃªncias

#### Positivas:
- âœ… Bidirecional (cancelar, pausar, retry)
- âœ… Baixa latÃªncia (<50ms por update)
- âœ… Eficiente (1 conexÃ£o persistente)
- âœ… Broadcast (mÃºltiplos clientes recebem updates)

#### Negativas:
- âŒ Mais complexo que SSE (gerenciar conexÃµes)
- âŒ Debugging mais difÃ­cil (requer ferramentas especializadas)
- âŒ Reconnect manual (SSE tem reconnect automÃ¡tico)

#### MitigaÃ§Ãµes:
- **Complexity**: Usar biblioteca (FastAPI WebSocket Manager)
- **Debugging**: Usar Postman/Insomnia para testar WebSocket
- **Reconnect**: Implementar reconnect logic no frontend (exponential backoff)

### MÃ©tricas de Sucesso
- **LatÃªncia**: <100ms (server â†’ client update)
- **Connection Uptime**: >99% (reconnect automÃ¡tico)
- **Broadcast Latency**: <200ms (100 clientes simultÃ¢neos)

### ReferÃªncias
- [FastAPI WebSocket](https://fastapi.tiangolo.com/advanced/websockets/)
- [WebSocket API (MDN)](https://developer.mozilla.org/en-US/docs/Web/API/WebSocket)
- [mockup 05_oracles_knowledge.md](../ux-ui/mockups/05_oracles_knowledge.md)

---

## ğŸ“Š Resumo de ADRs

| ADR | DecisÃ£o | Justificativa Principal | Trade-off |
|-----|---------|-------------------------|-----------|
| ADR-001 | pgvector (nÃ£o Qdrant) | Simplicidade operacional | Performance em >10M vetores |
| ADR-002 | Go + Python (hÃ­brido) | Best tool for the job | 2 stacks para manter |
| ADR-003 | SSE (nÃ£o WebSocket) | Simplicidade, unidirecional | Apenas Server â†’ Client |
| ADR-004 | JSON Schema | PadrÃ£o da indÃºstria | Curva de aprendizado |
| ADR-005 | IVFFlat (nÃ£o HNSW) | Build rÃ¡pido, recall suficiente | Latency superior |
| ADR-006 | Soft Delete | Auditoria, compliance | Queries mais complexas |
| ADR-007 | WebSocket | Bidirecional, batch upload | Complexidade de cÃ³digo |

---

## ğŸ“… PrÃ³ximos ADRs (Fases Futuras)

**Fase 2**:
- ADR-008: CrewAI vs LangChain Agents (Agentes autÃ´nomos)
- ADR-009: Celery vs Bull (Background jobs)
- ADR-010: Redis Pub/Sub vs RabbitMQ (Message broker)

**Fase 3**:
- ADR-011: NebulaGraph vs Neo4j (Graph database)
- ADR-012: MigraÃ§Ã£o pgvector â†’ Qdrant (Vector DB escalÃ¡vel)
- ADR-013: OpenTelemetry setup (Observability)

**Fase 4**:
- ADR-014: Kubernetes deployment strategy
- ADR-015: Multi-tenancy architecture
- ADR-016: Disaster recovery strategy

---

**VersÃ£o**: 1.0.0
**Data**: 2025-12-28
**Autor**: Squad Arquitetura (Tech Lead + Architecture Owner)
**Aprovado por**: Product Owner (pendente)
