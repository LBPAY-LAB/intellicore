# üí° SUGEST√ïES DE EVOLU√á√ÉO - SuperCore v2.0

**Data**: 2025-12-21
**Status**: Propostas para Avalia√ß√£o
**Prop√≥sito**: Sugerir melhorias e adi√ß√µes √† documenta√ß√£o base v2.0

---

## üìã INSTRU√á√ïES

Este documento cont√©m sugest√µes identificadas durante an√°lise dos documentos v1 e v2.0.

**Como usar:**
1. Leia cada sugest√£o
2. Avalie e decida: Aprovar / Rejeitar / Revisar
3. Atualize o Status conforme decis√£o
4. Sugest√µes aprovadas ser√£o incorporadas √† documenta√ß√£o

---

## üåü SUGEST√ïES CR√çTICAS (High Impact)

### S001: Adicionar Temporal.io para Workflow Orchestration Durable
**Categoria**: Stack / Workflow Orchestration
**Problema Atual**:
- LangGraph √© excelente para workflows AI-driven, mas n√£o √© dur√°vel (state pode ser perdido)
- Workflows de longa dura√ß√£o (dias/semanas) precisam de persistence e retry autom√°tico
- Exemplos: Onboarding de cliente (aguarda documentos), Compliance review (aprova√ß√£o manual)

**Proposta**:
Adicionar **Temporal.io v1.22+** como workflow engine dur√°vel complementar ao LangGraph.

**Stack sugerida**:
```yaml
Temporal:
  server: v1.22.0
  sdk_python: v1.5.0
  sdk_go: v1.25.0
  storage: PostgreSQL (reusa mesma inst√¢ncia)
```

**Casos de Uso**:
1. **Onboarding Workflow**: Multi-step com human-in-the-loop (aguarda docs, an√°lise de cr√©dito)
2. **Compliance Review**: Aprova√ß√£o multi-n√≠vel com timeouts e escalations
3. **Scheduled Tasks**: Jobs recorrentes com retry autom√°tico (relat√≥rios mensais)

**Benef√≠cios**:
- ‚úÖ Workflows sobrevivem a restarts (durable execution)
- ‚úÖ Retry autom√°tico com exponential backoff
- ‚úÖ Visibility completa (UI para ver workflows em execu√ß√£o)
- ‚úÖ CQRS nativo (event sourcing de workflows)
- ‚úÖ Multi-language (Python para AI, Go para performance)

**Esfor√ßo Estimado**: M√©dio (2-3 dias setup + 1 semana integra√ß√£o)
**Prioridade**: P1 (importante para workflows de longa dura√ß√£o)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S002: Adicionar DuckDB para Analytics In-Process
**Categoria**: Stack / Analytics
**Problema Atual**:
- PostgreSQL √© OLTP (transa√ß√µes), n√£o otimizado para analytics (agrega√ß√µes, window functions)
- Queries anal√≠ticas complexas (dashboards) podem sobrecarregar PostgreSQL
- BI tools (Metabase, Superset) fazem queries pesadas

**Proposta**:
Adicionar **DuckDB v0.9.2+** como analytics engine in-process.

**Stack sugerida**:
```yaml
DuckDB:
  version: v0.9.2
  python: duckdb==0.9.2
  use_cases:
    - Analytics queries (dashboards, reports)
    - Data export (Parquet, CSV)
    - Ad-hoc analysis (Jupyter notebooks)
```

**Arquitetura**:
```
PostgreSQL (OLTP) ‚Üí (ETL di√°rio) ‚Üí DuckDB (OLAP)
                                      ‚Üì
                              BI Tools, Dashboards
```

**Benef√≠cios**:
- ‚úÖ Analytics 10x-100x mais r√°pido que PostgreSQL
- ‚úÖ In-process (zero network latency)
- ‚úÖ SQL familiar (compat√≠vel com PostgreSQL)
- ‚úÖ Export eficiente para Parquet (data lake)
- ‚úÖ Footprint pequeno (embeddable)

**Esfor√ßo Estimado**: Baixo (1 dia setup + ETL pipeline)
**Prioridade**: P1 (cr√≠tico para dashboards perform√°ticos)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S003: Adicionar OpenFGA para Authorization Fine-Grained
**Categoria**: Stack / Security / Authorization
**Problema Atual**:
- RLS PostgreSQL √© bom para row-level security, mas n√£o flex√≠vel para permiss√µes complexas
- Exemplo: "Usu√°rio X pode editar Contas APENAS se for Gerente da Ag√™ncia E conta est√° ATIVA"
- RBAC tradicional (roles) n√£o escala para permiss√µes contextuais

**Proposta**:
Adicionar **OpenFGA (Zanzibar-inspired)** para fine-grained authorization.

**Stack sugerida**:
```yaml
OpenFGA:
  server: v1.4.0
  sdk_python: v0.3.0
  sdk_go: v0.3.0
  storage: PostgreSQL (reusa mesma inst√¢ncia)
```

**Modelo de Authorization**:
```dsl
# OpenFGA Authorization Model
model
  schema 1.1

type user

type oracle
  relations
    define owner: [user]
    define admin: [user]
    define editor: [user] or admin
    define viewer: [user] or editor or admin

type object_definition
  relations
    define oracle: [oracle]
    define editor: [user] or admin from oracle
    define viewer: [user] or editor or viewer from oracle

type instance
  relations
    define object_definition: [object_definition]
    define owner: [user]
    define editor: [user] or owner or editor from object_definition
    define viewer: [user] or editor or viewer from object_definition
```

**Queries**:
```python
# Check: "Can user:alice edit instance:12345?"
await fga.check(
    user="user:alice",
    relation="editor",
    object="instance:12345"
)
```

**Benef√≠cios**:
- ‚úÖ Fine-grained permissions (al√©m de RBAC)
- ‚úÖ Relationship-based (Zanzibar model)
- ‚úÖ Performance (√≠ndices otimizados)
- ‚úÖ Auditoria (quem pode acessar o qu√™)
- ‚úÖ Escal√°vel (Google usa Zanzibar para YouTube, Drive)

**Esfor√ßo Estimado**: M√©dio (1 semana setup + migration de RBAC)
**Prioridade**: P0 (cr√≠tico para multi-tenancy seguro)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S004: Adicionar Grafana + Prometheus Stack para Observability
**Categoria**: Stack / Observability
**Problema Atual**:
- OpenTelemetry coleta m√©tricas, mas n√£o h√° UI para visualizar
- Logs distribu√≠dos (Go, Python, Next.js) precisam de agrega√ß√£o
- Alerting n√£o est√° configurado

**Proposta**:
Adicionar stack completo de observability:

**Stack sugerida**:
```yaml
Observability:
  metrics:
    prometheus: v2.48.0
    grafana: v10.2.0
  logs:
    loki: v2.9.0
  traces:
    tempo: v2.3.0
  alerts:
    alertmanager: v0.26.0
```

**Dashboards Grafana**:
1. **SuperCore Overview**: QPS, latency, error rate
2. **PostgreSQL**: Connections, query performance, cache hit ratio
3. **NebulaGraph**: Query latency, storage usage
4. **AI Services**: LLM latency, token usage, cache hit rate
5. **Multi-Tenant**: M√©tricas por Oracle (QPS, storage, costs)

**Alerting Rules**:
- üö® Error rate > 1% (√∫ltimos 5min)
- üö® Latency p99 > 500ms
- üö® Database connections > 80% capacity
- üö® LLM API failures > 10 (√∫ltimos 10min)

**Benef√≠cios**:
- ‚úÖ Visibility completa do sistema
- ‚úÖ Alerting proativo (antes de users reclamarem)
- ‚úÖ Debugging r√°pido (correla√ß√£o traces + logs + metrics)
- ‚úÖ Cost tracking (por Oracle)

**Esfor√ßo Estimado**: M√©dio (3-4 dias setup + dashboards)
**Prioridade**: P0 (cr√≠tico para produ√ß√£o)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S005: Adicionar Chaos Engineering com LitmusChaos
**Categoria**: Processos / Resili√™ncia
**Problema Atual**:
- Sistema n√£o foi testado para falhas (network partitions, pod crashes, disk full)
- Produ√ß√£o pode ter falhas catastr√≥ficas n√£o testadas
- SLAs (99.9% uptime) exigem resili√™ncia provada

**Proposta**:
Adicionar **LitmusChaos v3.0+** para chaos engineering.

**Chaos Experiments**:
1. **Pod Delete**: Matar pods aleatoriamente (testa restart autom√°tico)
2. **Network Latency**: Injetar lat√™ncia 500ms-2s (testa timeouts)
3. **Disk Fill**: Preencher disco (testa garbage collection)
4. **CPU Hog**: Consumir 90% CPU (testa auto-scaling)
5. **PostgreSQL Failure**: Derrubar PostgreSQL (testa failover)

**Cad√™ncia**:
- **Dev**: Chaos experiments daily (automated)
- **Staging**: Chaos experiments semanais (GameDay)
- **Prod**: Chaos experiments mensais (controlled)

**Benef√≠cios**:
- ‚úÖ Confian√ßa em resili√™ncia (provar que sistema se recupera)
- ‚úÖ Identificar pontos fracos ANTES de produ√ß√£o
- ‚úÖ SRE mindset (falhas s√£o inevit√°veis, prepare-se)
- ‚úÖ SLA compliance (99.9% uptime comprovado)

**Esfor√ßo Estimado**: M√©dio (1 semana setup + experiments)
**Prioridade**: P1 (importante para produ√ß√£o resiliente)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

## üí° SUGEST√ïES IMPORTANTES (Medium Impact)

### S010: Adicionar Feature Flags com Flagsmith
**Categoria**: Stack / Feature Management
**Problema Atual**:
- Deploys s√£o "tudo ou nada" (feature vai para 100% dos usu√°rios)
- Rollback exige redeploy (lento, arriscado)
- A/B testing n√£o √© poss√≠vel

**Proposta**:
Adicionar **Flagsmith v2.80+** para feature flags.

**Use Cases**:
1. **Gradual Rollout**: Nova feature para 5% ‚Üí 25% ‚Üí 50% ‚Üí 100%
2. **A/B Testing**: Testar UI diferente para 50% dos usu√°rios
3. **Kill Switch**: Desligar feature com bug SEM redeploy
4. **Per-Oracle**: Feature X habilitada apenas para Oracle ABC

**Stack sugerida**:
```yaml
Flagsmith:
  server: v2.80.0 (self-hosted)
  sdk_python: v3.5.0
  sdk_typescript: v3.5.0
```

**Benef√≠cios**:
- ‚úÖ Deploy seguro (gradual rollout)
- ‚úÖ Rollback instant√¢neo (toggle flag)
- ‚úÖ Experimentation (A/B testing)
- ‚úÖ Multi-tenant (flags por Oracle)

**Esfor√ßo Estimado**: Baixo (2 dias setup)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S011: Adicionar Vault para Secrets Management
**Categoria**: Stack / Security / Secrets
**Problema Atual**:
- Secrets em `.env` files (inseguro)
- Rota√ß√£o manual de secrets (propenso a erro)
- Auditoria de acessos a secrets inexistente

**Proposta**:
Adicionar **HashiCorp Vault v1.15+** para secrets management.

**Features**:
1. **Dynamic Secrets**: PostgreSQL credentials geradas on-demand (TTL 1h)
2. **Encryption as a Service**: Encrypt/decrypt PII (CPF, cart√£o)
3. **Secret Rotation**: Auto-rotate secrets (monthly)
4. **Audit Log**: Quem acessou qual secret, quando

**Stack sugerida**:
```yaml
Vault:
  server: v1.15.0
  storage: PostgreSQL (reusa mesma inst√¢ncia)
  sdk_python: hvac==2.1.0
  sdk_go: vault/api v1.10.0
```

**Benef√≠cios**:
- ‚úÖ Secrets nunca em plaintext
- ‚úÖ Rota√ß√£o autom√°tica (compliance)
- ‚úÖ Auditoria completa (quem acessou o qu√™)
- ‚úÖ Dynamic credentials (PostgreSQL, MinIO)

**Esfor√ßo Estimado**: M√©dio (3 dias setup + migration)
**Prioridade**: P0 (cr√≠tico para produ√ß√£o segura)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S012: Adicionar SonarQube para Code Quality
**Categoria**: Processos / Code Quality
**Problema Atual**:
- Code quality n√£o √© mensurado (bugs, code smells, security hotspots)
- Code review √© manual (propenso a erro)
- Technical debt cresce invis√≠vel

**Proposta**:
Adicionar **SonarQube v10.3+** para an√°lise est√°tica.

**An√°lises**:
1. **Security**: OWASP Top 10, CWE vulnerabilities
2. **Bugs**: Null pointer, race conditions
3. **Code Smells**: Complexidade, duplica√ß√£o
4. **Coverage**: Test coverage m√≠nimo 80%

**CI/CD Integration**:
```yaml
# GitHub Actions
- name: SonarQube Scan
  run: sonar-scanner
  env:
    SONAR_HOST_URL: https://sonar.supercore.dev
    SONAR_TOKEN: ${{ secrets.SONAR_TOKEN }}

# Quality Gate
- name: Check Quality Gate
  run: |
    quality_gate=$(curl -s "$SONAR_HOST_URL/api/qualitygates/project_status?projectKey=supercore")
    if [ "$quality_gate" != "OK" ]; then
      echo "Quality gate failed!"
      exit 1
    fi
```

**Benef√≠cios**:
- ‚úÖ Code quality vis√≠vel (dashboards)
- ‚úÖ Bloqueia PRs com bugs cr√≠ticos
- ‚úÖ Track technical debt
- ‚úÖ Security vulnerabilities detectadas cedo

**Esfor√ßo Estimado**: Baixo (1 dia setup)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S013: Adicionar SAST/DAST no CI/CD Pipeline
**Categoria**: Processos / Security
**Problema Atual**:
- Security testing √© manual (se houver)
- Vulnerabilidades chegam em produ√ß√£o
- Compliance exige security scans (LGPD, PCI-DSS)

**Proposta**:
Adicionar SAST + DAST ao pipeline CI/CD.

**Ferramentas sugeridas**:
```yaml
SAST:
  tool: Semgrep (open-source)
  version: v1.50.0
  languages: Go, Python, TypeScript
  rules: OWASP Top 10, CWE

DAST:
  tool: OWASP ZAP
  version: v2.14.0
  scan_type: API scan (OpenAPI spec)
  frequency: Nightly (staging environment)
```

**Pipeline Integration**:
1. **SAST**: Runs on every PR (bloqueia se vulnerabilidade cr√≠tica)
2. **DAST**: Runs nightly contra staging (report de vulnerabilidades)

**Benef√≠cios**:
- ‚úÖ Security vulnerabilities detectadas cedo
- ‚úÖ Compliance (LGPD, PCI-DSS)
- ‚úÖ Shift-left security (devs corrigem bugs antes de merge)

**Esfor√ßo Estimado**: Baixo (2 dias setup)
**Prioridade**: P0 (cr√≠tico para seguran√ßa)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S014: Adicionar Dependabot/Renovate para Dependency Updates
**Categoria**: Processos / Dependency Management
**Problema Atual**:
- Dependencies ficam desatualizadas (security vulnerabilities)
- Update manual √© trabalhoso e esquecido
- Breaking changes descobertos tarde

**Proposta**:
Adicionar **Renovate** (ou Dependabot) para auto-update de dependencies.

**Config sugerida**:
```json
// renovate.json
{
  "extends": ["config:base"],
  "packageRules": [
    {
      "matchUpdateTypes": ["minor", "patch"],
      "automerge": true
    },
    {
      "matchUpdateTypes": ["major"],
      "automerge": false,
      "labels": ["major-update"]
    }
  ],
  "schedule": ["before 5am on monday"]
}
```

**Benef√≠cios**:
- ‚úÖ Dependencies sempre atualizadas
- ‚úÖ Security patches autom√°ticos
- ‚úÖ Breaking changes detectados cedo (PR com testes)
- ‚úÖ Reduz technical debt

**Esfor√ßo Estimado**: Muito Baixo (1h setup)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S015: Adicionar OpenAPI Spec Auto-Generation
**Categoria**: Stack / API Documentation
**Problema Atual**:
- API docs ficam desatualizadas (code evolui, docs n√£o)
- Frontend precisa de types sincronizados com backend
- Manual API testing √© trabalhoso

**Proposta**:
Auto-gerar OpenAPI spec + TypeScript types do backend.

**Ferramentas**:
```yaml
Backend (Go):
  tool: swaggo/swag
  version: v1.16.2
  output: openapi.yaml

Backend (Python):
  tool: FastAPI (built-in)
  output: openapi.json

Frontend Types:
  tool: openapi-typescript
  version: v6.7.0
  input: openapi.yaml
  output: src/types/api.ts
```

**Pipeline**:
```bash
# Generate OpenAPI spec
swag init -g main.go -o ./docs

# Generate TypeScript types
npx openapi-typescript ./docs/openapi.yaml -o ./frontend/src/types/api.ts

# Validate API matches spec (contract testing)
npx dredd openapi.yaml http://localhost:8080
```

**Benef√≠cios**:
- ‚úÖ API docs sempre sincronizadas
- ‚úÖ TypeScript types type-safe
- ‚úÖ Contract testing (API matches spec)
- ‚úÖ API client auto-generated

**Esfor√ßo Estimado**: Baixo (1 dia setup)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S016: Adicionar E2E Testing com Playwright (CI/CD)
**Categoria**: Processos / Testing
**Problema Atual**:
- E2E testing √© manual (QA team)
- Regressions descobertas tarde (em produ√ß√£o)
- Confidence baixo em deploys

**Proposta**:
Adicionar Playwright E2E tests ao CI/CD.

**Test Suites**:
1. **Happy Path**: Create Oracle ‚Üí Upload Context ‚Üí Generate Objects ‚Üí Deploy
2. **Edge Cases**: Invalid inputs, network failures, timeouts
3. **Multi-Tenant**: Isolamento entre Oracles (user A n√£o v√™ dados de Oracle B)

**Pipeline Integration**:
```yaml
# .github/workflows/e2e.yml
name: E2E Tests
on: [pull_request]
jobs:
  e2e:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      - name: Start Services
        run: docker-compose up -d
      - name: Run E2E Tests
        run: npx playwright test
      - name: Upload Report
        uses: actions/upload-artifact@v3
        with:
          name: playwright-report
          path: playwright-report/
```

**Benef√≠cios**:
- ‚úÖ Regressions detectadas cedo (antes de merge)
- ‚úÖ Confidence alto em deploys
- ‚úÖ QA team foca em testes explorat√≥rios (n√£o repetitivos)

**Esfor√ßo Estimado**: M√©dio (1 semana cria√ß√£o de testes)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S017: Adicionar Load Testing com k6
**Categoria**: Processos / Performance
**Problema Atual**:
- Performance n√£o √© testada sob carga
- Limites de throughput desconhecidos
- Produ√ß√£o pode degradar sob pico de tr√°fego

**Proposta**:
Adicionar **k6** para load testing.

**Test Scenarios**:
```javascript
// load-test.js
import http from 'k6/http';
import { check, sleep } from 'k6';

export let options = {
  stages: [
    { duration: '2m', target: 100 },  // Ramp-up to 100 users
    { duration: '5m', target: 100 },  // Stay at 100 users
    { duration: '2m', target: 200 },  // Ramp-up to 200 users
    { duration: '5m', target: 200 },  // Stay at 200 users
    { duration: '2m', target: 0 },    // Ramp-down to 0 users
  ],
  thresholds: {
    'http_req_duration': ['p(99)<500'], // 99% of requests < 500ms
    'http_req_failed': ['rate<0.01'],   // Error rate < 1%
  },
};

export default function () {
  let res = http.get('http://localhost:8080/api/v1/oracles');
  check(res, {
    'status is 200': (r) => r.status === 200,
    'response time < 500ms': (r) => r.timings.duration < 500,
  });
  sleep(1);
}
```

**Pipeline Integration**:
- **Nightly**: Load test contra staging (report de performance)
- **Before Release**: Load test com carga 2x esperada (stress test)

**Benef√≠cios**:
- ‚úÖ Conhecer limites de throughput
- ‚úÖ Identificar bottlenecks (database, API, cache)
- ‚úÖ Validar auto-scaling funciona
- ‚úÖ SLA compliance (p99 < 500ms)

**Esfor√ßo Estimado**: Baixo (2 dias cria√ß√£o de testes)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S018: Adicionar SLIs/SLOs/SLAs Framework
**Categoria**: Processos / SRE
**Problema Atual**:
- SLAs n√£o est√£o definidos (qual uptime prometido?)
- N√£o h√° m√©tricas de confiabilidade
- Error budget desconhecido

**Proposta**:
Definir SLIs, SLOs e SLAs formais.

**Framework sugerido**:
```yaml
SLIs (Service Level Indicators):
  availability:
    metric: (successful_requests / total_requests) * 100
    measurement_window: 30 days
  latency:
    metric: p99 latency
    measurement_window: 24 hours
  error_rate:
    metric: (failed_requests / total_requests) * 100
    measurement_window: 1 hour

SLOs (Service Level Objectives):
  availability:
    target: 99.9%  # 43.2 min downtime/month
    error_budget: 0.1% (43.2 min/month)
  latency:
    target: p99 < 500ms
  error_rate:
    target: < 0.1%

SLAs (Service Level Agreements):
  tier_premium:
    availability: 99.95%  # 21.6 min downtime/month
    support: 24/7, response time < 15min
  tier_standard:
    availability: 99.9%   # 43.2 min downtime/month
    support: Business hours, response time < 4h
```

**Error Budget Policy**:
- **Budget OK**: Deploy features normalmente
- **Budget 50% consumido**: Freeze features n√£o-cr√≠ticas, foco em reliability
- **Budget esgotado**: Stop all deploys, incident postmortem obrigat√≥rio

**Benef√≠cios**:
- ‚úÖ Expectativas claras (time + usu√°rios)
- ‚úÖ Decis√µes data-driven (deploy vs reliability)
- ‚úÖ Accountability (SLA breaches ‚Üí postmortem)

**Esfor√ßo Estimado**: Baixo (1 dia defini√ß√£o + 1 dia dashboards)
**Prioridade**: P1
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S019: Adicionar Incident Management com PagerDuty/OnCall
**Categoria**: Processos / Incident Management
**Problema Atual**:
- Alertas v√£o para Slack (f√°cil de perder)
- Escalation manual (ineficiente)
- On-call rotation n√£o estruturada

**Proposta**:
Adicionar **PagerDuty** (ou Grafana OnCall self-hosted) para incident management.

**Features**:
1. **Alert Routing**: Alerts ‚Üí PagerDuty ‚Üí On-call engineer
2. **Escalation**: Se n√£o ack em 15min ‚Üí Escalate para senior
3. **On-Call Rotation**: Autom√°tico (weekly rotation)
4. **Runbooks**: Links para runbooks (como resolver incident X)

**Integration**:
```yaml
Alertmanager (Prometheus):
  routes:
    - receiver: pagerduty-critical
      match:
        severity: critical
    - receiver: pagerduty-warning
      match:
        severity: warning

PagerDuty:
  critical_incidents:
    escalation_policy: immediate
    urgency: high
  warning_incidents:
    escalation_policy: low-urgency
    urgency: low
```

**Benef√≠cios**:
- ‚úÖ Alertas nunca perdidos (phone call, SMS, push)
- ‚úÖ Escalation autom√°tico (se on-call n√£o responde)
- ‚úÖ On-call rotation justo (automated)
- ‚úÖ Postmortems estruturados

**Esfor√ßo Estimado**: Baixo (1 dia setup)
**Prioridade**: P1 (cr√≠tico para produ√ß√£o)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S020: Adicionar Architecture Decision Records (ADRs)
**Categoria**: Processos / Documentation
**Problema Atual**:
- Decis√µes arquiteturais n√£o documentadas (por que escolhemos X?)
- Novo time member n√£o entende contexto
- Decis√µes s√£o esquecidas (por que n√£o usamos Y?)

**Proposta**:
Criar ADRs para TODAS as decis√µes arquiteturais importantes.

**Template ADR**:
```markdown
# ADR-001: Escolha de Apache Pulsar sobre Kafka

**Status**: Aceito
**Data**: 2025-12-21
**Deciders**: Arquiteto, Tech Lead
**Context**: Precisamos de message broker para comunica√ß√£o ass√≠ncrona

## Decis√£o
Usar Apache Pulsar v3.4.0 como message broker.

## Rationale
- ‚úÖ Multi-tenancy nativo (namespaces por Oracle)
- ‚úÖ Geo-replication built-in
- ‚úÖ Schema registry nativo
- ‚úÖ Throughput similar ao Kafka

## Alternativas Consideradas
1. **Apache Kafka**: Sem multi-tenancy nativo, geo-replication complexa
2. **RabbitMQ**: Throughput inferior, n√£o escala bem

## Consequ√™ncias
- Positivas: Isolamento multi-tenant, geo-replication f√°cil
- Negativas: Ecosistema menor que Kafka, menos tooling

## Compliance
- LGPD: Isolamento por namespace garante compliance
```

**Localiza√ß√£o**:
```
docs/architecture/decisions/
‚îú‚îÄ‚îÄ 001-apache-pulsar.md
‚îú‚îÄ‚îÄ 002-next-js-app-router.md
‚îú‚îÄ‚îÄ 003-postgresql-over-mysql.md
‚îî‚îÄ‚îÄ README.md (√≠ndice de ADRs)
```

**Benef√≠cios**:
- ‚úÖ Decis√µes documentadas (contexto preservado)
- ‚úÖ Onboarding r√°pido (novos devs entendem "por qu√™")
- ‚úÖ Evita rediscutir decis√µes passadas

**Esfor√ßo Estimado**: Muito Baixo (30min por ADR)
**Prioridade**: P2 (nice to have, mas importante)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

## üîß SUGEST√ïES MENORES (Nice to Have)

### S030: Adicionar Storybook para UI Component Library
**Categoria**: Stack / Frontend / Documentation
**Problema Atual**:
- Componentes shadcn/ui customizados n√£o t√™m showcase
- Designers n√£o conseguem ver componentes dispon√≠veis
- Documenta√ß√£o de props √© manual

**Proposta**:
Adicionar **Storybook v7.6+** para component showcase.

**Estrutura**:
```
frontend/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îî‚îÄ‚îÄ components/
‚îÇ       ‚îú‚îÄ‚îÄ OracleSelector.tsx
‚îÇ       ‚îú‚îÄ‚îÄ OracleSelector.stories.tsx  # Storybook story
‚îÇ       ‚îú‚îÄ‚îÄ ObjectForm.tsx
‚îÇ       ‚îî‚îÄ‚îÄ ObjectForm.stories.tsx
‚îî‚îÄ‚îÄ .storybook/
    ‚îú‚îÄ‚îÄ main.ts
    ‚îî‚îÄ‚îÄ preview.ts
```

**Benef√≠cios**:
- ‚úÖ Component showcase visual
- ‚úÖ Design system documentation
- ‚úÖ Testes visuais (snapshot testing)

**Esfor√ßo Estimado**: Baixo (1 dia setup)
**Prioridade**: P2
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S031: Adicionar Bundle Analyzer para Frontend Performance
**Categoria**: Stack / Frontend / Performance
**Problema Atual**:
- Bundle size do Next.js n√£o √© monitorado
- N√£o sabemos quais dependencies s√£o pesadas
- Performance regressions passam despercebidas

**Proposta**:
Adicionar **@next/bundle-analyzer** para an√°lise de bundle.

**Setup**:
```javascript
// next.config.js
const withBundleAnalyzer = require('@next/bundle-analyzer')({
  enabled: process.env.ANALYZE === 'true',
});

module.exports = withBundleAnalyzer({
  // ... next config
});
```

**CI Check**:
```yaml
# Fail if bundle size > 500KB
- name: Check Bundle Size
  run: |
    npm run build
    size=$(du -sk .next/static | cut -f1)
    if [ $size -gt 512000 ]; then
      echo "Bundle size exceeded 500KB!"
      exit 1
    fi
```

**Benef√≠cios**:
- ‚úÖ Bundle size monitorado
- ‚úÖ Identificar dependencies pesadas
- ‚úÖ Performance regressions detectadas

**Esfor√ßo Estimado**: Muito Baixo (1h setup)
**Prioridade**: P2
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S032: Adicionar Lighthouse CI para Web Performance
**Categoria**: Processos / Frontend / Performance
**Problema Atual**:
- Web performance (Core Web Vitals) n√£o √© testada
- Accessibility (WCAG) n√£o √© validada
- SEO best practices n√£o s√£o checadas

**Proposta**:
Adicionar **Lighthouse CI** ao pipeline.

**Checks**:
```yaml
# .lighthouserc.js
module.exports = {
  ci: {
    collect: {
      url: ['http://localhost:3000'],
      numberOfRuns: 3,
    },
    assert: {
      preset: 'lighthouse:recommended',
      assertions: {
        'categories:performance': ['error', {minScore: 0.9}],
        'categories:accessibility': ['error', {minScore: 0.9}],
        'categories:best-practices': ['error', {minScore: 0.9}],
        'categories:seo': ['warn', {minScore: 0.8}],
      },
    },
  },
};
```

**Benef√≠cios**:
- ‚úÖ Core Web Vitals monitorados
- ‚úÖ Accessibility compliance (WCAG 2.1 AA)
- ‚úÖ SEO best practices

**Esfor√ßo Estimado**: Baixo (1 dia setup)
**Prioridade**: P2
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S033: Adicionar Conventional Commits + Semantic Release
**Categoria**: Processos / Versioning
**Problema Atual**:
- Commit messages inconsistentes
- Versionamento manual (esquecido)
- Changelog gerado manualmente

**Proposta**:
Adotar **Conventional Commits** + **semantic-release**.

**Commit Convention**:
```
<type>(<scope>): <subject>

Types:
  feat: Nova feature (minor version bump)
  fix: Bug fix (patch version bump)
  docs: Documentation only
  refactor: Code refactor (no behavior change)
  perf: Performance improvement
  test: Add tests
  chore: Maintenance (deps, config)

Examples:
  feat(oracle): add multi-tenant namespace isolation
  fix(auth): resolve JWT token expiration bug
  docs(readme): update quick start guide
```

**Semantic Release**:
```yaml
# .releaserc.yml
branches:
  - main
plugins:
  - '@semantic-release/commit-analyzer'
  - '@semantic-release/release-notes-generator'
  - '@semantic-release/changelog'
  - '@semantic-release/github'
  - '@semantic-release/git'
```

**Benef√≠cios**:
- ‚úÖ Commit history leg√≠vel
- ‚úÖ Versionamento autom√°tico (semver)
- ‚úÖ Changelog auto-gerado
- ‚úÖ Release notes autom√°ticas

**Esfor√ßo Estimado**: Muito Baixo (1h setup)
**Prioridade**: P2
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S034: Adicionar Pre-commit Hooks com Husky
**Categoria**: Processos / Code Quality
**Problema Atual**:
- Commits com c√≥digo n√£o formatado
- Commits com linting errors
- Tests n√£o rodados antes de commit

**Proposta**:
Adicionar **Husky** + **lint-staged** para pre-commit hooks.

**Setup**:
```json
// package.json
{
  "husky": {
    "hooks": {
      "pre-commit": "lint-staged",
      "commit-msg": "commitlint -E HUSKY_GIT_PARAMS"
    }
  },
  "lint-staged": {
    "*.{ts,tsx}": [
      "eslint --fix",
      "prettier --write"
    ],
    "*.{go}": [
      "gofmt -w",
      "golangci-lint run"
    ],
    "*.py": [
      "black",
      "ruff check --fix"
    ]
  }
}
```

**Benef√≠cios**:
- ‚úÖ C√≥digo sempre formatado
- ‚úÖ Linting errors detectados antes de commit
- ‚úÖ Conventional commits enforced

**Esfor√ßo Estimado**: Muito Baixo (30min setup)
**Prioridade**: P2
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

### S035: Adicionar GitHub Actions Workflow Approval
**Categoria**: Processos / CI/CD
**Problema Atual**:
- Deploy para produ√ß√£o n√£o requer aprova√ß√£o
- Qualquer PR merged pode ir para prod automaticamente
- Risco de deploy acidental

**Proposta**:
Adicionar approval step para deploys de produ√ß√£o.

**Workflow**:
```yaml
# .github/workflows/deploy-prod.yml
jobs:
  deploy:
    runs-on: ubuntu-latest
    environment:
      name: production
      url: https://supercore.lbpay.com
    steps:
      - name: Deploy to Production
        run: kubectl apply -f k8s/prod/
```

**GitHub Environment Settings**:
```
Settings ‚Üí Environments ‚Üí production:
  ‚úÖ Required reviewers: @tech-lead, @cto
  ‚úÖ Wait timer: 0 minutes
  ‚úÖ Deployment branches: only main
```

**Benef√≠cios**:
- ‚úÖ Deploy de produ√ß√£o requer aprova√ß√£o
- ‚úÖ Evita deploys acidentais
- ‚úÖ Auditoria de quem aprovou

**Esfor√ßo Estimado**: Muito Baixo (15min setup)
**Prioridade**: P1 (importante para produ√ß√£o segura)
**Status**: ‚è≥ Aguardando Avalia√ß√£o

**Decis√£o**:
_[Deixar espa√ßo para decis√£o: Aprovar/Rejeitar/Revisar]_

**Justificativa**:
_[Deixar espa√ßo para justificativa da decis√£o]_

---

## üìä RESUMO

**Total de Sugest√µes**: 35
- üåü Cr√≠ticas (High Impact): 5
- üí° Importantes (Medium Impact): 15
- üîß Menores (Nice to Have): 15

**Status Geral**: ‚è≥ Aguardando Avalia√ß√£o

---

## üìà PRIORIZA√á√ÉO RECOMENDADA

### P0 - Implementar IMEDIATAMENTE (Bloqueadores de Produ√ß√£o)
1. S003 - OpenFGA (Authorization)
2. S004 - Grafana + Prometheus (Observability)
3. S011 - Vault (Secrets Management)
4. S013 - SAST/DAST (Security)

### P1 - Implementar ANTES de Produ√ß√£o
1. S001 - Temporal.io (Workflows dur√°veis)
2. S002 - DuckDB (Analytics)
3. S005 - LitmusChaos (Resili√™ncia)
4. S010 - Flagsmith (Feature Flags)
5. S012 - SonarQube (Code Quality)
6. S014 - Renovate (Dependency Updates)
7. S015 - OpenAPI Auto-Gen (API Docs)
8. S016 - Playwright E2E (Testing)
9. S017 - k6 Load Testing (Performance)
10. S018 - SLIs/SLOs/SLAs (SRE)
11. S019 - PagerDuty (Incident Management)
12. S035 - Workflow Approval (Seguran√ßa)

### P2 - Implementar AP√ìS Produ√ß√£o (Melhorias Cont√≠nuas)
1. S020 - ADRs (Documentation)
2. S030 - Storybook (Component Library)
3. S031 - Bundle Analyzer (Frontend Performance)
4. S032 - Lighthouse CI (Web Performance)
5. S033 - Conventional Commits (Versionamento)
6. S034 - Husky Pre-commit (Code Quality)

---

**Instru√ß√µes Finais**:
1. Avaliar sugest√µes P0 primeiro (cr√≠ticas para produ√ß√£o)
2. Criar tasks no backlog para sugest√µes aprovadas
3. Rejeitar sugest√µes que n√£o agregam valor (com justificativa)
4. Revisar sugest√µes que precisam de refinamento

---

**Vers√£o**: 1.0.0
**√öltima Atualiza√ß√£o**: 2025-12-21
**Pr√≥xima Revis√£o**: Ap√≥s avalia√ß√£o das sugest√µes P0
