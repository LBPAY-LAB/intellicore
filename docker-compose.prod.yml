version: '3.9'

# CoreBanking Brain - Production Docker Compose
# Sprint 20 - US-DB-025: Production Deployment Config
#
# Usage:
#   docker-compose -f docker-compose.prod.yml up -d
#
# Required environment variables (set in .env.production):
#   - POSTGRES_USER
#   - POSTGRES_PASSWORD
#   - POSTGRES_DB
#   - JWT_SECRET
#   - MINIO_ROOT_USER
#   - MINIO_ROOT_PASSWORD
#   - MEILI_MASTER_KEY
#   - OLLAMA_MODEL (default: llama3.3)

services:
  # ===========================================
  # Core Services
  # ===========================================

  server:
    build:
      context: ./server
      dockerfile: Dockerfile
    container_name: supercore-server
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - PORT=4000
      - DATABASE_URL=postgresql://${POSTGRES_USER}:${POSTGRES_PASSWORD}@postgres:5432/${POSTGRES_DB}
      - REDIS_HOST=valkey
      - REDIS_PORT=6379
      - MINIO_ENDPOINT=minio
      - MINIO_PORT=9000
      - MINIO_ACCESS_KEY=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_SECRET_KEY=${MINIO_ROOT_PASSWORD}
      - QDRANT_HOST=qdrant
      - QDRANT_PORT=6333
      - LLM_GATEWAY_URL=http://llm-gateway:8000
      - NEBULA_GRAPHD_HOST=nebula-graphd
      - NEBULA_GRAPHD_PORT=9669
      - MEILI_HOST=http://meilisearch:7700
      - MEILI_MASTER_KEY=${MEILI_MASTER_KEY}
      - JWT_SECRET=${JWT_SECRET}
      - JWT_EXPIRES_IN=1h
    ports:
      - "4000:4000"
    depends_on:
      postgres:
        condition: service_healthy
      valkey:
        condition: service_healthy
      minio:
        condition: service_healthy
      qdrant:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:4000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  client:
    build:
      context: ./client
      dockerfile: Dockerfile
    container_name: supercore-client
    restart: unless-stopped
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_GRAPHQL_URL=http://server:4000/graphql
    ports:
      - "3000:3000"
    depends_on:
      - server
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:3000"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # ===========================================
  # Databases
  # ===========================================

  postgres:
    image: postgres:16-alpine
    container_name: supercore-postgres
    restart: unless-stopped
    environment:
      - POSTGRES_DB=${POSTGRES_DB:-lbpay}
      - POSTGRES_USER=${POSTGRES_USER:-lbpay}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - PGDATA=/var/lib/postgresql/data/pgdata
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ./init-db.sql:/docker-entrypoint-initdb.d/init.sql:ro
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER:-lbpay} -d ${POSTGRES_DB:-lbpay}"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
    logging:
      driver: "json-file"
      options:
        max-size: "100m"
        max-file: "5"

  valkey:
    image: valkey/valkey:latest
    container_name: supercore-valkey
    restart: unless-stopped
    command: valkey-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    volumes:
      - valkey_data:/data
    healthcheck:
      test: ["CMD", "valkey-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ===========================================
  # CoreBanking Brain - AI Services
  # ===========================================

  qdrant:
    image: qdrant/qdrant:latest
    container_name: supercore-qdrant
    restart: unless-stopped
    environment:
      QDRANT__SERVICE__GRPC_PORT: 6334
      QDRANT__STORAGE__OPTIMIZERS__DEFAULT_SEGMENT_NUMBER: 4
      QDRANT__STORAGE__PERFORMANCE__MAX_SEARCH_THREADS: 4
    volumes:
      - qdrant_data:/qdrant/storage
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:6333/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

  ollama:
    image: ollama/ollama:latest
    container_name: supercore-ollama
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '4'
          memory: 8G
        reservations:
          cpus: '1'
          memory: 4G

  llm-gateway:
    build:
      context: ./llm-gateway
      dockerfile: Dockerfile
    container_name: supercore-llm-gateway
    restart: unless-stopped
    environment:
      - OLLAMA_URL=http://ollama:11434
      - VALKEY_URL=redis://valkey:6379
      - LOG_LEVEL=WARNING
      - DEBUG=false
      - RATE_LIMIT_PER_MINUTE=20
    depends_on:
      ollama:
        condition: service_healthy
      valkey:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # ===========================================
  # CoreBanking Brain - NebulaGraph Cluster
  # ===========================================

  nebula-metad:
    image: vesoft/nebula-metad:v3.8.0
    container_name: supercore-nebula-metad
    restart: unless-stopped
    environment:
      USER: root
      TZ: America/Sao_Paulo
    command:
      - --meta_server_addrs=nebula-metad:9559
      - --local_ip=nebula-metad
      - --ws_ip=nebula-metad
      - --port=9559
      - --ws_http_port=19559
      - --data_path=/data/meta
      - --log_dir=/logs
      - --v=0
      - --minloglevel=2
    volumes:
      - nebula_metad_data:/data/meta
      - nebula_metad_logs:/logs
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  nebula-storaged:
    image: vesoft/nebula-storaged:v3.8.0
    container_name: supercore-nebula-storaged
    restart: unless-stopped
    environment:
      USER: root
      TZ: America/Sao_Paulo
    command:
      - --meta_server_addrs=nebula-metad:9559
      - --local_ip=nebula-storaged
      - --ws_ip=nebula-storaged
      - --port=9779
      - --ws_http_port=19779
      - --data_path=/data/storage
      - --log_dir=/logs
      - --v=0
      - --minloglevel=2
    depends_on:
      - nebula-metad
    volumes:
      - nebula_storaged_data:/data/storage
      - nebula_storaged_logs:/logs
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  nebula-graphd:
    image: vesoft/nebula-graphd:v3.8.0
    container_name: supercore-nebula-graphd
    restart: unless-stopped
    environment:
      USER: root
      TZ: America/Sao_Paulo
    command:
      - --meta_server_addrs=nebula-metad:9559
      - --local_ip=nebula-graphd
      - --ws_ip=nebula-graphd
      - --port=9669
      - --ws_http_port=19669
      - --log_dir=/logs
      - --v=0
      - --minloglevel=2
    depends_on:
      - nebula-metad
      - nebula-storaged
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  # ===========================================
  # Search & Storage Services
  # ===========================================

  meilisearch:
    image: getmeili/meilisearch:v1.11
    container_name: supercore-meilisearch
    restart: unless-stopped
    environment:
      MEILI_MASTER_KEY: ${MEILI_MASTER_KEY}
      MEILI_ENV: production
      MEILI_NO_ANALYTICS: true
    volumes:
      - meilisearch_data:/meili_data
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--spider", "http://localhost:7700/health"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '1'
          memory: 1G

  minio:
    image: minio/minio:latest
    container_name: supercore-minio
    restart: unless-stopped
    command: server /data --console-address ":9001"
    environment:
      - MINIO_ROOT_USER=${MINIO_ROOT_USER:-minioadmin}
      - MINIO_ROOT_PASSWORD=${MINIO_ROOT_PASSWORD}
    volumes:
      - minio_data:/data
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 30s
      timeout: 20s
      retries: 3
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '0.5'
          memory: 512M

  # ===========================================
  # Load Balancer / Reverse Proxy
  # ===========================================

  nginx:
    image: nginx:alpine
    container_name: supercore-nginx
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./nginx/ssl:/etc/nginx/ssl:ro
    depends_on:
      - server
      - client
    networks:
      - supercore-network
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 128M
    logging:
      driver: "json-file"
      options:
        max-size: "50m"
        max-file: "3"

# ===========================================
# Volumes
# ===========================================

volumes:
  postgres_data:
    driver: local
  valkey_data:
    driver: local
  meilisearch_data:
    driver: local
  minio_data:
    driver: local
  qdrant_data:
    driver: local
  ollama_data:
    driver: local
  nebula_metad_data:
    driver: local
  nebula_metad_logs:
    driver: local
  nebula_storaged_data:
    driver: local
  nebula_storaged_logs:
    driver: local

# ===========================================
# Networks
# ===========================================

networks:
  supercore-network:
    driver: bridge
    ipam:
      config:
        - subnet: 172.28.0.0/16
