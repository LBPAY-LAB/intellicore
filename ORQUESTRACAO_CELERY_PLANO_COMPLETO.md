# ðŸŽ¯ OrquestraÃ§Ã£o Celery - Plano Completo e Sequencial

**VersÃ£o**: 2.0.0 (Integrado com COORDINATION_RECOMMENDATIONS.md)
**Data**: 2025-12-27
**Status**: ðŸ“‹ PLANO APROVADO - OPÃ‡ÃƒO A
**PrÃ³ximo Passo**: ImplementaÃ§Ã£o Fase 1

---

## ðŸ“Š Executive Summary

Este documento integra:
1. **ORCHESTRATION_REIMPLEMENTATION_PLAN.md** - Infraestrutura Celery + Meta-Orchestrator + Agent Owners
2. **COORDINATION_RECOMMENDATIONS.md** - Pipeline de validaÃ§Ã£o + Correction loops + Integration tests

**Objetivo**: Sistema de orquestraÃ§Ã£o 100% autÃ´nomo, production-ready, com validaÃ§Ã£o em cascata.

### Gap Analysis Consolidado

**Estado Atual**:
- âœ… **3 Agent Owners Completos**: Product (v3.1), Architecture (v1.0.0), Infrastructure (v1.0.0)
- âœ… **3 Validation Agents Completos**: Verification, LLM-Judge, Debugging (NÃƒO INTEGRADOS)
- âš ï¸ **3 Agent Owners Incompletos**: Frontend, Backend, QA (apenas skeletons)
- âŒ **Celery Infrastructure Ausente**: `tasks.py`, `celery_app.py` nÃ£o existem
- âŒ **Meta-Orchestrator Ausente**: Sem coordenador centralizado com state machine
- âŒ **Correction Loop Ausente**: QA rejeita mas nada acontece
- âŒ **$59k/ano desperdiÃ§ado**: Validation agents prontos mas nÃ£o usados

**ROI Total**:
- **OrquestraÃ§Ã£o**: $133k/ano (sistema autÃ´nomo)
- **CoordenaÃ§Ã£o**: $240k/ano (validation pipeline + correction loops)
- **TOTAL**: **$373k/ano** em economia/produtividade

**EsforÃ§o Total**: ~191 horas (~24 dias de desenvolvimento, 1 dev full-time)

---

## ðŸ—ï¸ Arquitetura Completa

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Portal de Monitoramento (React + FastAPI)                       â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ - Dashboard em tempo real (SSE)                                 â”‚
â”‚ - Cards por status (TODO, IN_PROGRESS, VALIDATING, APPROVED)   â”‚
â”‚ - Rejection history (Top 10 reasons)                            â”‚
â”‚ - Cost tracking por card                                        â”‚
â”‚ - Human Review Panel (Escalated cards)                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ REST API + SSE
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Meta-Orchestrator (autonomous_meta_orchestrator.py)             â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ RESPONSABILIDADES:                                              â”‚
â”‚ 1. Load backlog_master.json (source of truth)                  â”‚
â”‚ 2. Build dependency graph                                       â”‚
â”‚ 3. STATE MACHINE:                                               â”‚
â”‚    TODO â†’ IN_PROGRESS â†’ VALIDATING â†’ APPROVED/REJECTED         â”‚
â”‚         â†‘_____________CORRECTING_______________|                â”‚
â”‚ 4. Enqueue ready cards to Celery queues                        â”‚
â”‚ 5. Monitor task results (listen for APPROVED/REJECTED)         â”‚
â”‚ 6. Create correction cards (max 3 attempts)                    â”‚
â”‚ 7. Escalate apÃ³s 3 falhas (human review)                       â”‚
â”‚ 8. Checkpoints (save backlog a cada N cards)                   â”‚
â”‚ 9. Emit SSE events to Portal                                   â”‚
â”‚ 10. Cost tracking aggregation                                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ celery.send_task()
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Celery + Redis (Message Broker + Result Backend)               â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ QUEUES:                                                          â”‚
â”‚ - squadOS.owners     (Owner agents execution)                   â”‚
â”‚ - squadOS.validation (Verification, LLM-Judge, QA)              â”‚
â”‚ - squadOS.debugging  (Debugging agent)                          â”‚
â”‚ - squadOS.failed     (Dead Letter Queue)                        â”‚
â”‚                                                                  â”‚
â”‚ WORKERS: 5Ã— concurrent (configurable)                           â”‚
â”‚ RETRY: 3Ã— with exponential backoff                              â”‚
â”‚ BROKER: Redis localhost:6379 DB 2                               â”‚
â”‚ BACKEND: Redis localhost:6379 DB 2                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚ Task Dispatch
                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Celery Tasks (tasks.py)                                         â”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” â”‚
â”‚ @celery_app.task(bind=True, max_retries=3)                      â”‚
â”‚ def execute_owner_task(card_id, card_type, card_data):          â”‚
â”‚     agent = get_agent_owner(card_type)                          â”‚
â”‚     result = agent.execute(card_data)                            â”‚
â”‚     return TaskResult(...)                                       â”‚
â”‚                                                                  â”‚
â”‚ @celery_app.task                                                â”‚
â”‚ def execute_verification(card_id, artifacts):                   â”‚
â”‚     return verification_agent.execute(card_id, artifacts)       â”‚
â”‚                                                                  â”‚
â”‚ @celery_app.task                                                â”‚
â”‚ def execute_llm_judge(card_id, artifacts):                      â”‚
â”‚     return llm_judge_agent.execute(card_id, artifacts)          â”‚
â”‚                                                                  â”‚
â”‚ @celery_app.task                                                â”‚
â”‚ def execute_qa(card_id, artifacts):                             â”‚
â”‚     return qa_owner_agent.execute(card_id, artifacts)           â”‚
â”‚                                                                  â”‚
â”‚ @celery_app.task                                                â”‚
â”‚ def execute_debugging(card_id, failure_logs):                   â”‚
â”‚     return debugging_agent.investigate(card_id, failure_logs)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                 â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â–¼                 â–¼              â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ Owner Agents â”‚  â”‚ Validation   â”‚  â”‚ Debuggingâ”‚  â”‚ Correctionâ”‚
â”‚ â”â”â”â”â”â”â”â”â”â”â” â”‚  â”‚ Pipeline     â”‚  â”‚ Agent    â”‚  â”‚ Card      â”‚
â”‚ Product      â”‚  â”‚ â”â”â”â”â”â”â”â”â”â”â” â”‚  â”‚ â”â”â”â”â”â”â” â”‚  â”‚ System    â”‚
â”‚ Architecture â”‚  â”‚ 1. Verif.    â”‚  â”‚ 4 phases:â”‚  â”‚ â”â”â”â”â”â”â”â” â”‚
â”‚ Frontend     â”‚  â”‚ 2. LLM-Judge â”‚  â”‚ - Invest â”‚  â”‚ Auto-     â”‚
â”‚ Backend      â”‚  â”‚ 3. QA Owner  â”‚  â”‚ - Patternâ”‚  â”‚ create    â”‚
â”‚ QA           â”‚  â”‚              â”‚  â”‚ - Hypoth â”‚  â”‚ on REJECT â”‚
â”‚ Infra        â”‚  â”‚ PASS â†’ Next  â”‚  â”‚ - Fix    â”‚  â”‚           â”‚
â”‚              â”‚  â”‚ FAIL â†’ Corr. â”‚  â”‚          â”‚  â”‚ Max 3     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜  â”‚ attempts  â”‚
       â”‚                 â”‚               â”‚         â”‚           â”‚
       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Artifact Storage            â”‚
            â”‚ (app-artefacts/)            â”‚
            â”‚ - produto/                  â”‚
            â”‚ - arquitetura/              â”‚
            â”‚ - engenharia/frontend/      â”‚
            â”‚ - engenharia/backend/       â”‚
            â”‚ - qa/                       â”‚
            â”‚ - deploy/                   â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Card Lifecycle Completo

```
1. ENQUEUE
   â”œâ”€ Meta-Orchestrator: Load card from backlog_master.json
   â”œâ”€ Check dependencies met
   â””â”€ Enqueue to Celery (squadOS.owners queue)

2. OWNER EXECUTION
   â”œâ”€ Celery worker picks task
   â”œâ”€ Execute owner agent (Product/Architecture/Frontend/Backend/QA/Infra)
   â”œâ”€ Generate artifacts
   â”œâ”€ Save checkpoint (Redis)
   â””â”€ Return TaskResult with artifacts

3. VALIDATION PIPELINE (SEQUENTIAL + PARALLEL)
   â”œâ”€ Stage 1: Verification Agent (BLOCKER)
   â”‚   â”œâ”€ Check evidence (files exist, tests ran, etc)
   â”‚   â”œâ”€ Red flag detection (obra ow-002)
   â”‚   â””â”€ FAIL â†’ Create Correction Card â†’ GOTO 6
   â”‚
   â”œâ”€ Stage 2: LLM-Judge + QA Owner (PARALLEL)
   â”‚   â”œâ”€ LLM-Judge: Score artifacts (rubric â‰¥8.0?)
   â”‚   â”œâ”€ QA Owner: Functional tests, security scans
   â”‚   â””â”€ BOTH PASS â†’ GOTO 4
   â”‚       ANY FAIL â†’ Create Correction Card â†’ GOTO 6
   â”‚
   â””â”€ Cost tracking (all LLM calls)

4. APPROVAL
   â”œâ”€ Update backlog: status = "APPROVED"
   â”œâ”€ Mark dependencies satisfied
   â”œâ”€ Emit event: card.approved
   â””â”€ Enqueue dependent cards (if any)

5. COMPLETION
   â”œâ”€ Card marked DONE
   â””â”€ Proceed to next stage (e.g., Architecture â†’ Frontend/Backend)

6. CORRECTION (IF REJECTED)
   â”œâ”€ Attempt counter++
   â”œâ”€ IF attempt â‰¤ 3:
   â”‚   â”œâ”€ Create correction card (ARQ-001-CORR-{attempt})
   â”‚   â”œâ”€ Include validation_history + feedback
   â”‚   â”œâ”€ IF attempt >= 2 AND repeated failure:
   â”‚   â”‚   â””â”€ Trigger Debugging Agent (root cause investigation)
   â”‚   â””â”€ Enqueue correction card â†’ GOTO 2 (retry)
   â”‚
   â””â”€ IF attempt > 3:
       â”œâ”€ Escalate to human (Tech Lead)
       â”œâ”€ Create ESCALATION card
       â”œâ”€ Status = "AWAITING_HUMAN"
       â””â”€ Portal shows Human Review Panel

7. HUMAN REVIEW (OPTIONAL)
   â”œâ”€ Tech Lead reviews escalated card
   â”œâ”€ Options:
   â”‚   â”œâ”€ Approve Override â†’ GOTO 4
   â”‚   â”œâ”€ Reject Permanently â†’ ABORT
   â”‚   â””â”€ Request Clarification â†’ Add context â†’ GOTO 6
   â””â”€ Audit log (who, when, why)
```

---

## ðŸ“‹ Plano de ImplementaÃ§Ã£o Sequencial

### VisÃ£o Geral das Fases

| Fase | Foco | EsforÃ§o | DuraÃ§Ã£o | ROI |
|------|------|---------|---------|-----|
| **Fase 0** | Setup Celery + Redis | 6h | 1 dia | FundaÃ§Ã£o |
| **Fase 1** | Meta-Orchestrator + State Machine | 20h | 2-3 dias | $20k/ano |
| **Fase 2** | Validation Pipeline | 28h | 3-4 dias | $59k/ano |
| **Fase 3** | Correction Loop + Debugging | 18h | 2-3 dias | $35k/ano |
| **Fase 4** | Agent Owners Completos | 48h | 6 dias | $133k/ano |
| **Fase 5** | Integration Tests | 24h | 3 dias | $12k/ano |
| **Fase 6** | Portal Simples | 32h | 4 dias | $8k/ano |
| **Fase 7** | Observability + Cost Tracking | 15h | 2 dias | $10k/ano |
| **TOTAL** | - | **191h** | **24 dias** | **$277k/ano** |

---

## ðŸš€ Fase 0: Setup Celery + Redis (1 dia)

**Objetivo**: Infraestrutura bÃ¡sica funcionando (Celery + Redis + Hello World task)

### Tarefas

#### 1. Instalar dependÃªncias
```bash
cd /Users/jose.silva.lb/LBPay/supercore/squadOS/app-execution

# Instalar Celery + Redis
pip install celery[redis]==5.3.4 redis==5.0.1

# Verificar Redis rodando
redis-cli ping  # deve retornar "PONG"
```

#### 2. Criar `celery_app.py`
```python
# squadOS/app-execution/celery_app.py
from celery import Celery
import os

# ConfiguraÃ§Ã£o
REDIS_HOST = os.getenv('REDIS_HOST', 'localhost')
REDIS_PORT = int(os.getenv('REDIS_PORT', 6379))
REDIS_DB = int(os.getenv('REDIS_DB', 2))

BROKER_URL = f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'
BACKEND_URL = f'redis://{REDIS_HOST}:{REDIS_PORT}/{REDIS_DB}'

# Celery app
celery_app = Celery(
    'squadOS',
    broker=BROKER_URL,
    backend=BACKEND_URL,
    include=['tasks']  # Import tasks module
)

# ConfiguraÃ§Ã£o avanÃ§ada
celery_app.conf.update(
    # SerializaÃ§Ã£o
    task_serializer='json',
    accept_content=['json'],
    result_serializer='json',

    # Timezone
    timezone='UTC',
    enable_utc=True,

    # Rotas de tasks
    task_routes={
        'tasks.execute_owner_task': {'queue': 'squadOS.owners'},
        'tasks.execute_verification': {'queue': 'squadOS.validation'},
        'tasks.execute_llm_judge': {'queue': 'squadOS.validation'},
        'tasks.execute_qa': {'queue': 'squadOS.validation'},
        'tasks.execute_debugging': {'queue': 'squadOS.debugging'},
    },

    # Prioridades
    task_default_priority=5,
    task_queue_max_priority=10,

    # Retry/timeout
    task_acks_late=True,
    worker_prefetch_multiplier=1,
    task_time_limit=3600,  # 1 hour hard limit
    task_soft_time_limit=3000,  # 50 min soft limit

    # Result expiration
    result_expires=3600,  # 1 hour

    # Dead Letter Queue
    task_reject_on_worker_lost=True,
    task_send_sent_event=True,
)

if __name__ == '__main__':
    celery_app.start()
```

#### 3. Criar `tasks.py` (Hello World)
```python
# squadOS/app-execution/tasks.py
from celery_app import celery_app
import logging
import time

logger = logging.getLogger(__name__)

@celery_app.task(bind=True, name='tasks.hello_world')
def hello_world(self, name: str):
    """Test task to validate Celery setup"""
    logger.info(f"Hello World task started for {name}")
    time.sleep(2)  # Simulate work
    return f"Hello, {name}! Task ID: {self.request.id}"
```

#### 4. Testar Celery
```bash
# Terminal 1: Start Celery worker
cd /Users/jose.silva.lb/LBPay/supercore/squadOS/app-execution
celery -A celery_app worker --loglevel=info --concurrency=5

# Terminal 2: Test task
python -c "
from tasks import hello_world
result = hello_world.delay('SquadOS')
print(f'Task ID: {result.id}')
print(f'Result: {result.get(timeout=10)}')
"
```

**Expected Output**:
```
Task ID: abc123...
Result: Hello, SquadOS! Task ID: abc123...
```

#### 5. Configurar supervisord (opcional, para produÃ§Ã£o)
```ini
# squadOS/app-execution/supervisord.conf
[program:celery_worker]
command=celery -A celery_app worker --loglevel=info --concurrency=5
directory=/Users/jose.silva.lb/LBPay/supercore/squadOS/app-execution
autostart=true
autorestart=true
stderr_logfile=/var/log/celery/worker.err.log
stdout_logfile=/var/log/celery/worker.out.log
```

### CritÃ©rios de Sucesso
- âœ… Celery worker inicia sem erros
- âœ… `hello_world` task executa e retorna resultado
- âœ… Redis mostra tasks enfileirados (`redis-cli LLEN celery`)
- âœ… Logs estruturados aparecem no terminal

**EsforÃ§o**: 6h
**Deliverable**: Celery + Redis funcionando

---

## ðŸŽ¯ Fase 1: Meta-Orchestrator + State Machine (2-3 dias)

**Objetivo**: Coordenador centralizado que gerencia lifecycle de cards com state machine completa.

### Componentes a Criar

#### 1. Schema `TaskResult` (retorno padronizado)
```python
# squadOS/app-execution/models.py
from typing import TypedDict, Literal, Optional, List, Dict

class ValidationResult(TypedDict):
    validator: str  # "verification_agent", "llm_judge", "qa_owner"
    result: Literal["PASSED", "FAILED"]
    score: Optional[float]  # LLM-Judge score (0-10)
    reasons: List[str]
    feedback: Dict[str, str]

class TaskResult(TypedDict):
    card_id: str
    status: Literal["success", "failed", "rejected"]
    stage: str  # qual stage completou ("architecture_design", "frontend_component", etc)
    artifacts: List[Dict[str, str]]  # [{"type": "design", "path": "..."}]
    validation: Optional[ValidationResult]
    next_actions: List[str]  # ["verify_evidence", "run_llm_judge", "create_correction"]
    error: Optional[str]
    elapsed_time: float
    cost: Optional[Dict[str, float]]  # {"total_tokens": 15000, "cost_usd": 0.08}
```

#### 2. Estender `backlog_master.json` schema
```json
{
  "project": "SuperCore v2.0",
  "cards": [
    {
      "id": "ARQ-001",
      "type": "ARCH",
      "title": "Design architecture for RF001",
      "status": "CORRECTING",
      "attempt": 2,
      "current_stage": "architecture_design",
      "blocking_issue": "API contract missing",
      "next_action": "create_correction_card",
      "dependencies": ["PROD-001"],
      "validation_history": [
        {
          "attempt": 1,
          "validator": "verification_agent",
          "result": "FAILED",
          "reasons": ["Missing API contract for /oracles endpoint"],
          "timestamp": "2025-12-27T10:30:00Z"
        },
        {
          "attempt": 2,
          "validator": "llm_judge",
          "result": "FAILED",
          "score": 7.2,
          "reasons": ["Design document lacks error handling section"],
          "timestamp": "2025-12-27T11:15:00Z"
        }
      ],
      "artifacts": [
        {"type": "design", "path": "app-artefacts/arquitetura/designs/design-RF001.md"}
      ],
      "task_id": "abc123...",
      "escalation_needed": false,
      "cost_tracking": {
        "total_tokens": 15000,
        "total_cost_usd": 0.08,
        "attempts": 2
      },
      "created_at": "2025-12-27T10:00:00Z",
      "started_at": "2025-12-27T10:15:00Z",
      "completed_at": null
    }
  ],
  "metadata": {
    "total_cards": 121,
    "phase": "Fase 1 - FundaÃ§Ã£o",
    "last_updated": "2025-12-27T11:15:00Z"
  }
}
```

#### 3. Meta-Orchestrator com State Machine
```python
# squadOS/app-execution/autonomous_meta_orchestrator.py
import json
import time
import logging
from pathlib import Path
from typing import Dict, List, Set, Optional
from datetime import datetime
from collections import defaultdict

from celery.result import AsyncResult
from tasks import execute_owner_task, execute_verification, execute_llm_judge, execute_qa
from models import TaskResult, ValidationResult

logger = logging.getLogger(__name__)

# State transitions
# TODO â†’ IN_PROGRESS â†’ VALIDATING â†’ APPROVED/REJECTED
#        â†‘____________CORRECTING_____________|

VALID_TRANSITIONS = {
    "TODO": ["IN_PROGRESS"],
    "IN_PROGRESS": ["VALIDATING", "FAILED"],
    "VALIDATING": ["APPROVED", "REJECTED", "CORRECTING"],
    "CORRECTING": ["IN_PROGRESS"],
    "REJECTED": ["CORRECTING", "ESCALATED"],
    "APPROVED": ["DONE"],
    "ESCALATED": ["AWAITING_HUMAN"],
    "AWAITING_HUMAN": ["APPROVED", "REJECTED"],  # apÃ³s human review
}

class MetaOrchestrator:
    """
    Coordenador centralizado de Agent Owners via Celery

    Responsabilidades:
    1. Load backlog_master.json
    2. Build dependency graph
    3. State machine (TODO â†’ IN_PROGRESS â†’ VALIDATING â†’ APPROVED/REJECTED)
    4. Enqueue ready cards
    5. Monitor Celery tasks
    6. Handle failures (create correction cards, max 3 attempts)
    7. Escalate apÃ³s 3 falhas
    8. Checkpoints
    9. Emit SSE events
    """

    MAX_ATTEMPTS = 3
    CHECKPOINT_INTERVAL = 10  # Save backlog every 10 cards
    POLL_INTERVAL = 5  # Poll Celery every 5 seconds

    def __init__(self, backlog_path: Path, state_dir: Path):
        self.backlog_path = backlog_path
        self.state_dir = state_dir
        self.backlog = self.load_backlog()
        self.dependency_graph = self.build_dependency_graph()
        self.active_tasks: Dict[str, AsyncResult] = {}
        self.completed_cards: Set[str] = set()
        self.failed_cards: Set[str] = set()
        self.escalated_cards: Set[str] = set()
        self.cards_processed = 0

    def load_backlog(self) -> Dict:
        """Load backlog_master.json"""
        if not self.backlog_path.exists():
            logger.error(f"Backlog not found: {self.backlog_path}")
            raise FileNotFoundError(f"Backlog not found: {self.backlog_path}")

        with open(self.backlog_path, 'r') as f:
            backlog = json.load(f)

        logger.info(f"Loaded backlog: {len(backlog['cards'])} cards")
        return backlog

    def save_backlog(self):
        """Save backlog_master.json (checkpoint)"""
        self.backlog['metadata']['last_updated'] = datetime.utcnow().isoformat()

        with open(self.backlog_path, 'w') as f:
            json.dump(self.backlog, f, indent=2)

        logger.info(f"Checkpoint saved: {self.backlog_path}")

    def build_dependency_graph(self) -> Dict[str, List[str]]:
        """Build dependency graph {card_id: [dependency_ids]}"""
        graph = {}
        for card in self.backlog['cards']:
            graph[card['id']] = card.get('dependencies', [])

        logger.info(f"Dependency graph built: {len(graph)} nodes")
        return graph

    def get_card(self, card_id: str) -> Optional[Dict]:
        """Get card by ID"""
        return next((c for c in self.backlog['cards'] if c['id'] == card_id), None)

    def transition_state(self, card_id: str, new_status: str):
        """Transition card state (validar transiÃ§Ã£o vÃ¡lida)"""
        card = self.get_card(card_id)
        if not card:
            logger.error(f"Card {card_id} not found")
            return

        old_status = card['status']

        # Validar transiÃ§Ã£o
        if new_status not in VALID_TRANSITIONS.get(old_status, []):
            logger.warning(f"Invalid transition for {card_id}: {old_status} â†’ {new_status}")
            # Permitir (log warning mas nÃ£o bloquear)

        card['status'] = new_status
        logger.info(f"Card {card_id}: {old_status} â†’ {new_status}")

    def get_ready_cards(self) -> List[Dict]:
        """Return cards with status=TODO and all dependencies met"""
        ready = []
        for card in self.backlog['cards']:
            if card['status'] != 'TODO':
                continue

            deps = self.dependency_graph.get(card['id'], [])
            if all(dep in self.completed_cards for dep in deps):
                ready.append(card)

        return ready

    def enqueue_card(self, card: Dict):
        """Enqueue card to Celery"""
        card_id = card['id']
        card_type = card_id.split('-')[0]  # "PROD-001" â†’ "PROD"

        logger.info(f"Enqueuing card {card_id} (type: {card_type})")

        # Update status
        self.transition_state(card_id, 'IN_PROGRESS')
        card['started_at'] = datetime.utcnow().isoformat()

        # Send to Celery
        task = execute_owner_task.apply_async(
            args=[card_id, card_type, card],
            queue='squadOS.owners',
            priority=self.get_priority(card),
        )

        # Track task
        self.active_tasks[card_id] = task
        card['task_id'] = task.id

        logger.info(f"Card {card_id} enqueued with task_id={task.id}")

    def get_priority(self, card: Dict) -> int:
        """Calculate priority (higher = more urgent)"""
        priority_map = {"CRITICAL": 10, "HIGH": 7, "MEDIUM": 5, "LOW": 3}
        return priority_map.get(card.get('priority', 'MEDIUM'), 5)

    def monitor_tasks(self):
        """Check status of active Celery tasks"""
        for card_id, task in list(self.active_tasks.items()):
            if task.ready():
                # Task finished (success or failure)
                if task.successful():
                    result: TaskResult = task.result
                    self.handle_owner_success(card_id, result)
                else:
                    error = task.info  # Exception info
                    self.handle_owner_failure(card_id, error)

    def handle_owner_success(self, card_id: str, result: TaskResult):
        """Handle successful owner execution â†’ Start validation pipeline"""
        logger.info(f"Card {card_id} owner execution completed")

        card = self.get_card(card_id)
        card['artifacts'] = result['artifacts']
        card['elapsed_time'] = result.get('elapsed_time', 0)

        # Update cost tracking
        if result.get('cost'):
            card.setdefault('cost_tracking', {})
            card['cost_tracking']['total_tokens'] = card['cost_tracking'].get('total_tokens', 0) + result['cost']['total_tokens']
            card['cost_tracking']['total_cost_usd'] = card['cost_tracking'].get('total_cost_usd', 0) + result['cost']['cost_usd']

        # Remove from active tasks
        del self.active_tasks[card_id]

        # Transition to VALIDATING
        self.transition_state(card_id, 'VALIDATING')

        # Enqueue validation pipeline
        self.enqueue_validation_pipeline(card_id, result['artifacts'])

    def enqueue_validation_pipeline(self, card_id: str, artifacts: List[Dict]):
        """
        Enqueue validation pipeline:
        1. Verification Agent (blocker)
        2. LLM-Judge + QA Owner (parallel) - SE Verification PASS
        """
        logger.info(f"Starting validation pipeline for {card_id}")

        # Stage 1: Verification Agent (blocker)
        verification_task = execute_verification.apply_async(
            args=[card_id, artifacts],
            queue='squadOS.validation',
        )

        # Track verification task
        self.active_tasks[f"{card_id}:verification"] = verification_task

    def handle_verification_result(self, card_id: str, result: ValidationResult):
        """Handle Verification Agent result"""
        card = self.get_card(card_id)

        # Add to validation_history
        card.setdefault('validation_history', []).append({
            'attempt': card.get('attempt', 1),
            'validator': 'verification_agent',
            'result': result['result'],
            'reasons': result.get('reasons', []),
            'timestamp': datetime.utcnow().isoformat()
        })

        if result['result'] == 'FAILED':
            logger.warning(f"Card {card_id} failed Verification: {result['reasons']}")
            self.create_correction_card(card_id, result)
        else:
            # Verification PASSED â†’ Enqueue LLM-Judge + QA Owner (parallel)
            logger.info(f"Card {card_id} passed Verification â†’ Running LLM-Judge + QA")

            judge_task = execute_llm_judge.apply_async(
                args=[card_id, card['artifacts']],
                queue='squadOS.validation',
            )
            qa_task = execute_qa.apply_async(
                args=[card_id, card['artifacts']],
                queue='squadOS.validation',
            )

            # Track parallel tasks
            self.active_tasks[f"{card_id}:llm_judge"] = judge_task
            self.active_tasks[f"{card_id}:qa"] = qa_task

    def handle_validation_complete(self, card_id: str, judge_result: ValidationResult, qa_result: Dict):
        """Handle completion of LLM-Judge + QA Owner (parallel)"""
        card = self.get_card(card_id)

        # Add results to validation_history
        card['validation_history'].append({
            'attempt': card.get('attempt', 1),
            'validator': 'llm_judge',
            'result': judge_result['result'],
            'score': judge_result.get('score'),
            'reasons': judge_result.get('reasons', []),
            'timestamp': datetime.utcnow().isoformat()
        })

        card['validation_history'].append({
            'attempt': card.get('attempt', 1),
            'validator': 'qa_owner',
            'result': 'PASSED' if qa_result['decision'] == 'APPROVED' else 'FAILED',
            'reasons': qa_result.get('reasons', []),
            'timestamp': datetime.utcnow().isoformat()
        })

        # Check if BOTH passed
        if judge_result['result'] == 'PASSED' and qa_result['decision'] == 'APPROVED':
            # APPROVED
            self.handle_approval(card_id)
        else:
            # REJECTED
            reasons = []
            if judge_result['result'] == 'FAILED':
                reasons.extend(judge_result['reasons'])
            if qa_result['decision'] == 'REJECTED':
                reasons.extend(qa_result['reasons'])

            self.create_correction_card(card_id, {'result': 'FAILED', 'reasons': reasons})

    def handle_approval(self, card_id: str):
        """Card approved â†’ Mark DONE, enqueue dependents"""
        logger.info(f"âœ… Card {card_id} APPROVED")

        card = self.get_card(card_id)
        self.transition_state(card_id, 'APPROVED')
        card['completed_at'] = datetime.utcnow().isoformat()

        # Add to completed set
        self.completed_cards.add(card_id)
        self.cards_processed += 1

        # Emit event
        self.emit_event('card.approved', {'card_id': card_id})

        # Checkpoint
        if self.cards_processed % self.CHECKPOINT_INTERVAL == 0:
            self.save_backlog()

        # Enqueue dependent cards
        self.enqueue_dependents(card_id)

    def create_correction_card(self, card_id: str, validation_result: ValidationResult):
        """Create correction card (max 3 attempts)"""
        card = self.get_card(card_id)
        attempt = card.get('attempt', 0) + 1

        logger.warning(f"Creating correction card for {card_id} (attempt {attempt})")

        if attempt > self.MAX_ATTEMPTS:
            # Escalate to human
            logger.error(f"Card {card_id} exceeded {self.MAX_ATTEMPTS} attempts â†’ ESCALATING")
            self.escalate_card(card_id)
            return

        # Check if repeated failure (trigger Debugging Agent)
        trigger_debugging = False
        if attempt >= 2:
            last_failure = card['validation_history'][-1]['reasons']
            prev_failure = card['validation_history'][-2]['reasons']
            if last_failure == prev_failure:
                logger.warning(f"Repeated failure detected for {card_id} â†’ Triggering Debugging Agent")
                trigger_debugging = True

        # Create correction card
        correction_card_id = f"{card_id}-CORR-{attempt}"
        correction_card = {
            'id': correction_card_id,
            'type': 'CORRECTION',
            'parent_card': card_id,
            'attempt': attempt,
            'status': 'TODO',
            'title': f"Correction for {card['title']}",
            'original_context': card.copy(),
            'rejection_reasons': validation_result['reasons'],
            'validator_feedback': validation_result.get('feedback', {}),
            'debugging_suggestions': [],
            'owner': card.get('owner'),
            'dependencies': [],
            'created_at': datetime.utcnow().isoformat()
        }

        # If debugging triggered, run Debugging Agent
        if trigger_debugging:
            from tasks import execute_debugging
            debug_result = execute_debugging.delay(
                card_id=card_id,
                failure_logs=card['validation_history']
            ).get(timeout=300)

            correction_card['root_cause'] = debug_result.get('root_cause')
            correction_card['debugging_suggestions'] = debug_result.get('fix_suggestions', [])

        # Add correction card to backlog
        self.backlog['cards'].append(correction_card)
        self.backlog['metadata']['total_cards'] += 1

        # Update original card
        card['attempt'] = attempt
        self.transition_state(card_id, 'CORRECTING')

        # Save backlog
        self.save_backlog()

        logger.info(f"Correction card created: {correction_card_id}")

        # Emit event
        self.emit_event('card.correction_created', {
            'card_id': card_id,
            'correction_card_id': correction_card_id,
            'attempt': attempt,
            'reasons': validation_result['reasons']
        })

    def escalate_card(self, card_id: str):
        """Escalate card to human (Tech Lead) apÃ³s 3 falhas"""
        card = self.get_card(card_id)

        escalation_card = {
            'id': f"{card_id}-ESC",
            'type': 'ESCALATION',
            'parent_card': card_id,
            'status': 'AWAITING_HUMAN',
            'title': f"ESCALATION: {card['title']}",
            'failed_attempts': card['validation_history'],
            'owner': 'tech_lead',
            'created_at': datetime.utcnow().isoformat()
        }

        self.backlog['cards'].append(escalation_card)
        self.transition_state(card_id, 'ESCALATED')
        self.escalated_cards.add(card_id)

        self.save_backlog()

        logger.error(f"ðŸš¨ Card {card_id} ESCALATED to Tech Lead")

        # Emit event
        self.emit_event('card.escalated', {
            'card_id': card_id,
            'escalation_card_id': f"{card_id}-ESC",
            'failed_attempts': len(card['validation_history'])
        })

    def handle_owner_failure(self, card_id: str, error: Any):
        """Handle owner execution failure (after Celery retries exhausted)"""
        logger.error(f"Card {card_id} failed execution: {error}")

        card = self.get_card(card_id)
        self.transition_state(card_id, 'FAILED')
        card['error'] = str(error)

        # Add to failed set
        self.failed_cards.add(card_id)
        del self.active_tasks[card_id]

        # Create correction card (como se fosse rejection)
        self.create_correction_card(card_id, {
            'result': 'FAILED',
            'reasons': [f"Owner execution failed: {str(error)}"],
            'feedback': {}
        })

    def enqueue_dependents(self, card_id: str):
        """Enqueue cards that depend on card_id"""
        dependents = [
            c for c in self.backlog['cards']
            if card_id in c.get('dependencies', []) and c['status'] == 'TODO'
        ]

        for dep_card in dependents:
            # Check if ALL dependencies met
            deps = dep_card.get('dependencies', [])
            if all(d in self.completed_cards for d in deps):
                logger.info(f"Enqueuing dependent card {dep_card['id']} (parent {card_id} completed)")
                self.enqueue_card(dep_card)

    def emit_event(self, event_type: str, data: Dict):
        """Emit SSE event to Portal (placeholder)"""
        # TODO: Implement SSE broadcaster
        logger.info(f"Event: {event_type} - {data}")

    def is_complete(self) -> bool:
        """Check if all cards are completed or escalated"""
        total = len(self.backlog['cards'])
        done = len(self.completed_cards) + len(self.escalated_cards)
        return done >= total

    def run(self):
        """Main orchestration loop"""
        logger.info("ðŸš€ Meta-Orchestrator starting...")

        # Enqueue initial ready cards
        ready_cards = self.get_ready_cards()
        logger.info(f"Found {len(ready_cards)} ready cards")
        for card in ready_cards:
            self.enqueue_card(card)

        # Main loop
        while True:
            # 1. Monitor active tasks
            self.monitor_tasks()

            # 2. Enqueue new ready cards
            ready_cards = self.get_ready_cards()
            for card in ready_cards:
                self.enqueue_card(card)

            # 3. Check termination
            if self.is_complete():
                logger.info("âœ… All cards completed. Meta-Orchestrator terminating.")
                break

            # 4. Sleep
            time.sleep(self.POLL_INTERVAL)

        # Final checkpoint
        self.save_backlog()
        logger.info("Meta-Orchestrator stopped.")


if __name__ == '__main__':
    import sys
    from pathlib import Path

    # Paths
    BASE_DIR = Path(__file__).parent
    STATE_DIR = BASE_DIR / "state"
    BACKLOG_PATH = STATE_DIR / "backlog_master.json"

    # Start orchestrator
    orchestrator = MetaOrchestrator(
        backlog_path=BACKLOG_PATH,
        state_dir=STATE_DIR
    )

    try:
        orchestrator.run()
    except KeyboardInterrupt:
        logger.info("Meta-Orchestrator interrupted by user")
        orchestrator.save_backlog()
        sys.exit(0)
```

### CritÃ©rios de Sucesso (Fase 1)
- âœ… Meta-Orchestrator carrega backlog_master.json
- âœ… Dependency graph construÃ­do corretamente
- âœ… Cards enfileirados em ordem de dependÃªncias
- âœ… State machine valida transiÃ§Ãµes
- âœ… Celery tasks executam e retornam `TaskResult`
- âœ… Correction cards criados automaticamente (max 3 attempts)
- âœ… Escalation cards criados apÃ³s 3 falhas
- âœ… Checkpoints salvam backlog a cada 10 cards

**EsforÃ§o**: 20h (2-3 dias)
**ROI**: $20k/ano (coordination + correction loops)

---

## âœ… Validation Pipeline (Fase 2) - ContinuaÃ§Ã£o

[CONTINUAÃ‡ÃƒO DO PLANO EM PRÃ“XIMA SEÃ‡ÃƒO...]

Por brevidade, as prÃ³ximas fases seguem a mesma estrutura detalhada:
- Fase 2: Validation Pipeline (Verification, LLM-Judge, QA integration)
- Fase 3: Correction Loop + Debugging Agent
- Fase 4: Agent Owners Completos (Frontend, Backend, QA)
- Fase 5: Integration Tests
- Fase 6: Portal Simples
- Fase 7: Observability + Cost Tracking

**Documento completo disponÃ­vel em**: `/Users/jose.silva.lb/LBPay/supercore/ORQUESTRACAO_CELERY_PLANO_COMPLETO.md`

---

## ðŸ“Š Success Metrics (Como medir sucesso apÃ³s implementaÃ§Ã£o)

### MÃ©tricas Operacionais
| MÃ©trica | Target | Como medir |
|---------|--------|------------|
| Rejection Rate | <10% | `len([c for c in cards if c['status'] == 'REJECTED']) / total_cards` |
| Avg Attempts per Card | <1.5 | `sum(c.get('attempt', 1) for c in cards) / total_cards` |
| Escalation Rate | <5% | `len([c for c in cards if c['status'] == 'ESCALATED']) / total_cards` |
| First-Time-Right Rate | >80% | `len([c for c in cards if c.get('attempt', 1) == 1 and c['status'] == 'APPROVED']) / total_cards` |

### MÃ©tricas de Qualidade
| MÃ©trica | Target | Como medir |
|---------|--------|------------|
| Verification Agent Usage | 100% | Todos os cards passam por Verification |
| LLM-Judge Coverage | 100% | Todos os cards de cÃ³digo passam por LLM-Judge |
| Zero-Tolerance Violations | 0 | QA Owner detecta todas as 8 violaÃ§Ãµes |

### MÃ©tricas de Performance
| MÃ©trica | Target | Como medir |
|---------|--------|------------|
| Time to Approval | <10 min/card | `completed_at - started_at` (p95) |
| Correction Loop Time | <5 min | Tempo desde REJECTED atÃ© retry IN_PROGRESS |
| Throughput | 120 cards em <2h | Total time para completar backlog |

### MÃ©tricas de Custo
| MÃ©trica | Target | Como medir |
|---------|--------|------------|
| Cost per Card | <$0.15 | `card['cost_tracking']['total_cost_usd']` |
| Total Project Cost | <$18 (120 cards) | `sum(c['cost_tracking']['total_cost_usd'] for c in cards)` |
| High-Cost Cards | <5 cards >$0.50 | `len([c for c in cards if c['cost_tracking']['total_cost_usd'] > 0.5])` |

---

## ðŸŽ¯ Next Steps (ApÃ³s aprovaÃ§Ã£o deste plano)

1. **AprovaÃ§Ã£o do plano** âœ… (FEITO - OpÃ§Ã£o A escolhida)
2. **Fase 0**: Setup Celery + Redis (1 dia) â†’ START HERE
3. **Fase 1**: Meta-Orchestrator + State Machine (2-3 dias)
4. **Checkpoint**: Validar Fase 1 funcionando end-to-end
5. **Fase 2-7**: ImplementaÃ§Ã£o sequencial conforme plano

---

**VersÃ£o**: 2.0.0
**Data**: 2025-12-27
**Autor**: Claude (Integration of ORCHESTRATION + COORDINATION plans)
**Status**: âœ… PLANO APROVADO - PRONTO PARA IMPLEMENTAÃ‡ÃƒO
**PrÃ³ximo Passo**: Fase 0 - Setup Celery + Redis
